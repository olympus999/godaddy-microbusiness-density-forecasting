{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8988304-69fc-4e3d-a15e-b7da71b87192",
   "metadata": {},
   "source": [
    "# All"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada2126-7935-4780-b60b-62d39225d607",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import/read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b590acc4-31dc-4c94-8155-19e68c214486",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "from types import SimpleNamespace\n",
    "from typing import Callable\n",
    "import copy\n",
    "\n",
    "import bayes_opt as bayes\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import (\n",
    "    BayesianOptimization,\n",
    "    SequentialDomainReductionTransformer,\n",
    "    UtilityFunction,\n",
    ")\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.util import load_logs\n",
    "from library.classes import Feature, ManageDataSplit, ManageFeatures, feature_objects\n",
    "from library.classes.trait import DataFrame\n",
    "from library.feature_func import (\n",
    "    add_categorical_feature,\n",
    "    add_feature_targets_groupby_stats,\n",
    "    add_numerical_feature,\n",
    "    f_rolling_mean,\n",
    "    f_shifted,\n",
    "    time_arrow,\n",
    "    f_microbusiness_pct_change,\n",
    "    f_microbusiness_density_diff,\n",
    ")\n",
    "from library.optimize_this import optimize_this\n",
    "from library.utils import build_callbacks, read_df, smape, states, states_abb, write_df\n",
    "from meteostat import Monthly, Point, Stations\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from traitlets import (\n",
    "    Any,\n",
    "    Bool,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Float,\n",
    "    HasTraits,\n",
    "    Int,\n",
    "    List,\n",
    "    TraitError,\n",
    "    TraitType,\n",
    "    Tuple,\n",
    "    Unicode,\n",
    "    default,\n",
    "    validate,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa7b749-b179-491b-84de-b586c94dbd71",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path = \"../data/\"\n",
    "boundaries_sub_data_path = \"other/boundaries\"\n",
    "# bayesian_run_path = \"../data/bayesian_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a255db8-0b36-465b-a5a0-90471a4beb29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_census = read_df(\"census_starter.csv\")\n",
    "df_test = read_df(\"test.csv\")\n",
    "df_train = read_df(\"train.csv\")\n",
    "df_submission = read_df(\"sample_submission.csv\")\n",
    "# df_population = read_df('df_population.csv', 'other')\n",
    "# df_census_population = read_df('df_census_population.csv', 'kaggle_census')\n",
    "# df_train_census = read_df('df_train_census.csv', 'kaggle_census')\n",
    "df_adjusted_microbusiness_density = read_df(\n",
    "    \"df_adjusted_microbusiness_density.csv\", \"kaggle_census\"\n",
    ")\n",
    "\n",
    "# df_boundaries = read_df(\"us-county-boundaries.csv\", boundaries_sub_data_path, delimiter=\";\")\n",
    "df_train = pd.merge(df_train, df_adjusted_microbusiness_density, \"left\", \"row_id\")\n",
    "# df_train = df_train.rename(\n",
    "#     columns={\n",
    "#         \"microbusiness_density\": \"original_microbusiness_density\",\n",
    "#         \"adjusted_microbusiness_density\": \"microbusiness_density\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "df_train = df_train.rename(\n",
    "    columns={\n",
    "        \"microbusiness_density\": \"original_microbusiness_density\",\n",
    "        \"active\": \"microbusiness_density\",\n",
    "    }\n",
    ")\n",
    "df_train[\"microbusiness_density\"] = df_train[\"microbusiness_density\"].apply(np.log1p)\n",
    "\n",
    "df_location = read_df(\"cfips_location.csv\", \"usa-counties-coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6aafbe-6bd4-4ab9-8c8e-e04af6fc517a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 27)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df_train[df_train.isna().any(axis=1)]\n",
    "if t.shape[0] != 24:\n",
    "    raise Exception(\"Nan counts used to be 24... something changed\")\n",
    "df_train[df_train.isna().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26862e-21d2-48ef-9acb-48e8a6fdb8d2",
   "metadata": {},
   "source": [
    "### Weather save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30b5b17-6d62-42d9-ab11-fb4cf193fcf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_weather_data(path_weather):\n",
    "    # Temperatures\n",
    "    temps = df_boundaries[[\"NAME\", \"NAMELSAD\", \"INTPTLAT\", \"INTPTLON\"]].copy()\n",
    "    temps[\"min_date\"] = df_train[\"first_day_of_month\"].min()\n",
    "    temps[\"max_date\"] = df_train[\"first_day_of_month\"].max()\n",
    "\n",
    "    data_list = []\n",
    "    for idx, row in temps.iterrows():\n",
    "        p = Point(row[\"INTPTLAT\"], row[\"INTPTLON\"], 70)\n",
    "\n",
    "        data = Monthly(p, row[\"min_date\"], row[\"max_date\"])\n",
    "        data = data.fetch()\n",
    "\n",
    "        if data.shape[0] > 0:\n",
    "            data[\"state\"] = row[\"NAME\"]\n",
    "            data[\"county\"] = row[\"NAMELSAD\"]\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(idx)\n",
    "\n",
    "    weather_data = pd.concat(data_list)\n",
    "    weather_data.to_csv(path_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3185d92-86b2-43c8-807f-4fc0cd9bd87a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_weather = \"../data/other/weather/weather.csv\"\n",
    "# save_weather_data(path_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134983df-a2b2-461b-bbb5-2809a2d7b622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv(path_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99894c95-7057-452e-93e8-22291f9552cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda2a9c-3c75-4fc7-8700-8884a9f83b40",
   "metadata": {},
   "source": [
    "### Feature setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928e4b4e-744a-422f-a9f2-4b66bdd614f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "manage_data_split = ManageDataSplit(df_train)\n",
    "\n",
    "enabled_tuple = (0, 0.55)\n",
    "enabled_tuple_h = (0, 0.75)\n",
    "enabled_tuple_almost = (0.4, 1)\n",
    "enabled_tuple_always = (1, 1)\n",
    "params_tuple = (0, 10)\n",
    "\n",
    "gamma = 0\n",
    "\n",
    "# Better to clear it. Otherwise it might containt features we do not want\n",
    "feature_objects.clear()\n",
    "\n",
    "for cols in [\n",
    "    {\n",
    "        \"target_col\": \"microbusiness_density\",\n",
    "        \"groupby_col\": \"cfips\",\n",
    "        \"params_bounds\": list(repeat((1, 12), 4)),\n",
    "    },\n",
    "    # {\"target_col\": \"microbusiness_density\", \"groupby_col\": \"county\"},\n",
    "    # {\"target_col\": \"microbusiness_density\", \"groupby_col\": \"state\"},\n",
    "]:\n",
    "    target_col = cols[\"target_col\"]\n",
    "    groupby_col = cols[\"groupby_col\"]\n",
    "    params_bounds = list(repeat((1, 20), 4))\n",
    "    if \"params_bounds\" in cols.keys():\n",
    "        params_bounds = cols[\"params_bounds\"]\n",
    "    f_col = \"{}_{}_rolling_mean\".format(groupby_col, target_col)\n",
    "    feature_target_rolling_mean = Feature(\n",
    "        f_col,\n",
    "        f_rolling_mean,\n",
    "        df_train,\n",
    "        target_col=target_col,\n",
    "        groupby_col=groupby_col,\n",
    "        enabled_bounds=list(repeat(enabled_tuple, 4)),\n",
    "        params_bounds=params_bounds,\n",
    "    )\n",
    "\n",
    "\n",
    "target_col = \"microbusiness_density\"\n",
    "params_bounds = list(repeat((2, 10), 4))\n",
    "params_bounds[0] = (1, 1+gamma)\n",
    "enabled_bounds = list(repeat(enabled_tuple, 4))\n",
    "enabled_bounds[0] = enabled_tuple_always\n",
    "feature_target_shift_mean = Feature(\n",
    "    f_col=\"{}_shift\".format(target_col),\n",
    "    f=f_shifted,\n",
    "    df=df_train,\n",
    "    target_col=target_col,\n",
    "    enabled_bounds=enabled_bounds,\n",
    "    params_bounds=params_bounds,\n",
    ")\n",
    "\n",
    "target_col = \"original_microbusiness_density\"\n",
    "params_bounds = list(repeat((2, 10), 4))\n",
    "enabled_bounds = list(repeat(enabled_tuple, 4))\n",
    "params_bounds[0] = (1, 1+gamma)\n",
    "enabled_bounds[0] = enabled_tuple_always\n",
    "params_bounds[1] = (2, 2+gamma)\n",
    "enabled_bounds[1] = enabled_tuple_almost\n",
    "feature_target_shift_mean = Feature(\n",
    "    f_col=\"{}_shift\".format(target_col),\n",
    "    f=f_shifted,\n",
    "    df=df_train,\n",
    "    target_col=target_col,\n",
    "    enabled_bounds=enabled_bounds,\n",
    "    params_bounds=params_bounds,\n",
    ")\n",
    "\n",
    "for idx, col in enumerate(\n",
    "    [\n",
    "        (\"county\", enabled_tuple_almost),\n",
    "        \"state\",\n",
    "        (\"cfips\", enabled_tuple_almost),\n",
    "    ]\n",
    "):\n",
    "    _tuple = enabled_tuple\n",
    "    if type(col) is not str:\n",
    "        _tuple = col[1]\n",
    "        col = col[0]\n",
    "    _feature = Feature(col, add_categorical_feature, df_train, enabled_bounds=[_tuple])\n",
    "\n",
    "for idx, col in enumerate(\n",
    "    [\n",
    "        \"median_hh_inc\",\n",
    "        \"pct_bb\",\n",
    "        \"pct_college\",\n",
    "        \"pct_foreign_born\",\n",
    "        \"pct_it_workers\",\n",
    "        (\"target_census_over_18_population_x1000\", enabled_tuple_almost),\n",
    "        (\"target_census_population_x1000\", enabled_tuple_almost),\n",
    "        \"lng\",\n",
    "        \"lat\",\n",
    "        \"rot_15_x\",\n",
    "        \"rot_15_y\",\n",
    "        \"rot_30_x\",\n",
    "        \"rot_30_y\",\n",
    "        \"rot_45_x\",\n",
    "        \"rot_45_y\",\n",
    "    ]\n",
    "):\n",
    "    _tuple = enabled_tuple\n",
    "    if type(col) is not str:\n",
    "        _tuple = col[1]\n",
    "        col = col[0]\n",
    "    _feature = Feature(col, add_numerical_feature, df_train, enabled_bounds=[_tuple])\n",
    "\n",
    "feature_time_arrow = Feature(\n",
    "    \"time_arrow\", time_arrow, df_train, enabled_bounds=[enabled_tuple]\n",
    ")\n",
    "\n",
    "# for groupby_col in [\n",
    "#     \"cfips\",\n",
    "#     \"state\",\n",
    "#     \"county\",\n",
    "# ]:\n",
    "#     for col in [\n",
    "#         \"median_hh_inc\",\n",
    "#         \"pct_bb\",\n",
    "#         \"pct_college\",\n",
    "#         \"pct_foreign_born\",\n",
    "#         \"pct_it_workers\",\n",
    "#     ]:\n",
    "#         for agg_function in [\"median\", \"mean\", \"std\"]:\n",
    "#             f_col = \"{}_{}_target_{}\".format(groupby_col, col, agg_function)\n",
    "#             _feature = Feature(\n",
    "#                 f_col,\n",
    "#                 add_feature_targets_groupby_stats,\n",
    "#                 df_train,\n",
    "#                 groupby_col=groupby_col,\n",
    "#                 col=col,\n",
    "#                 agg_function=agg_function,\n",
    "#                 enabled_bounds=[enabled_tuple],\n",
    "#                 train_idx=manage_data_split._train_idx,\n",
    "#             )\n",
    "\n",
    "feature_microbusiness_density_pct_change = Feature(\n",
    "    \"microbusiness_density_pct_change\",\n",
    "    f_microbusiness_pct_change,\n",
    "    df_train,\n",
    "    enabled_bounds=[enabled_tuple],\n",
    ")\n",
    "\n",
    "feature_microbusiness_density_diff = Feature(\n",
    "    \"microbusiness_density_diff\",\n",
    "    f_microbusiness_density_diff,\n",
    "    df_train,\n",
    "    enabled_bounds=[enabled_tuple],\n",
    ")\n",
    "\n",
    "# Bounded region of parameter space\n",
    "model_pbounds = {\n",
    "    \"num_leaves\": (3, 200),\n",
    "    \"num_iterations\": (2000, 2000),\n",
    "    \"learning_rate\": (0.01, 2.5),\n",
    "    \"bagging_fraction\": (0.0001, 1),\n",
    "    \"feature_fraction\": (0.0001, 1),\n",
    "    \"lambda_l1\": (0, 500),\n",
    "    \"lambda_l2\": (0, 500),\n",
    "    \"bagging_freq\": (0, 500),\n",
    "    \"min_data_in_leaf\": (10, 3000),\n",
    "    \"min_sum_hessian_in_leaf\": (0, 500),\n",
    "    \"max_depth\": (-10, 150),\n",
    "    \"path_smooth\": (0, 500),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff45bf33-522a-4b36-824a-7da6da47cf8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87780,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manage_data_split._train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58dc91f8-8436-4758-ac39-fd1786ebd4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25080,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manage_data_split._val_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f04970c5-0ba2-4bb0-9c80-d347889a5216",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# manage_features = ManageFeatures(feature_objects)\n",
    "# manage_features.set_model_pbounds(model_pbounds)\n",
    "\n",
    "# pbounds = manage_features.get_pbounds()\n",
    "\n",
    "\n",
    "# feature = feature_target_shift_mean\n",
    "# df_mapped = manage_features._make_mapped(d)\n",
    "# df_mapped_feature = df_mapped[df_mapped[\"f_col\"] == feature.f_col]\n",
    "# r = feature.f(\n",
    "#     df=feature.df.copy(),\n",
    "#     df_mapped_feature=df_mapped_feature,\n",
    "#     f_col=feature.f_col,\n",
    "#     **feature._kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60cb81-43a1-4ce6-abdf-9cf531b9e109",
   "metadata": {},
   "source": [
    "#### Start bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37f689bb-3230-4c48-8057-36aaf32679c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae np.exp train(79632, 8) test(15675, 8) -18.9411 eval(25080, 8) -19.1352\n",
      "mae np.exp train(83240, 6) test(15670, 6) -6.924 eval(25073, 6) -6.8279\n",
      "mae np.exp train(64909, 10) test(15675, 10) -10.5961 eval(25080, 10) -10.6712\n",
      "mae np.exp train(74492, 6) test(15675, 6) -9.283 eval(25080, 6) -9.8926\n",
      "mae np.exp train(58191, 15) test(15675, 15) -18.7226 eval(25080, 15) -20.6989\n",
      "mae np.exp train(80115, 9) test(15670, 9) -12.7758 eval(25073, 9) -13.3693\n",
      "mae np.exp train(80755, 8) test(15670, 8) -75.2847 eval(25073, 8) -89.3045\n",
      "mae np.exp train(81105, 8) test(15675, 8) -8.7238 eval(25080, 8) -6.6706\n",
      "mae np.exp train(55971, 12) test(15675, 12) -109.8022 eval(25080, 12) -593.3956\n",
      "mae np.exp train(52079, 8) test(15675, 8) -10.5591 eval(25080, 8) -10.5564\n",
      "mae np.exp train(80963, 8) test(15675, 8) -33.812 eval(25080, 8) -38.595\n",
      "mae np.exp train(83642, 9) test(15675, 9) -5.6798 eval(25080, 9) -5.8365\n",
      "mae np.exp train(83728, 8) test(15675, 8) -11.6677 eval(25080, 8) -12.435\n",
      "mae np.exp train(80542, 9) test(15675, 9) -39.6121 eval(25080, 9) -38.2117\n",
      "mae np.exp train(83790, 7) test(15670, 7) -14.4669 eval(25073, 7) -14.5504\n",
      "mae np.exp train(80867, 7) test(15675, 7) -111.3241 eval(25080, 7) -141.1562\n",
      "mae np.exp train(81235, 7) test(15675, 7) -14.1908 eval(25080, 7) -14.6822\n",
      "mae np.exp train(56161, 14) test(15675, 14) -34.7627 eval(25080, 14) -35.0346\n",
      "mae np.exp train(80494, 11) test(15675, 11) -10.4337 eval(25080, 11) -10.3099\n",
      "mae np.exp train(80054, 7) test(15675, 7) -6.2242 eval(25080, 7) -6.2953\n",
      "mae np.exp train(80653, 8) test(15670, 8) -12.9977 eval(25073, 8) -11.193\n",
      "mae np.exp train(79697, 8) test(15675, 8) -109.7048 eval(25080, 8) -587.6154\n",
      "mae np.exp train(52916, 11) test(15670, 11) -130.1838 eval(25073, 11) -179.356\n",
      "mae np.exp train(83627, 8) test(15675, 8) -13.8409 eval(25080, 8) -13.6662\n",
      "mae np.exp train(80227, 10) test(15670, 10) -57.2466 eval(25073, 10) -67.0627\n",
      "mae np.exp train(61190, 10) test(15675, 10) -20.0116 eval(25080, 10) -20.0121\n",
      "mae np.exp train(79525, 9) test(15675, 9) -46.5564 eval(25080, 9) -46.7722\n",
      "mae np.exp train(80675, 5) test(15675, 5) -116.915 eval(25080, 5) -151.3144\n",
      "mae np.exp train(80263, 7) test(15675, 7) -13.836 eval(25080, 7) -13.808\n",
      "mae np.exp train(67956, 13) test(15675, 13) -13.9021 eval(25080, 13) -13.6756\n",
      "mae np.exp train(81340, 9) test(15675, 9) -5.141 eval(25080, 9) -5.1458\n",
      "mae np.exp train(80640, 8) test(15675, 8) -114.2439 eval(25080, 8) -146.611\n",
      "mae np.exp train(80609, 5) test(15675, 5) -34.9142 eval(25080, 5) -39.978\n",
      "mae np.exp train(64749, 7) test(15675, 7) -19.1435 eval(25080, 7) -19.9711\n",
      "mae np.exp train(80935, 6) test(15675, 6) -18.0859 eval(25080, 6) -19.9797\n",
      "mae np.exp train(76928, 8) test(15670, 8) -63.5918 eval(25073, 8) -76.0982\n",
      "mae np.exp train(79354, 7) test(15675, 7) -10.3062 eval(25080, 7) -10.3349\n",
      "mae np.exp train(61444, 10) test(15675, 10) -5.4964 eval(25080, 10) -5.8135\n",
      "mae np.exp train(82981, 7) test(15670, 7) -11.8839 eval(25073, 7) -10.8481\n",
      "mae np.exp train(59177, 9) test(15670, 9) -6.1601 eval(25073, 9) -6.2698\n",
      "mae np.exp train(79615, 5) test(15675, 5) -124.984 eval(25080, 5) -167.7532\n",
      "mae np.exp train(83630, 9) test(15675, 9) -8.975 eval(25080, 9) -8.6751\n",
      "mae np.exp train(65170, 9) test(15675, 9) -11.6347 eval(25080, 9) -11.8901\n",
      "mae np.exp train(71270, 9) test(15675, 9) -17.7624 eval(25080, 9) -16.4138\n",
      "mae np.exp train(79102, 8) test(15675, 8) -6.8889 eval(25080, 8) -6.6367\n",
      "mae np.exp train(76795, 9) test(15675, 9) -122.4877 eval(25080, 9) -188.8845\n",
      "mae np.exp train(61894, 10) test(15675, 10) -33.5319 eval(25080, 10) -37.6754\n",
      "mae np.exp train(49831, 7) test(15675, 7) -24.5903 eval(25080, 7) -27.0123\n",
      "mae np.exp train(82835, 6) test(15675, 6) -120.0469 eval(25080, 6) -157.8032\n",
      "mae np.exp train(80046, 7) test(15675, 7) -118.3226 eval(25080, 7) -174.0891\n",
      "mae np.exp train(80867, 10) test(15675, 10) -6.6772 eval(25080, 10) -5.8991\n",
      "mae np.exp train(83447, 6) test(15675, 6) -121.5029 eval(25080, 6) -160.9288\n",
      "mae np.exp train(62093, 9) test(15675, 9) -10.3595 eval(25080, 9) -10.6867\n",
      "mae np.exp train(80404, 9) test(15670, 9) -7.2268 eval(25073, 9) -7.6882\n",
      "mae np.exp train(84540, 7) test(15675, 7) -4.6797 eval(25080, 7) -3.7568\n",
      "mae np.exp train(74529, 8) test(15675, 8) -116.026 eval(25080, 8) -149.8012\n",
      "mae np.exp train(80077, 9) test(15675, 9) -13.7264 eval(25080, 9) -14.0829\n",
      "mae np.exp train(80022, 10) test(15670, 10) -129.9227 eval(25073, 10) -177.9147\n",
      "mae np.exp train(64588, 7) test(15675, 7) -19.4692 eval(25080, 7) -20.8674\n",
      "mae np.exp train(83208, 9) test(15675, 9) -8.54 eval(25080, 9) -9.1045\n",
      "mae np.exp train(67791, 9) test(15675, 9) -7.2262 eval(25080, 9) -6.7519\n",
      "mae np.exp train(58263, 8) test(15675, 8) -18.1104 eval(25080, 8) -17.8977\n",
      "mae np.exp train(76305, 9) test(15675, 9) -8.4211 eval(25080, 9) -8.6356\n",
      "mae np.exp train(80604, 7) test(15675, 7) -112.4267 eval(25080, 7) -143.3112\n",
      "mae np.exp train(81182, 12) test(15675, 12) -4.366 eval(25080, 12) -3.5939\n",
      "mae np.exp train(79520, 6) test(15675, 6) -7.1334 eval(25080, 6) -7.2812\n",
      "mae np.exp train(48904, 14) test(15670, 14) -16.6686 eval(25073, 14) -16.8372\n",
      "mae np.exp train(80307, 10) test(15675, 10) -11.4031 eval(25080, 10) -11.4946\n",
      "mae np.exp train(62011, 11) test(15670, 11) -116.8346 eval(25073, 11) -151.3313\n",
      "mae np.exp train(61979, 6) test(15675, 6) -6.2927 eval(25080, 6) -6.7276\n",
      "mae np.exp train(80205, 10) test(15670, 10) -6.0936 eval(25073, 10) -5.5494\n",
      "mae np.exp train(80101, 8) test(15675, 8) -117.7205 eval(25080, 8) -152.9824\n",
      "mae np.exp train(58929, 8) test(15675, 8) -132.0189 eval(25080, 8) -183.6157\n",
      "mae np.exp train(81035, 10) test(15675, 10) -17.3602 eval(25080, 10) -18.7616\n",
      "mae np.exp train(67686, 10) test(15675, 10) -5.333 eval(25080, 10) -5.5678\n",
      "mae np.exp train(52277, 11) test(15675, 11) -6.1001 eval(25080, 11) -6.3662\n",
      "mae np.exp train(79312, 8) test(15675, 8) -6.6496 eval(25080, 8) -6.5615\n",
      "mae np.exp train(61500, 8) test(15675, 8) -15.2253 eval(25080, 8) -16.2069\n",
      "mae np.exp train(55210, 9) test(15675, 9) -15.0806 eval(25080, 9) -16.0649\n",
      "mae np.exp train(62471, 8) test(15675, 8) -5.1347 eval(25080, 8) -5.2912\n",
      "mae np.exp train(83592, 6) test(15675, 6) -32.8414 eval(25080, 6) -37.3252\n",
      "mae np.exp train(67741, 11) test(15675, 11) -58.5111 eval(25080, 11) -69.9896\n",
      "mae np.exp train(61386, 9) test(15675, 9) -130.2279 eval(25080, 9) -179.1432\n",
      "mae np.exp train(80085, 7) test(15675, 7) -5.7488 eval(25080, 7) -5.7623\n",
      "mae np.exp train(77879, 8) test(15675, 8) -10.7179 eval(25080, 8) -11.3256\n",
      "mae np.exp train(61324, 8) test(15675, 8) -115.0334 eval(25080, 8) -147.9691\n",
      "mae np.exp train(65284, 7) test(15675, 7) -5.1406 eval(25080, 7) -5.1701\n",
      "mae np.exp train(59273, 7) test(15675, 7) -10.8001 eval(25080, 7) -10.5306\n",
      "mae np.exp train(55506, 8) test(15675, 8) -5.376 eval(25080, 8) -5.2303\n",
      "mae np.exp train(64707, 10) test(15675, 10) -4.5695 eval(25080, 10) -4.6341\n",
      "mae np.exp train(81307, 7) test(15675, 7) -14.3209 eval(25080, 7) -15.0128\n",
      "mae np.exp train(83243, 9) test(15675, 9) -14.1813 eval(25080, 9) -15.1285\n",
      "mae np.exp train(79243, 7) test(15670, 7) -15.7422 eval(25073, 7) -16.2108\n",
      "mae np.exp train(79777, 6) test(15675, 6) -109.7114 eval(25080, 6) -588.0338\n",
      "mae np.exp train(79690, 8) test(15675, 8) -22.9153 eval(25080, 8) -22.4413\n",
      "mae np.exp train(61787, 11) test(15675, 11) -127.4907 eval(25080, 11) -203.5868\n",
      "mae np.exp train(80778, 8) test(15670, 8) -9.5134 eval(25073, 8) -9.7706\n",
      "mae np.exp train(68044, 11) test(15670, 11) -78.2702 eval(25073, 11) -106.2792\n",
      "mae np.exp train(65432, 8) test(15675, 8) -11.292 eval(25080, 8) -10.0058\n",
      "mae np.exp train(68075, 8) test(15675, 8) -132.533 eval(25080, 8) -184.4183\n",
      "mae np.exp train(73401, 12) test(15675, 12) -11.1631 eval(25080, 12) -10.4539\n",
      "mae np.exp train(55786, 9) test(15675, 9) -13.2128 eval(25080, 9) -13.7916\n",
      "mae np.exp train(83385, 5) test(15675, 5) -4.9774 eval(25080, 5) -5.1515\n",
      "mae np.exp train(61626, 13) test(15675, 13) -12.6595 eval(25080, 13) -13.6894\n",
      "mae np.exp train(49378, 8) test(15675, 8) -7.6511 eval(25080, 8) -7.7673\n",
      "mae np.exp train(80539, 7) test(15675, 7) -116.4714 eval(25080, 7) -172.2019\n",
      "mae np.exp train(79743, 6) test(15675, 6) -7.1272 eval(25080, 6) -7.4773\n",
      "mae np.exp train(80603, 7) test(15675, 7) -20.5095 eval(25080, 7) -21.0224\n",
      "mae np.exp train(79430, 8) test(15675, 8) -9.5322 eval(25080, 8) -9.4148\n",
      "mae np.exp train(80121, 9) test(15675, 9) -127.9845 eval(25080, 9) -182.9965\n",
      "mae np.exp train(80275, 9) test(15675, 9) -114.7852 eval(25080, 9) -171.0182\n",
      "mae np.exp train(80445, 8) test(15675, 8) -109.7803 eval(25080, 8) -592.1709\n",
      "mae np.exp train(79989, 7) test(15670, 7) -114.5471 eval(25073, 7) -168.1179\n",
      "mae np.exp train(83022, 7) test(15675, 7) -110.3211 eval(25080, 7) -144.6177\n",
      "mae np.exp train(71402, 8) test(15675, 8) -109.8022 eval(25080, 8) -593.3956\n",
      "mae np.exp train(80290, 7) test(15675, 7) -116.5399 eval(25080, 7) -157.7307\n",
      "mae np.exp train(55477, 10) test(15670, 10) -15.3371 eval(25073, 10) -16.3855\n",
      "mae np.exp train(76941, 10) test(15670, 10) -6.2921 eval(25073, 10) -6.4722\n",
      "mae np.exp train(83013, 8) test(15670, 8) -122.4977 eval(25073, 8) -162.4949\n",
      "mae np.exp train(71216, 8) test(15675, 8) -11.7615 eval(25080, 8) -11.6579\n",
      "mae np.exp train(70538, 7) test(15675, 7) -8.6899 eval(25080, 7) -8.8526\n",
      "mae np.exp train(80734, 8) test(15675, 8) -46.4355 eval(25080, 8) -47.5686\n",
      "mae np.exp train(59085, 8) test(15675, 8) -123.9883 eval(25080, 8) -165.8074\n",
      "mae np.exp train(79872, 9) test(15675, 9) -123.2125 eval(25080, 9) -163.8324\n",
      "mae np.exp train(76993, 10) test(15675, 10) -6.0714 eval(25080, 10) -5.3741\n",
      "mae np.exp train(70786, 11) test(15675, 11) -123.0174 eval(25080, 11) -163.3518\n",
      "mae np.exp train(79931, 10) test(15675, 10) -16.1047 eval(25080, 10) -16.4236\n",
      "mae np.exp train(80575, 8) test(15675, 8) -24.5635 eval(25080, 8) -25.5157\n",
      "mae np.exp train(52566, 6) test(15675, 6) -6.2603 eval(25080, 6) -6.2737\n",
      "mae np.exp train(68051, 11) test(15675, 11) -121.6314 eval(25080, 11) -184.736\n",
      "mae np.exp train(80422, 8) test(15675, 8) -109.7522 eval(25080, 8) -590.5263\n",
      "mae np.exp train(71367, 10) test(15675, 10) -31.903 eval(25080, 10) -36.5694\n",
      "mae np.exp train(80994, 9) test(15675, 9) -25.9296 eval(25080, 9) -26.3478\n",
      "mae np.exp train(71540, 8) test(15675, 8) -9.4815 eval(25080, 8) -9.7186\n",
      "mae np.exp train(80046, 9) test(15675, 9) -8.2912 eval(25080, 9) -7.8296\n",
      "mae np.exp train(74613, 9) test(15675, 9) -11.8863 eval(25080, 9) -12.2518\n",
      "mae np.exp train(52347, 9) test(15675, 9) -8.5892 eval(25080, 9) -8.7481\n",
      "mae np.exp train(80641, 10) test(15670, 10) -120.1601 eval(25073, 10) -159.2197\n",
      "mae np.exp train(55591, 8) test(15675, 8) -10.6448 eval(25080, 8) -11.2067\n",
      "mae np.exp train(82759, 6) test(15675, 6) -113.1003 eval(25080, 6) -144.1597\n",
      "mae np.exp train(62005, 10) test(15675, 10) -130.9673 eval(25080, 10) -180.3896\n",
      "mae np.exp train(80516, 9) test(15675, 9) -18.1532 eval(25080, 9) -18.9126\n",
      "mae np.exp train(80863, 8) test(15675, 8) -132.8727 eval(25080, 8) -184.8595\n",
      "mae np.exp train(71125, 9) test(15675, 9) -122.9764 eval(25080, 9) -163.823\n",
      "mae np.exp train(64393, 9) test(15675, 9) -5.0167 eval(25080, 9) -5.0869\n",
      "mae np.exp train(79942, 9) test(15675, 9) -6.5986 eval(25080, 9) -6.7459\n",
      "mae np.exp train(80445, 8) test(15675, 8) -111.8092 eval(25080, 8) -141.7215\n",
      "mae np.exp train(79276, 8) test(15675, 8) -16.1244 eval(25080, 8) -17.4189\n",
      "mae np.exp train(48791, 9) test(15675, 9) -7.3692 eval(25080, 9) -7.7205\n",
      "mae np.exp train(79341, 8) test(15670, 8) -112.4755 eval(25073, 8) -143.0534\n",
      "mae np.exp train(55105, 10) test(15670, 10) -29.1116 eval(25073, 10) -32.3707\n",
      "mae np.exp train(56100, 10) test(15675, 10) -11.9593 eval(25080, 10) -11.9948\n",
      "mae np.exp train(79999, 9) test(15675, 9) -136.9631 eval(25080, 9) -186.5282\n",
      "mae np.exp train(58186, 10) test(15675, 10) -9.4627 eval(25080, 10) -10.1334\n",
      "mae np.exp train(55775, 8) test(15675, 8) -74.8323 eval(25080, 8) -88.5472\n",
      "mae np.exp train(80651, 8) test(15675, 8) -11.2298 eval(25080, 8) -11.2226\n",
      "mae np.exp train(79678, 6) test(15675, 6) -5.4471 eval(25080, 6) -5.7045\n",
      "mae np.exp train(76769, 8) test(15675, 8) -5.96 eval(25080, 8) -6.2684\n",
      "mae np.exp train(74324, 8) test(15670, 8) -17.6214 eval(25073, 8) -17.7068\n",
      "mae np.exp train(82723, 8) test(15675, 8) -8.082 eval(25080, 8) -8.6342\n",
      "mae np.exp train(79868, 6) test(15675, 6) -8.6638 eval(25080, 6) -9.1886\n",
      "mae np.exp train(79710, 7) test(15675, 7) -130.4406 eval(25080, 7) -179.711\n",
      "mae np.exp train(77663, 9) test(15675, 9) -11.0846 eval(25080, 9) -11.7993\n",
      "mae np.exp train(55732, 8) test(15675, 8) -12.1835 eval(25080, 8) -12.4453\n",
      "mae np.exp train(74222, 10) test(15675, 10) -4.8559 eval(25080, 10) -4.7586\n",
      "mae np.exp train(82575, 5) test(15675, 5) -6.3447 eval(25080, 5) -6.7358\n",
      "mae np.exp train(62002, 9) test(15675, 9) -30.0985 eval(25080, 9) -33.412\n",
      "mae np.exp train(80002, 7) test(15675, 7) -16.4809 eval(25080, 7) -16.2625\n",
      "mae np.exp train(80307, 9) test(15675, 9) -8.3551 eval(25080, 9) -8.4876\n",
      "mae np.exp train(74396, 8) test(15675, 8) -48.4231 eval(25080, 8) -54.1903\n",
      "mae np.exp train(77153, 10) test(15670, 10) -21.636 eval(25073, 10) -23.8525\n",
      "mae np.exp train(80910, 11) test(15675, 11) -25.212 eval(25080, 11) -24.4242\n",
      "mae np.exp train(80285, 8) test(15675, 8) -6.9457 eval(25080, 8) -7.0033\n",
      "mae np.exp train(81238, 8) test(15675, 8) -50.3762 eval(25080, 8) -51.0773\n",
      "mae np.exp train(80974, 8) test(15675, 8) -18.673 eval(25080, 8) -17.6205\n",
      "mae np.exp train(80204, 7) test(15675, 7) -115.8561 eval(25080, 7) -168.7888\n",
      "mae np.exp train(58831, 7) test(15675, 7) -4.9878 eval(25080, 7) -4.5749\n",
      "mae np.exp train(79748, 5) test(15675, 5) -37.4006 eval(25080, 5) -43.7212\n",
      "mae np.exp train(61188, 9) test(15675, 9) -111.3142 eval(25080, 9) -142.6977\n",
      "mae np.exp train(52590, 10) test(15675, 10) -5.8952 eval(25080, 10) -6.2033\n",
      "mae np.exp train(48909, 8) test(15675, 8) -23.4378 eval(25080, 8) -24.7499\n",
      "mae np.exp train(61405, 8) test(15675, 8) -10.4099 eval(25080, 8) -11.3613\n",
      "mae np.exp train(80224, 6) test(15675, 6) -13.4752 eval(25080, 6) -13.4091\n",
      "mae np.exp train(80796, 9) test(15675, 9) -15.8601 eval(25080, 9) -15.5012\n",
      "mae np.exp train(80740, 7) test(15675, 7) -131.0179 eval(25080, 7) -190.2508\n",
      "mae np.exp train(70494, 7) test(15675, 7) -11.893 eval(25080, 7) -12.6855\n",
      "mae np.exp train(64575, 14) test(15675, 14) -25.8546 eval(25080, 14) -27.1994\n",
      "mae np.exp train(81090, 6) test(15675, 6) -6.2039 eval(25080, 6) -5.9814\n",
      "mae np.exp train(80141, 7) test(15675, 7) -122.2846 eval(25080, 7) -170.0695\n",
      "mae np.exp train(64506, 9) test(15675, 9) -9.8036 eval(25080, 9) -10.4077\n",
      "mae np.exp train(82827, 8) test(15675, 8) -110.7506 eval(25080, 8) -167.1941\n",
      "mae np.exp train(77122, 10) test(15675, 10) -17.4999 eval(25080, 10) -19.191\n",
      "mae np.exp train(70583, 11) test(15675, 11) -6.9327 eval(25080, 11) -7.3656\n",
      "mae np.exp train(64334, 7) test(15675, 7) -8.1259 eval(25080, 7) -8.4153\n",
      "mae np.exp train(83844, 7) test(15675, 7) -109.8022 eval(25080, 7) -593.3956\n",
      "mae np.exp train(80162, 9) test(15670, 9) -12.3756 eval(25073, 9) -12.8378\n",
      "mae np.exp train(52060, 8) test(15675, 8) -9.9707 eval(25080, 8) -9.8422\n",
      "mae np.exp train(64987, 10) test(15675, 10) -4.6066 eval(25080, 10) -4.5566\n",
      "mae np.exp train(79768, 8) test(15675, 8) -17.3217 eval(25080, 8) -16.694\n",
      "mae np.exp train(80060, 7) test(15675, 7) -11.7388 eval(25080, 7) -11.7773\n",
      "mae np.exp train(67946, 9) test(15670, 9) -6.9798 eval(25073, 9) -6.8327\n",
      "mae np.exp train(74149, 8) test(15675, 8) -44.9244 eval(25080, 8) -51.2192\n",
      "mae np.exp train(61376, 11) test(15675, 11) -18.9264 eval(25080, 11) -19.3539\n",
      "mae np.exp train(58294, 8) test(15675, 8) -5.7518 eval(25080, 8) -5.6623\n",
      "mae np.exp train(80425, 7) test(15675, 7) -120.0685 eval(25080, 7) -180.2295\n",
      "mae np.exp train(67824, 10) test(15675, 10) -10.7155 eval(25080, 10) -11.0011\n",
      "mae np.exp train(52410, 10) test(15675, 10) -134.5669 eval(25080, 10) -191.0969\n",
      "mae np.exp train(82669, 7) test(15675, 7) -8.5085 eval(25080, 7) -7.9074\n",
      "mae np.exp train(80266, 7) test(15670, 7) -46.0949 eval(25073, 7) -47.6571\n",
      "mae np.exp train(79780, 5) test(15675, 5) -4.8748 eval(25080, 5) -4.9381\n",
      "mae np.exp train(79785, 7) test(15675, 7) -124.8229 eval(25080, 7) -174.394\n",
      "mae np.exp train(65583, 8) test(15675, 8) -5.4476 eval(25080, 8) -5.6758\n",
      "mae np.exp train(65421, 8) test(15675, 8) -41.8111 eval(25080, 8) -47.8703\n",
      "mae np.exp train(79945, 9) test(15675, 9) -6.0779 eval(25080, 9) -6.2338\n",
      "mae np.exp train(79933, 8) test(15670, 8) -122.7852 eval(25073, 8) -163.1395\n",
      "mae np.exp train(82536, 8) test(15675, 8) -12.4128 eval(25080, 8) -13.3289\n",
      "mae np.exp train(52752, 10) test(15675, 10) -6.3911 eval(25080, 10) -6.5986\n",
      "mae np.exp train(80132, 9) test(15675, 9) -11.6512 eval(25080, 9) -12.0343\n",
      "mae np.exp train(58486, 11) test(15675, 11) -18.1906 eval(25080, 11) -18.4315\n",
      "mae np.exp train(79239, 9) test(15670, 9) -28.1928 eval(25073, 9) -29.8819\n",
      "mae np.exp train(80873, 11) test(15675, 11) -4.2663 eval(25080, 11) -4.3206\n",
      "mae np.exp train(80367, 10) test(15675, 10) -31.7524 eval(25080, 10) -29.194\n",
      "mae np.exp train(79503, 9) test(15675, 9) -34.817 eval(25080, 9) -39.3361\n",
      "mae np.exp train(80926, 7) test(15675, 7) -7.8944 eval(25080, 7) -7.4159\n",
      "mae np.exp train(80327, 6) test(15675, 6) -5.465 eval(25080, 6) -5.3279\n",
      "mae np.exp train(80824, 6) test(15675, 6) -25.9705 eval(25080, 6) -27.02\n",
      "mae np.exp train(79629, 10) test(15675, 10) -18.4797 eval(25080, 10) -20.5055\n",
      "mae np.exp train(84046, 6) test(15675, 6) -109.7948 eval(25080, 6) -592.9881\n",
      "mae np.exp train(49474, 9) test(15675, 9) -43.0874 eval(25080, 9) -39.8242\n",
      "mae np.exp train(68233, 8) test(15675, 8) -8.3222 eval(25080, 8) -9.1668\n",
      "mae np.exp train(79623, 9) test(15675, 9) -108.8233 eval(25080, 9) -145.4285\n",
      "mae np.exp train(52278, 9) test(15675, 9) -16.5662 eval(25080, 9) -16.4127\n",
      "mae np.exp train(76838, 8) test(15675, 8) -4.0261 eval(25080, 8) -4.1997\n",
      "mae np.exp train(68085, 9) test(15670, 9) -127.6895 eval(25073, 9) -189.4294\n",
      "mae np.exp train(79579, 6) test(15675, 6) -128.2181 eval(25080, 6) -174.4772\n",
      "mae np.exp train(80052, 10) test(15675, 10) -5.0169 eval(25080, 10) -5.2103\n",
      "mae np.exp train(62445, 10) test(15675, 10) -115.318 eval(25080, 10) -148.495\n",
      "mae np.exp train(55838, 12) test(15675, 12) -7.8687 eval(25080, 12) -7.1479\n",
      "mae np.exp train(74894, 9) test(15675, 9) -109.8245 eval(25080, 9) -594.613\n",
      "mae np.exp train(67796, 9) test(15675, 9) -11.302 eval(25080, 9) -10.8891\n",
      "mae np.exp train(73266, 11) test(15670, 11) -35.6751 eval(25073, 11) -39.7121\n",
      "mae np.exp train(73886, 7) test(15675, 7) -21.0721 eval(25080, 7) -21.4645\n",
      "mae np.exp train(80741, 6) test(15675, 6) -119.341 eval(25080, 6) -178.9551\n",
      "mae np.exp train(74445, 9) test(15675, 9) -61.9409 eval(25080, 9) -69.7977\n",
      "mae np.exp train(80165, 8) test(15675, 8) -10.2681 eval(25080, 8) -10.3277\n",
      "mae np.exp train(80370, 11) test(15675, 11) -9.9583 eval(25080, 11) -10.2491\n",
      "mae np.exp train(52303, 8) test(15675, 8) -109.8096 eval(25080, 8) -593.8021\n",
      "mae np.exp train(64705, 14) test(15675, 14) -10.0502 eval(25080, 14) -8.7217\n",
      "mae np.exp train(55947, 9) test(15675, 9) -8.5386 eval(25080, 9) -8.2945\n",
      "mae np.exp train(79690, 9) test(15670, 9) -6.5181 eval(25073, 9) -6.8758\n",
      "mae np.exp train(49461, 8) test(15675, 8) -123.7051 eval(25080, 8) -190.4056\n",
      "mae np.exp train(75162, 10) test(15675, 10) -6.6224 eval(25080, 10) -6.6347\n",
      "mae np.exp train(52406, 8) test(15675, 8) -14.3999 eval(25080, 8) -15.2837\n",
      "mae np.exp train(56167, 10) test(15675, 10) -7.9262 eval(25080, 10) -8.2649\n",
      "mae np.exp train(80390, 8) test(15675, 8) -129.1515 eval(25080, 8) -177.0294\n",
      "mae np.exp train(80922, 7) test(15675, 7) -13.5031 eval(25080, 7) -13.5619\n",
      "mae np.exp train(71152, 9) test(15675, 9) -124.0075 eval(25080, 9) -184.7487\n",
      "mae np.exp train(80553, 8) test(15675, 8) -60.1082 eval(25080, 8) -67.5048\n",
      "mae np.exp train(52673, 13) test(15670, 13) -41.9453 eval(25073, 13) -46.1767\n",
      "mae np.exp train(79688, 7) test(15670, 7) -9.9759 eval(25073, 7) -10.2715\n",
      "mae np.exp train(64398, 8) test(15675, 8) -128.9108 eval(25080, 8) -176.2212\n",
      "mae np.exp train(80505, 6) test(15675, 6) -8.7699 eval(25080, 6) -8.9025\n",
      "mae np.exp train(80867, 6) test(15675, 6) -6.366 eval(25080, 6) -6.7428\n",
      "mae np.exp train(79184, 10) test(15670, 10) -112.0013 eval(25073, 10) -142.3158\n",
      "mae np.exp train(80098, 8) test(15675, 8) -109.6611 eval(25080, 8) -584.6628\n",
      "mae np.exp train(80575, 6) test(15675, 6) -7.5947 eval(25080, 6) -7.9654\n",
      "mae np.exp train(55914, 8) test(15675, 8) -6.3937 eval(25080, 8) -6.4973\n",
      "mae np.exp train(79509, 8) test(15675, 8) -109.7181 eval(25080, 8) -588.4513\n",
      "mae np.exp train(79313, 8) test(15675, 8) -10.1735 eval(25080, 8) -10.4542\n",
      "mae np.exp train(61146, 8) test(15675, 8) -20.2748 eval(25080, 8) -21.9809\n",
      "mae np.exp train(61394, 8) test(15675, 8) -9.8513 eval(25080, 8) -10.1597\n",
      "mae np.exp train(58420, 10) test(15675, 10) -24.3621 eval(25080, 10) -26.8302\n",
      "mae np.exp train(79763, 9) test(15675, 9) -7.5806 eval(25080, 9) -6.5992\n",
      "mae np.exp train(64813, 10) test(15675, 10) -34.7537 eval(25080, 10) -33.525\n",
      "mae np.exp train(81101, 9) test(15675, 9) -123.9132 eval(25080, 9) -181.5716\n",
      "mae np.exp train(64378, 6) test(15675, 6) -33.9593 eval(25080, 6) -39.1761\n",
      "mae np.exp train(52721, 10) test(15675, 10) -11.2764 eval(25080, 10) -11.278\n",
      "mae np.exp train(80308, 8) test(15675, 8) -24.0315 eval(25080, 8) -24.0528\n",
      "mae np.exp train(70435, 8) test(15675, 8) -29.7391 eval(25080, 8) -33.4052\n",
      "mae np.exp train(58432, 9) test(15675, 9) -129.5427 eval(25080, 9) -177.2629\n",
      "mae np.exp train(73666, 8) test(15675, 8) -119.4969 eval(25080, 8) -156.2506\n",
      "mae np.exp train(55729, 10) test(15675, 10) -15.3509 eval(25080, 10) -16.1375\n",
      "mae np.exp train(83237, 6) test(15675, 6) -49.5847 eval(25080, 6) -55.5655\n",
      "mae np.exp train(81185, 5) test(15675, 5) -8.2018 eval(25080, 5) -8.2836\n",
      "mae np.exp train(80598, 9) test(15675, 9) -7.727 eval(25080, 9) -7.6624\n",
      "mae np.exp train(79520, 8) test(15675, 8) -109.7592 eval(25080, 8) -590.9387\n",
      "mae np.exp train(79952, 13) test(15675, 13) -19.7249 eval(25080, 13) -21.9235\n",
      "mae np.exp train(77446, 9) test(15675, 9) -14.988 eval(25080, 9) -14.4784\n",
      "mae np.exp train(80015, 9) test(15675, 9) -10.6751 eval(25080, 9) -11.2867\n",
      "mae np.exp train(73836, 9) test(15675, 9) -7.8812 eval(25080, 9) -8.3659\n",
      "mae np.exp train(62395, 8) test(15675, 8) -17.025 eval(25080, 8) -17.6903\n",
      "mae np.exp train(80181, 8) test(15675, 8) -119.3677 eval(25080, 8) -157.1727\n",
      "mae np.exp train(79932, 8) test(15675, 8) -18.8018 eval(25080, 8) -22.481\n",
      "mae np.exp train(74088, 8) test(15675, 8) -17.9362 eval(25080, 8) -17.665\n",
      "mae np.exp train(80536, 9) test(15675, 9) -17.3559 eval(25080, 9) -16.1653\n",
      "mae np.exp train(82939, 7) test(15675, 7) -10.6776 eval(25080, 7) -9.3245\n",
      "mae np.exp train(80394, 7) test(15675, 7) -8.3992 eval(25080, 7) -8.1686\n",
      "mae np.exp train(65271, 8) test(15675, 8) -11.7781 eval(25080, 8) -11.5794\n",
      "mae np.exp train(55469, 11) test(15675, 11) -17.9314 eval(25080, 11) -18.6242\n",
      "mae np.exp train(80088, 8) test(15670, 8) -124.8041 eval(25073, 8) -167.0835\n",
      "mae np.exp train(79765, 8) test(15675, 8) -14.5929 eval(25080, 8) -13.7919\n",
      "mae np.exp train(73729, 8) test(15670, 8) -116.6049 eval(25073, 8) -150.5881\n",
      "mae np.exp train(80448, 8) test(15675, 8) -109.6918 eval(25080, 8) -586.7761\n",
      "mae np.exp train(83707, 7) test(15675, 7) -132.9481 eval(25080, 7) -196.6295\n",
      "mae np.exp train(79343, 8) test(15675, 8) -108.5971 eval(25080, 8) -144.5102\n",
      "mae np.exp train(55452, 10) test(15675, 10) -22.5385 eval(25080, 10) -23.7844\n",
      "mae np.exp train(80556, 11) test(15675, 11) -11.9873 eval(25080, 11) -12.5707\n",
      "mae np.exp train(55837, 10) test(15675, 10) -112.2434 eval(25080, 10) -142.6785\n",
      "mae np.exp train(58269, 9) test(15675, 9) -11.2351 eval(25080, 9) -11.4752\n",
      "mae np.exp train(79712, 9) test(15675, 9) -6.0597 eval(25080, 9) -5.6501\n",
      "mae np.exp train(64811, 8) test(15670, 8) -119.3648 eval(25073, 8) -156.0878\n",
      "mae np.exp train(61272, 10) test(15675, 10) -16.203 eval(25080, 10) -14.8648\n",
      "mae np.exp train(80484, 7) test(15675, 7) -114.7275 eval(25080, 7) -147.4445\n",
      "mae np.exp train(83310, 5) test(15675, 5) -4.8418 eval(25080, 5) -4.7561\n",
      "mae np.exp train(80301, 5) test(15675, 5) -7.5911 eval(25080, 5) -8.0575\n",
      "mae np.exp train(56215, 10) test(15675, 10) -6.7744 eval(25080, 10) -6.7684\n",
      "mae np.exp train(71577, 11) test(15675, 11) -11.4436 eval(25080, 11) -10.9816\n",
      "mae np.exp train(55592, 11) test(15675, 11) -15.0563 eval(25080, 11) -15.5121\n",
      "mae np.exp train(55743, 11) test(15675, 11) -29.4989 eval(25080, 11) -30.6403\n",
      "mae np.exp train(58565, 11) test(15675, 11) -126.7795 eval(25080, 11) -171.8138\n",
      "mae np.exp train(59247, 6) test(15675, 6) -6.236 eval(25080, 6) -6.414\n",
      "mae np.exp train(80172, 10) test(15675, 10) -7.7451 eval(25080, 10) -8.1291\n",
      "mae np.exp train(73649, 10) test(15675, 10) -7.1923 eval(25080, 10) -7.5079\n",
      "mae np.exp train(80761, 8) test(15670, 8) -9.4173 eval(25073, 8) -9.5004\n",
      "mae np.exp train(74276, 10) test(15675, 10) -4.6025 eval(25080, 10) -4.3854\n",
      "mae np.exp train(64444, 7) test(15675, 7) -37.8178 eval(25080, 7) -43.8421\n",
      "mae np.exp train(80346, 7) test(15675, 7) -14.7108 eval(25080, 7) -15.0801\n",
      "mae np.exp train(79541, 7) test(15675, 7) -65.6 eval(25080, 7) -78.724\n",
      "mae np.exp train(75069, 10) test(15675, 10) -116.3897 eval(25080, 10) -150.646\n",
      "mae np.exp train(79593, 9) test(15675, 9) -9.6696 eval(25080, 9) -9.8539\n",
      "mae np.exp train(60984, 11) test(15675, 11) -114.8338 eval(25080, 11) -150.2656\n",
      "mae np.exp train(79863, 6) test(15675, 6) -18.6961 eval(25080, 6) -18.765\n",
      "mae np.exp train(80180, 8) test(15675, 8) -109.8245 eval(25080, 8) -594.613\n",
      "mae np.exp train(79817, 5) test(15675, 5) -8.0235 eval(25080, 5) -8.3946\n",
      "mae np.exp train(56210, 10) test(15675, 10) -13.5365 eval(25080, 10) -14.435\n",
      "mae np.exp train(79850, 8) test(15675, 8) -13.7632 eval(25080, 8) -14.5903\n",
      "mae np.exp train(67733, 11) test(15675, 11) -15.3863 eval(25080, 11) -15.7883\n",
      "mae np.exp train(77438, 10) test(15670, 10) -67.2367 eval(25073, 10) -78.9193\n",
      "mae np.exp train(81292, 9) test(15675, 9) -109.7803 eval(25080, 9) -592.1709\n",
      "mae np.exp train(55405, 12) test(15675, 12) -109.6918 eval(25080, 12) -586.7761\n",
      "mae np.exp train(81235, 10) test(15675, 10) -32.0588 eval(25080, 10) -32.5684\n",
      "mae np.exp train(80342, 8) test(15675, 8) -109.7114 eval(25080, 8) -588.0338\n",
      "mae np.exp train(80636, 8) test(15675, 8) -4.3462 eval(25080, 8) -4.2317\n",
      "mae np.exp train(70984, 8) test(15670, 8) -109.6668 eval(25073, 8) -585.4606\n",
      "mae np.exp train(59361, 11) test(15675, 11) -6.5655 eval(25080, 11) -6.6338\n",
      "mae np.exp train(61873, 7) test(15675, 7) -4.611 eval(25080, 7) -4.4694\n",
      "mae np.exp train(79640, 6) test(15675, 6) -6.9792 eval(25080, 6) -7.2928\n",
      "mae np.exp train(74820, 8) test(15675, 8) -109.817 eval(25080, 8) -594.208\n",
      "mae np.exp train(62154, 11) test(15675, 11) -109.8245 eval(25080, 11) -594.613\n",
      "mae np.exp train(80055, 8) test(15675, 8) -109.7114 eval(25080, 8) -588.0338\n",
      "mae np.exp train(61125, 9) test(15675, 9) -5.6966 eval(25080, 9) -5.8953\n",
      "mae np.exp train(80615, 8) test(15675, 8) -16.9729 eval(25080, 8) -18.4771\n",
      "mae np.exp train(79980, 7) test(15675, 7) -10.8902 eval(25080, 7) -11.101\n",
      "mae np.exp train(79993, 8) test(15675, 8) -10.7964 eval(25080, 8) -12.0681\n",
      "mae np.exp train(73592, 9) test(15675, 9) -10.3592 eval(25080, 9) -10.2957\n",
      "mae np.exp train(67523, 8) test(15675, 8) -118.7653 eval(25080, 8) -175.1617\n",
      "mae np.exp train(76560, 6) test(15675, 6) -6.6408 eval(25080, 6) -6.1027\n",
      "mae np.exp train(61071, 8) test(15675, 8) -109.7248 eval(25080, 8) -588.8681\n",
      "mae np.exp train(58504, 8) test(15675, 8) -12.0157 eval(25080, 8) -13.5042\n",
      "mae np.exp train(61126, 9) test(15675, 9) -123.4272 eval(25080, 9) -164.4009\n",
      "mae np.exp train(73013, 11) test(15675, 11) -12.4024 eval(25080, 11) -12.6923\n",
      "mae np.exp train(71035, 9) test(15675, 9) -123.2535 eval(25080, 9) -164.0658\n",
      "mae np.exp train(83551, 5) test(15675, 5) -7.6452 eval(25080, 5) -7.5951\n",
      "mae np.exp train(67666, 10) test(15675, 10) -4.479 eval(25080, 10) -4.2164\n",
      "mae np.exp train(55987, 8) test(15675, 8) -12.2039 eval(25080, 8) -12.122\n",
      "mae np.exp train(80174, 8) test(15675, 8) -9.6104 eval(25080, 8) -9.0661\n",
      "mae np.exp train(83684, 7) test(15670, 7) -120.1904 eval(25073, 7) -158.3626\n",
      "mae np.exp train(61912, 8) test(15675, 8) -9.1961 eval(25080, 8) -8.2221\n",
      "mae np.exp train(80491, 7) test(15675, 7) -11.4514 eval(25080, 7) -10.1267\n",
      "mae np.exp train(55221, 13) test(15675, 13) -109.6983 eval(25080, 13) -587.1962\n",
      "mae np.exp train(61602, 10) test(15675, 10) -29.3488 eval(25080, 10) -30.6783\n",
      "mae np.exp train(79411, 9) test(15670, 9) -23.7215 eval(25073, 9) -24.5186\n",
      "mae np.exp train(79963, 8) test(15675, 8) -16.1505 eval(25080, 8) -17.0992\n",
      "mae np.exp train(67697, 9) test(15675, 9) -9.1051 eval(25080, 9) -8.0586\n",
      "mae np.exp train(80272, 9) test(15675, 9) -53.6219 eval(25080, 9) -58.7166\n",
      "mae np.exp train(61439, 11) test(15675, 11) -80.9172 eval(25080, 11) -91.7798\n",
      "mae np.exp train(64376, 10) test(15675, 10) -9.4478 eval(25080, 10) -10.2396\n",
      "mae np.exp train(80027, 9) test(15675, 9) -8.9577 eval(25080, 9) -9.184\n",
      "mae np.exp train(71278, 8) test(15675, 8) -7.6223 eval(25080, 8) -7.6461\n",
      "mae np.exp train(80479, 7) test(15675, 7) -59.6922 eval(25080, 7) -69.8146\n",
      "mae np.exp train(58791, 8) test(15675, 8) -21.1176 eval(25080, 8) -21.5949\n",
      "mae np.exp train(80259, 8) test(15675, 8) -7.9238 eval(25080, 8) -7.1408\n",
      "mae np.exp train(80263, 7) test(15675, 7) -15.1378 eval(25080, 7) -15.97\n",
      "mae np.exp train(82528, 7) test(15675, 7) -8.0826 eval(25080, 7) -8.2517\n",
      "mae np.exp train(65141, 9) test(15675, 9) -21.6555 eval(25080, 9) -24.1039\n",
      "mae np.exp train(81105, 7) test(15675, 7) -15.0157 eval(25080, 7) -15.3727\n",
      "mae np.exp train(80125, 10) test(15675, 10) -5.3548 eval(25080, 10) -5.5988\n",
      "mae np.exp train(80671, 7) test(15675, 7) -14.0611 eval(25080, 7) -15.0295\n",
      "mae np.exp train(80640, 7) test(15675, 7) -6.2374 eval(25080, 7) -6.5116\n",
      "mae np.exp train(49405, 8) test(15675, 8) -119.62 eval(25080, 8) -156.774\n",
      "mae np.exp train(79324, 7) test(15675, 7) -13.5008 eval(25080, 7) -13.8005\n",
      "mae np.exp train(79731, 7) test(15675, 7) -23.7116 eval(25080, 7) -24.6013\n",
      "mae np.exp train(71140, 7) test(15675, 7) -77.5105 eval(25080, 7) -108.8774\n",
      "mae np.exp train(83837, 7) test(15675, 7) -12.3263 eval(25080, 7) -12.3527\n",
      "mae np.exp train(80502, 7) test(15675, 7) -11.5232 eval(25080, 7) -10.0953\n",
      "mae np.exp train(52419, 10) test(15675, 10) -12.0541 eval(25080, 10) -13.2586\n",
      "mae np.exp train(80283, 7) test(15675, 7) -10.0475 eval(25080, 7) -10.1328\n",
      "mae np.exp train(79708, 7) test(15675, 7) -11.9418 eval(25080, 7) -12.0522\n",
      "mae np.exp train(80413, 8) test(15675, 8) -130.1725 eval(25080, 8) -194.1752\n",
      "mae np.exp train(58782, 7) test(15675, 7) -13.1916 eval(25080, 7) -14.4281\n",
      "mae np.exp train(80412, 8) test(15675, 8) -109.8096 eval(25080, 8) -593.8021\n",
      "mae np.exp train(80389, 8) test(15675, 8) -20.3528 eval(25080, 8) -22.7159\n",
      "mae np.exp train(80403, 7) test(15675, 7) -7.2428 eval(25080, 7) -7.3769\n",
      "mae np.exp train(80386, 9) test(15675, 9) -119.4268 eval(25080, 9) -171.3871\n",
      "mae np.exp train(65216, 9) test(15675, 9) -112.8693 eval(25080, 9) -143.7757\n",
      "mae np.exp train(80647, 8) test(15675, 8) -109.88 eval(25080, 8) -597.4261\n",
      "mae np.exp train(82604, 8) test(15675, 8) -7.4736 eval(25080, 8) -7.7243\n",
      "mae np.exp train(79587, 8) test(15675, 8) -18.5144 eval(25080, 8) -18.302\n",
      "mae np.exp train(70918, 7) test(15675, 7) -21.682 eval(25080, 7) -24.475\n",
      "mae np.exp train(62110, 10) test(15675, 10) -5.0216 eval(25080, 10) -5.1353\n",
      "mae np.exp train(64765, 11) test(15675, 11) -116.2227 eval(25080, 11) -156.1129\n",
      "mae np.exp train(65311, 11) test(15675, 11) -8.2833 eval(25080, 11) -7.8483\n",
      "mae np.exp train(52153, 11) test(15675, 11) -132.5208 eval(25080, 11) -183.9428\n",
      "mae np.exp train(80744, 8) test(15675, 8) -8.7045 eval(25080, 8) -7.6526\n",
      "mae np.exp train(68581, 8) test(15675, 8) -114.6358 eval(25080, 8) -154.2336\n",
      "mae np.exp train(80368, 7) test(15675, 7) -9.4644 eval(25080, 7) -8.1046\n",
      "mae np.exp train(61952, 10) test(15675, 10) -10.4017 eval(25080, 10) -11.3161\n",
      "mae np.exp train(62199, 10) test(15675, 10) -33.7232 eval(25080, 10) -31.1898\n",
      "mae np.exp train(80328, 8) test(15675, 8) -119.8541 eval(25080, 8) -157.1779\n",
      "mae np.exp train(80443, 9) test(15670, 9) -8.4873 eval(25073, 9) -7.521\n",
      "mae np.exp train(76756, 11) test(15675, 11) -9.822 eval(25080, 11) -10.5365\n",
      "mae np.exp train(80744, 9) test(15675, 9) -23.8216 eval(25080, 9) -23.9242\n",
      "mae np.exp train(74986, 10) test(15675, 10) -3.767 eval(25080, 10) -3.7558\n",
      "mae np.exp train(79739, 7) test(15675, 7) -109.6794 eval(25080, 7) -585.9334\n",
      "mae np.exp train(67234, 7) test(15675, 7) -15.3248 eval(25080, 7) -16.0016\n",
      "mae np.exp train(52161, 9) test(15670, 9) -8.6647 eval(25073, 9) -9.1521\n",
      "mae np.exp train(79565, 8) test(15675, 8) -113.0884 eval(25080, 8) -144.223\n",
      "mae np.exp train(83759, 6) test(15675, 6) -6.7134 eval(25080, 6) -7.0048\n",
      "mae np.exp train(59125, 11) test(15675, 11) -8.9021 eval(25080, 11) -9.1269\n",
      "mae np.exp train(80792, 7) test(15675, 7) -11.9281 eval(25080, 7) -12.2732\n",
      "mae np.exp train(65438, 10) test(15675, 10) -2.8887 eval(25080, 10) -2.8187\n",
      "mae np.exp train(52506, 8) test(15675, 8) -55.9145 eval(25080, 8) -64.0188\n",
      "mae np.exp train(83340, 8) test(15675, 8) -12.7779 eval(25080, 8) -12.4574\n",
      "mae np.exp train(62065, 12) test(15675, 12) -3.3071 eval(25080, 12) -3.3135\n",
      "mae np.exp train(61816, 9) test(15675, 9) -31.4078 eval(25080, 9) -29.2469\n",
      "mae np.exp train(80963, 6) test(15675, 6) -19.4643 eval(25080, 6) -20.104\n",
      "mae np.exp train(80711, 8) test(15675, 8) -20.0123 eval(25080, 8) -20.4675\n",
      "mae np.exp train(58032, 10) test(15675, 10) -30.9286 eval(25080, 10) -30.4854\n",
      "mae np.exp train(55865, 15) test(15675, 15) -3.7743 eval(25080, 15) -3.6779\n",
      "mae np.exp train(80618, 8) test(15675, 8) -3.4561 eval(25080, 8) -3.4989\n",
      "mae np.exp train(80552, 8) test(15675, 8) -5.7519 eval(25080, 8) -5.3401\n",
      "mae np.exp train(65164, 11) test(15675, 11) -3.3791 eval(25080, 11) -3.3978\n",
      "mae np.exp train(80482, 7) test(15675, 7) -6.3101 eval(25080, 7) -5.7078\n",
      "mae np.exp train(80182, 7) test(15675, 7) -12.6301 eval(25080, 7) -11.2166\n",
      "mae np.exp train(61361, 9) test(15675, 9) -117.9296 eval(25080, 9) -153.8075\n",
      "mae np.exp train(71363, 10) test(15675, 10) -3.2353 eval(25080, 10) -3.2192\n",
      "mae np.exp train(62065, 9) test(15675, 9) -4.0349 eval(25080, 9) -3.8863\n",
      "mae np.exp train(67917, 8) test(15675, 8) -8.4228 eval(25080, 8) -8.853\n",
      "mae np.exp train(82882, 6) test(15675, 6) -5.6616 eval(25080, 6) -5.9571\n",
      "mae np.exp train(64465, 9) test(15675, 9) -47.896 eval(25080, 9) -55.7034\n",
      "mae np.exp train(81180, 7) test(15675, 7) -11.1846 eval(25080, 7) -11.4423\n",
      "mae np.exp train(62572, 9) test(15675, 9) -67.7771 eval(25080, 9) -80.6231\n",
      "mae np.exp train(73640, 7) test(15675, 7) -130.7405 eval(25080, 7) -180.2179\n",
      "mae np.exp train(61906, 11) test(15675, 11) -3.3283 eval(25080, 11) -3.4148\n",
      "mae np.exp train(80232, 8) test(15675, 8) -9.9868 eval(25080, 8) -10.3024\n",
      "mae np.exp train(62065, 11) test(15675, 11) -3.2113 eval(25080, 11) -3.2025\n",
      "mae np.exp train(80640, 6) test(15675, 6) -5.7054 eval(25080, 6) -5.9867\n",
      "mae np.exp train(55249, 10) test(15675, 10) -8.3855 eval(25080, 10) -8.1537\n",
      "mae np.exp train(80154, 7) test(15675, 7) -9.5232 eval(25080, 7) -9.7111\n",
      "mae np.exp train(80389, 7) test(15675, 7) -19.8419 eval(25080, 7) -21.5922\n",
      "mae np.exp train(52503, 8) test(15675, 8) -18.2542 eval(25080, 8) -19.9773\n",
      "mae np.exp train(83235, 7) test(15675, 7) -6.0083 eval(25080, 7) -5.6467\n",
      "mae np.exp train(52509, 9) test(15675, 9) -120.0287 eval(25080, 9) -158.0296\n",
      "mae np.exp train(68186, 7) test(15675, 7) -3.3285 eval(25080, 7) -3.4171\n",
      "mae np.exp train(55987, 14) test(15675, 14) -3.2767 eval(25080, 14) -3.188\n",
      "mae np.exp train(70523, 11) test(15675, 11) -127.6768 eval(25080, 11) -187.3635\n",
      "mae np.exp train(80896, 7) test(15675, 7) -112.2149 eval(25080, 7) -140.95\n",
      "mae np.exp train(81024, 7) test(15675, 7) -19.9615 eval(25080, 7) -21.1959\n",
      "mae np.exp train(62065, 14) test(15675, 14) -3.4177 eval(25080, 14) -3.4537\n",
      "mae np.exp train(50155, 16) test(15670, 16) -109.7805 eval(25073, 16) -592.5299\n",
      "mae np.exp train(80257, 12) test(15675, 12) -6.7794 eval(25080, 12) -6.3625\n",
      "mae np.exp train(80522, 7) test(15675, 7) -10.5051 eval(25080, 7) -10.5646\n",
      "mae np.exp train(80534, 9) test(15670, 9) -4.8289 eval(25073, 9) -4.7271\n",
      "mae np.exp train(80141, 9) test(15675, 9) -10.8433 eval(25080, 9) -11.3448\n",
      "mae np.exp train(84014, 5) test(15675, 5) -6.2837 eval(25080, 5) -5.6308\n",
      "mae np.exp train(80664, 8) test(15675, 8) -109.7522 eval(25080, 8) -590.5263\n",
      "mae np.exp train(68076, 10) test(15675, 10) -6.1634 eval(25080, 10) -6.2418\n",
      "mae np.exp train(79660, 5) test(15675, 5) -126.8644 eval(25080, 5) -171.807\n",
      "mae np.exp train(79924, 7) test(15675, 7) -113.2092 eval(25080, 7) -144.1566\n",
      "mae np.exp train(80119, 10) test(15675, 10) -6.6337 eval(25080, 10) -6.7633\n",
      "mae np.exp train(61983, 17) test(15675, 17) -133.1894 eval(25080, 17) -186.3563\n",
      "mae np.exp train(80561, 18) test(15675, 18) -3.2488 eval(25080, 18) -3.3129\n",
      "mae np.exp train(79786, 6) test(15675, 6) -6.5284 eval(25080, 6) -6.7348\n",
      "mae np.exp train(80074, 10) test(15670, 10) -5.8619 eval(25073, 10) -6.0037\n",
      "mae np.exp train(68811, 8) test(15675, 8) -13.951 eval(25080, 8) -14.3755\n",
      "mae np.exp train(76900, 10) test(15675, 10) -13.5838 eval(25080, 10) -13.8617\n",
      "mae np.exp train(79438, 8) test(15675, 8) -20.6281 eval(25080, 8) -21.5405\n",
      "mae np.exp train(56091, 7) test(15675, 7) -44.7009 eval(25080, 7) -52.3965\n",
      "mae np.exp train(72041, 10) test(15670, 10) -5.1031 eval(25073, 10) -5.237\n",
      "mae np.exp train(83352, 6) test(15675, 6) -109.8096 eval(25080, 6) -593.8021\n",
      "mae np.exp train(52929, 8) test(15675, 8) -58.1879 eval(25080, 8) -66.2247\n",
      "mae np.exp train(61202, 10) test(15675, 10) -15.8734 eval(25080, 10) -15.4762\n",
      "mae np.exp train(55275, 9) test(15670, 9) -11.8195 eval(25073, 9) -12.1882\n",
      "mae np.exp train(74833, 8) test(15675, 8) -109.7592 eval(25080, 8) -590.9387\n",
      "mae np.exp train(79384, 7) test(15675, 7) -7.4643 eval(25080, 7) -7.604\n",
      "mae np.exp train(79587, 8) test(15675, 8) -6.305 eval(25080, 8) -6.73\n",
      "mae np.exp train(67601, 12) test(15675, 12) -10.0395 eval(25080, 12) -9.9085\n",
      "mae np.exp train(80619, 7) test(15675, 7) -3.6545 eval(25080, 7) -3.684\n",
      "mae np.exp train(74451, 12) test(15675, 12) -3.1178 eval(25080, 12) -3.2165\n",
      "mae np.exp train(55585, 18) test(15675, 18) -3.6098 eval(25080, 18) -3.6837\n",
      "mae np.exp train(80405, 7) test(15675, 7) -16.5147 eval(25080, 7) -17.2502\n",
      "mae np.exp train(68123, 7) test(15675, 7) -5.0993 eval(25080, 7) -4.6272\n",
      "mae np.exp train(65214, 8) test(15675, 8) -109.8477 eval(25080, 8) -595.8235\n",
      "mae np.exp train(70626, 10) test(15670, 10) -123.1249 eval(25073, 10) -177.4514\n",
      "mae np.exp train(59416, 10) test(15675, 10) -21.2296 eval(25080, 10) -22.2054\n",
      "mae np.exp train(80620, 6) test(15675, 6) -18.8311 eval(25080, 6) -19.5501\n",
      "mae np.exp train(79755, 9) test(15670, 9) -12.8039 eval(25073, 9) -13.9357\n",
      "mae np.exp train(65153, 9) test(15675, 9) -113.5085 eval(25080, 9) -145.4484\n",
      "mae np.exp train(64212, 8) test(15675, 8) -11.1355 eval(25080, 8) -11.5484\n",
      "mae np.exp train(79534, 9) test(15675, 9) -109.7181 eval(25080, 9) -588.4513\n",
      "mae np.exp train(67813, 11) test(15675, 11) -8.9712 eval(25080, 11) -9.5499\n",
      "mae np.exp train(49655, 21) test(15675, 21) -3.4534 eval(25080, 21) -3.5254\n",
      "mae np.exp train(55245, 8) test(15670, 8) -8.2457 eval(25073, 8) -8.7121\n",
      "mae np.exp train(65012, 9) test(15675, 9) -36.7184 eval(25080, 9) -36.6035\n",
      "mae np.exp train(80144, 7) test(15675, 7) -16.7287 eval(25080, 7) -17.3891\n",
      "mae np.exp train(62056, 18) test(15675, 18) -3.2318 eval(25080, 18) -3.2626\n",
      "mae np.exp train(62111, 13) test(15675, 13) -5.8444 eval(25080, 13) -5.4518\n",
      "mae np.exp train(55865, 19) test(15675, 19) -3.4086 eval(25080, 19) -3.5242\n",
      "mae np.exp train(79911, 7) test(15675, 7) -7.8042 eval(25080, 7) -7.9978\n",
      "mae np.exp train(77180, 10) test(15675, 10) -7.8575 eval(25080, 10) -8.2957\n",
      "mae np.exp train(55468, 8) test(15675, 8) -20.3588 eval(25080, 8) -20.7721\n",
      "mae np.exp train(59322, 7) test(15675, 7) -6.3808 eval(25080, 7) -5.4825\n",
      "mae np.exp train(62237, 10) test(15675, 10) -109.7662 eval(25080, 10) -591.3503\n",
      "mae np.exp train(65262, 10) test(15670, 10) -8.291 eval(25073, 10) -8.2431\n",
      "mae np.exp train(80051, 9) test(15675, 9) -113.7481 eval(25080, 9) -145.3757\n",
      "mae np.exp train(83188, 7) test(15675, 7) -6.5182 eval(25080, 7) -5.8822\n",
      "mae np.exp train(64645, 8) test(15675, 8) -13.0652 eval(25080, 8) -11.9655\n",
      "mae np.exp train(49114, 11) test(15675, 11) -10.5655 eval(25080, 11) -10.7571\n",
      "mae np.exp train(67862, 9) test(15675, 9) -11.5928 eval(25080, 9) -10.7076\n",
      "mae np.exp train(67470, 10) test(15675, 10) -7.0342 eval(25080, 10) -6.656\n",
      "mae np.exp train(73632, 9) test(15675, 9) -5.8015 eval(25080, 9) -6.2665\n",
      "mae np.exp train(49655, 17) test(15675, 17) -15.3379 eval(25080, 17) -14.7517\n",
      "mae np.exp train(83434, 8) test(15675, 8) -10.0025 eval(25080, 8) -9.0307\n",
      "mae np.exp train(68758, 8) test(15670, 8) -121.1112 eval(25073, 8) -160.9701\n",
      "mae np.exp train(80404, 10) test(15675, 10) -120.86 eval(25080, 10) -159.2853\n",
      "mae np.exp train(67140, 6) test(15675, 6) -7.6066 eval(25080, 6) -7.8304\n",
      "mae np.exp train(76372, 8) test(15675, 8) -5.4865 eval(25080, 8) -5.8166\n",
      "mae np.exp train(71325, 9) test(15675, 9) -14.7898 eval(25080, 9) -16.153\n",
      "mae np.exp train(56237, 8) test(15675, 8) -25.5748 eval(25080, 8) -26.0403\n",
      "mae np.exp train(67593, 13) test(15670, 13) -124.4516 eval(25073, 13) -166.3451\n",
      "mae np.exp train(58159, 7) test(15675, 7) -5.7873 eval(25080, 7) -5.9589\n",
      "mae np.exp train(83138, 5) test(15675, 5) -6.7752 eval(25080, 5) -7.1583\n",
      "mae np.exp train(80940, 10) test(15670, 10) -3.1503 eval(25073, 10) -2.9497\n",
      "mae np.exp train(79805, 10) test(15675, 10) -7.2438 eval(25080, 10) -6.9751\n",
      "mae np.exp train(79379, 11) test(15675, 11) -126.8753 eval(25080, 11) -200.8029\n",
      "mae np.exp train(58267, 7) test(15675, 7) -9.0552 eval(25080, 7) -9.2603\n",
      "mae np.exp train(73664, 11) test(15675, 11) -9.8793 eval(25080, 11) -10.4463\n",
      "mae np.exp train(71154, 8) test(15675, 8) -11.0024 eval(25080, 8) -11.0208\n",
      "mae np.exp train(49655, 21) test(15675, 21) -3.331 eval(25080, 21) -3.3995\n",
      "mae np.exp train(49660, 17) test(15675, 17) -4.5113 eval(25080, 17) -4.8241\n",
      "mae np.exp train(55858, 21) test(15675, 21) -3.3753 eval(25080, 21) -3.4412\n",
      "mae np.exp train(80113, 9) test(15675, 9) -5.9095 eval(25080, 9) -5.3208\n",
      "mae np.exp train(49655, 21) test(15675, 21) -3.3284 eval(25080, 21) -3.3913\n",
      "mae np.exp train(52125, 7) test(15675, 7) -15.4228 eval(25080, 7) -16.5737\n",
      "mae np.exp train(61573, 9) test(15675, 9) -13.625 eval(25080, 9) -14.4158\n",
      "mae np.exp train(64334, 9) test(15675, 9) -8.7029 eval(25080, 9) -9.2566\n",
      "mae np.exp train(49136, 18) test(15675, 18) -3.9937 eval(25080, 18) -4.1847\n",
      "mae np.exp train(68679, 18) test(15675, 18) -2.8379 eval(25080, 18) -2.8281\n",
      "mae np.exp train(80457, 6) test(15675, 6) -8.2519 eval(25080, 6) -7.984\n",
      "mae np.exp train(68371, 8) test(15675, 8) -109.7453 eval(25080, 8) -590.113\n",
      "mae np.exp train(79438, 11) test(15675, 11) -8.616 eval(25080, 11) -8.9643\n",
      "mae np.exp train(80214, 7) test(15675, 7) -42.2548 eval(25080, 7) -42.6717\n",
      "mae np.exp train(55139, 10) test(15675, 10) -6.3342 eval(25080, 10) -6.2373\n",
      "mae np.exp train(56173, 7) test(15675, 7) -17.8248 eval(25080, 7) -18.6565\n",
      "mae np.exp train(68052, 11) test(15675, 11) -121.3748 eval(25080, 11) -183.0241\n",
      "mae np.exp train(58732, 7) test(15675, 7) -46.6743 eval(25080, 7) -53.9676\n",
      "mae np.exp train(62005, 9) test(15675, 9) -7.3348 eval(25080, 9) -7.508\n",
      "mae np.exp train(49655, 21) test(15675, 21) -3.3799 eval(25080, 21) -3.4531\n",
      "mae np.exp train(58927, 8) test(15675, 8) -15.4875 eval(25080, 8) -15.9063\n",
      "mae np.exp train(79642, 9) test(15675, 9) -131.8224 eval(25080, 9) -182.6125\n",
      "mae np.exp train(76425, 8) test(15675, 8) -4.8856 eval(25080, 8) -5.1183\n",
      "mae np.exp train(80593, 7) test(15675, 7) -117.4392 eval(25080, 7) -176.3463\n",
      "mae np.exp train(48672, 22) test(15675, 22) -4.6824 eval(25080, 22) -4.9713\n",
      "mae np.exp train(80818, 5) test(15675, 5) -10.6543 eval(25080, 5) -11.3227\n",
      "mae np.exp train(58265, 10) test(15675, 10) -13.1681 eval(25080, 10) -12.4539\n",
      "mae np.exp train(64817, 10) test(15675, 10) -127.838 eval(25080, 10) -184.0221\n",
      "mae np.exp train(73348, 9) test(15675, 9) -8.2706 eval(25080, 9) -8.7526\n",
      "mae np.exp train(74381, 8) test(15675, 8) -35.9129 eval(25080, 8) -40.0078\n",
      "mae np.exp train(64358, 8) test(15675, 8) -6.4538 eval(25080, 8) -5.9214\n",
      "mae np.exp train(79752, 10) test(15675, 10) -16.8576 eval(25080, 10) -18.367\n",
      "mae np.exp train(68441, 8) test(15675, 8) -10.6692 eval(25080, 8) -11.4189\n",
      "mae np.exp train(62070, 7) test(15675, 7) -109.8477 eval(25080, 7) -595.8235\n",
      "mae np.exp train(79927, 7) test(15675, 7) -17.9969 eval(25080, 7) -18.4769\n",
      "mae np.exp train(77498, 9) test(15675, 9) -7.3982 eval(25080, 9) -7.6899\n",
      "mae np.exp train(79755, 6) test(15675, 6) -128.5574 eval(25080, 6) -175.2242\n",
      "mae np.exp train(49655, 22) test(15675, 22) -3.4495 eval(25080, 22) -3.5214\n",
      "mae np.exp train(64206, 7) test(15675, 7) -118.6573 eval(25080, 7) -154.7047\n",
      "mae np.exp train(83675, 6) test(15675, 6) -109.7181 eval(25080, 6) -588.4513\n",
      "mae np.exp train(79333, 6) test(15675, 6) -9.6115 eval(25080, 6) -8.806\n",
      "mae np.exp train(71965, 14) test(15675, 14) -6.4239 eval(25080, 14) -6.5994\n",
      "mae np.exp train(80172, 11) test(15675, 11) -6.5255 eval(25080, 11) -6.7745\n",
      "mae np.exp train(70947, 7) test(15670, 7) -29.8936 eval(25073, 7) -32.3181\n",
      "mae np.exp train(62404, 9) test(15675, 9) -5.7032 eval(25080, 9) -5.9636\n",
      "mae np.exp train(51716, 16) test(15675, 16) -84.6826 eval(25080, 16) -102.4182\n",
      "mae np.exp train(83199, 7) test(15675, 7) -12.956 eval(25080, 7) -12.999\n",
      "mae np.exp train(50155, 22) test(15670, 22) -2.636 eval(25073, 22) -2.5371\n",
      "mae np.exp train(70949, 7) test(15675, 7) -4.6 eval(25080, 7) -4.6173\n",
      "mae np.exp train(58392, 17) test(15675, 17) -4.0307 eval(25080, 17) -4.2262\n",
      "mae np.exp train(65009, 10) test(15675, 10) -122.1759 eval(25080, 10) -174.4783\n",
      "mae np.exp train(83136, 5) test(15675, 5) -21.9154 eval(25080, 5) -23.1006\n",
      "mae np.exp train(49764, 20) test(15675, 20) -3.0989 eval(25080, 20) -3.1271\n",
      "mae np.exp train(58571, 8) test(15675, 8) -38.7839 eval(25080, 8) -41.0794\n",
      "mae np.exp train(58470, 12) test(15675, 12) -15.4304 eval(25080, 12) -16.7618\n",
      "mae np.exp train(62361, 11) test(15675, 11) -116.348 eval(25080, 11) -150.8011\n",
      "mae np.exp train(82619, 8) test(15675, 8) -116.4761 eval(25080, 8) -150.7504\n",
      "mae np.exp train(79657, 9) test(15675, 9) -11.1324 eval(25080, 9) -11.9005\n",
      "mae np.exp train(80196, 6) test(15675, 6) -4.5923 eval(25080, 6) -4.5039\n",
      "mae np.exp train(64696, 9) test(15675, 9) -22.6933 eval(25080, 9) -22.1547\n",
      "mae np.exp train(64618, 9) test(15675, 9) -8.3178 eval(25080, 9) -8.4294\n",
      "mae np.exp train(49386, 11) test(15675, 11) -9.6907 eval(25080, 11) -9.8179\n",
      "mae np.exp train(79317, 9) test(15670, 9) -111.1719 eval(25073, 9) -161.5701\n",
      "mae np.exp train(73973, 9) test(15675, 9) -5.3858 eval(25080, 9) -5.4907\n",
      "mae np.exp train(56088, 11) test(15675, 11) -4.1889 eval(25080, 11) -4.2314\n",
      "mae np.exp train(68791, 11) test(15670, 11) -119.3257 eval(25073, 11) -156.5816\n",
      "mae np.exp train(80112, 9) test(15675, 9) -109.7453 eval(25080, 9) -590.113\n",
      "mae np.exp train(56056, 10) test(15675, 10) -121.1107 eval(25080, 10) -160.5908\n",
      "mae np.exp train(61687, 10) test(15675, 10) -7.4353 eval(25080, 10) -7.8698\n",
      "mae np.exp train(79846, 7) test(15670, 7) -8.7182 eval(25073, 7) -8.8416\n",
      "mae np.exp train(55534, 19) test(15675, 19) -14.6871 eval(25080, 19) -16.8547\n",
      "mae np.exp train(52412, 13) test(15675, 13) -62.5326 eval(25080, 13) -73.5327\n",
      "mae np.exp train(80497, 7) test(15675, 7) -6.4994 eval(25080, 7) -5.6973\n",
      "mae np.exp train(74446, 8) test(15675, 8) -8.3111 eval(25080, 8) -8.5943\n",
      "mae np.exp train(66927, 14) test(15675, 14) -129.8475 eval(25080, 14) -178.1005\n",
      "mae np.exp train(56423, 19) test(15675, 19) -109.7948 eval(25080, 19) -592.9881\n",
      "mae np.exp train(64377, 8) test(15675, 8) -109.7803 eval(25080, 8) -592.1709\n",
      "mae np.exp train(68651, 9) test(15675, 9) -6.236 eval(25080, 9) -5.9266\n",
      "mae np.exp train(67803, 9) test(15675, 9) -7.8516 eval(25080, 9) -8.3802\n",
      "mae np.exp train(65049, 12) test(15675, 12) -15.1367 eval(25080, 12) -16.356\n",
      "mae np.exp train(48672, 17) test(15675, 17) -109.7181 eval(25080, 17) -588.4513\n",
      "mae np.exp train(52393, 9) test(15675, 9) -15.5328 eval(25080, 9) -16.6711\n",
      "mae np.exp train(80249, 8) test(15675, 8) -19.5569 eval(25080, 8) -20.0838\n",
      "mae np.exp train(70652, 10) test(15675, 10) -24.1409 eval(25080, 10) -25.8171\n",
      "mae np.exp train(71452, 9) test(15675, 9) -12.3395 eval(25080, 9) -13.1827\n",
      "mae np.exp train(81417, 8) test(15675, 8) -109.7875 eval(25080, 8) -592.58\n",
      "mae np.exp train(80859, 8) test(15675, 8) -9.7446 eval(25080, 8) -9.8112\n",
      "mae np.exp train(68198, 9) test(15675, 9) -14.2735 eval(25080, 9) -14.2364\n",
      "mae np.exp train(83692, 5) test(15675, 5) -9.4837 eval(25080, 5) -10.0156\n",
      "mae np.exp train(64291, 6) test(15670, 6) -10.0858 eval(25073, 6) -10.4008\n",
      "mae np.exp train(81003, 6) test(15675, 6) -55.6431 eval(25080, 6) -66.2938\n",
      "mae np.exp train(80453, 10) test(15675, 10) -5.0619 eval(25080, 10) -4.8949\n",
      "mae np.exp train(80786, 12) test(15675, 12) -23.2503 eval(25080, 12) -26.0128\n",
      "mae np.exp train(80295, 8) test(15675, 8) -11.1562 eval(25080, 8) -11.9348\n",
      "mae np.exp train(61911, 9) test(15675, 9) -128.1044 eval(25080, 9) -187.9295\n",
      "mae np.exp train(79555, 6) test(15675, 6) -30.048 eval(25080, 6) -33.8831\n",
      "mae np.exp train(79541, 7) test(15675, 7) -13.3382 eval(25080, 7) -13.97\n",
      "mae np.exp train(70078, 8) test(15675, 8) -11.4961 eval(25080, 8) -11.7486\n",
      "mae np.exp train(49851, 18) test(15675, 18) -4.1942 eval(25080, 18) -4.0901\n",
      "mae np.exp train(80103, 8) test(15675, 8) -109.6611 eval(25080, 8) -584.6628\n",
      "mae np.exp train(80669, 9) test(15675, 9) -8.8172 eval(25080, 9) -9.2036\n",
      "mae np.exp train(64920, 7) test(15675, 7) -128.0164 eval(25080, 7) -174.3401\n",
      "mae np.exp train(76939, 8) test(15675, 8) -22.733 eval(25080, 8) -23.8256\n",
      "mae np.exp train(77457, 12) test(15675, 12) -7.4785 eval(25080, 12) -7.5985\n",
      "mae np.exp train(76731, 8) test(15675, 8) -110.7314 eval(25080, 8) -157.72\n",
      "mae np.exp train(67904, 10) test(15675, 10) -130.0774 eval(25080, 10) -178.8607\n",
      "mae np.exp train(62315, 10) test(15675, 10) -117.1841 eval(25080, 10) -152.1685\n",
      "mae np.exp train(74335, 10) test(15675, 10) -51.2335 eval(25080, 10) -58.3166\n",
      "mae np.exp train(58477, 11) test(15675, 11) -12.0036 eval(25080, 11) -12.7368\n",
      "mae np.exp train(58242, 9) test(15675, 9) -6.0137 eval(25080, 9) -5.6975\n",
      "mae np.exp train(52861, 8) test(15675, 8) -9.694 eval(25080, 8) -9.1409\n",
      "mae np.exp train(80935, 8) test(15675, 8) -64.5687 eval(25080, 8) -75.8038\n",
      "mae np.exp train(55912, 8) test(15675, 8) -109.7522 eval(25080, 8) -590.5263\n",
      "mae np.exp train(71392, 5) test(15675, 5) -120.5534 eval(25080, 5) -158.7386\n",
      "mae np.exp train(76913, 9) test(15670, 9) -4.7074 eval(25073, 9) -5.2104\n",
      "mae np.exp train(62080, 8) test(15675, 8) -18.0177 eval(25080, 8) -18.7538\n",
      "mae np.exp train(79488, 7) test(15675, 7) -10.8979 eval(25080, 7) -11.4125\n",
      "mae np.exp train(61547, 11) test(15675, 11) -18.3907 eval(25080, 11) -17.517\n",
      "mae np.exp train(80214, 8) test(15675, 8) -115.9849 eval(25080, 8) -149.6018\n",
      "mae np.exp train(58803, 8) test(15675, 8) -128.4288 eval(25080, 8) -175.3807\n",
      "mae np.exp train(83033, 8) test(15675, 8) -12.4191 eval(25080, 8) -13.5379\n",
      "mae np.exp train(79781, 8) test(15675, 8) -19.4517 eval(25080, 8) -18.9864\n",
      "mae np.exp train(80636, 8) test(15670, 8) -117.3646 eval(25073, 8) -185.1592\n",
      "mae np.exp train(55980, 17) test(15675, 17) -3.0756 eval(25080, 17) -3.0239\n",
      "mae np.exp train(67665, 9) test(15675, 9) -38.7941 eval(25080, 9) -45.2501\n",
      "mae np.exp train(65180, 11) test(15670, 11) -109.8403 eval(25073, 11) -595.7735\n",
      "mae np.exp train(65154, 16) test(15675, 16) -3.267 eval(25080, 16) -3.3362\n",
      "mae np.exp train(58971, 8) test(15675, 8) -109.8477 eval(25080, 8) -595.8235\n",
      "mae np.exp train(58623, 9) test(15675, 9) -27.6188 eval(25080, 9) -29.4783\n",
      "mae np.exp train(59423, 10) test(15675, 10) -128.201 eval(25080, 10) -173.6213\n",
      "mae np.exp train(62254, 13) test(15675, 13) -3.0525 eval(25080, 13) -3.0306\n",
      "mae np.exp train(80285, 7) test(15675, 7) -16.5685 eval(25080, 7) -16.5715\n",
      "mae np.exp train(61608, 9) test(15675, 9) -34.0406 eval(25080, 9) -33.5001\n",
      "mae np.exp train(52911, 9) test(15675, 9) -115.7671 eval(25080, 9) -149.3319\n",
      "mae np.exp train(80488, 8) test(15675, 8) -10.6399 eval(25080, 8) -9.8894\n",
      "mae np.exp train(79834, 8) test(15675, 8) -20.4058 eval(25080, 8) -21.1325\n",
      "mae np.exp train(65279, 11) test(15675, 11) -8.7643 eval(25080, 11) -7.9954\n",
      "mae np.exp train(52216, 11) test(15675, 11) -109.655 eval(25080, 11) -584.2375\n",
      "mae np.exp train(80576, 9) test(15675, 9) -8.5839 eval(25080, 9) -8.7172\n",
      "mae np.exp train(58839, 9) test(15675, 9) -109.8096 eval(25080, 9) -593.8021\n",
      "mae np.exp train(67746, 9) test(15675, 9) -109.7181 eval(25080, 9) -588.4513\n",
      "mae np.exp train(64836, 7) test(15675, 7) -5.8718 eval(25080, 7) -6.172\n",
      "mae np.exp train(55452, 9) test(15675, 9) -8.516 eval(25080, 9) -9.4259\n",
      "mae np.exp train(64476, 8) test(15675, 8) -6.6567 eval(25080, 8) -6.7079\n",
      "mae np.exp train(79963, 10) test(15675, 10) -7.3545 eval(25080, 10) -7.3139\n",
      "mae np.exp train(79439, 8) test(15675, 8) -17.042 eval(25080, 8) -17.7624\n",
      "mae np.exp train(82525, 8) test(15675, 8) -111.7403 eval(25080, 8) -163.9459\n",
      "mae np.exp train(77401, 8) test(15675, 8) -4.5483 eval(25080, 8) -4.546\n",
      "mae np.exp train(74013, 10) test(15675, 10) -115.3485 eval(25080, 10) -148.6044\n",
      "mae np.exp train(79868, 7) test(15675, 7) -9.0125 eval(25080, 7) -9.2015\n",
      "mae np.exp train(55639, 10) test(15675, 10) -6.42 eval(25080, 10) -6.5538\n",
      "mae np.exp train(80376, 7) test(15675, 7) -15.3874 eval(25080, 7) -14.8204\n",
      "mae np.exp train(73760, 8) test(15675, 8) -113.905 eval(25080, 8) -152.2481\n",
      "mae np.exp train(78016, 10) test(15675, 10) -134.1294 eval(25080, 10) -187.9703\n",
      "mae np.exp train(83251, 6) test(15675, 6) -6.9116 eval(25080, 6) -6.9366\n",
      "mae np.exp train(67667, 11) test(15675, 11) -109.7048 eval(25080, 11) -587.6154\n",
      "mae np.exp train(81227, 9) test(15675, 9) -11.8336 eval(25080, 9) -11.898\n",
      "mae np.exp train(81199, 8) test(15675, 8) -11.316 eval(25080, 8) -12.3005\n",
      "mae np.exp train(55610, 12) test(15675, 12) -128.804 eval(25080, 12) -175.9131\n",
      "mae np.exp train(80419, 10) test(15675, 10) -11.1823 eval(25080, 10) -11.4738\n",
      "mae np.exp train(83891, 6) test(15675, 6) -7.0028 eval(25080, 6) -7.064\n",
      "mae np.exp train(52499, 7) test(15675, 7) -6.1387 eval(25080, 7) -6.4014\n",
      "mae np.exp train(65131, 9) test(15675, 9) -110.0277 eval(25080, 9) -161.2365\n",
      "mae np.exp train(82481, 6) test(15675, 6) -106.6385 eval(25080, 6) -150.2956\n",
      "mae np.exp train(73771, 9) test(15675, 9) -122.2097 eval(25080, 9) -161.694\n",
      "mae np.exp train(80380, 7) test(15675, 7) -8.4969 eval(25080, 7) -8.444\n",
      "mae np.exp train(79837, 6) test(15675, 6) -8.347 eval(25080, 6) -8.7249\n",
      "mae np.exp train(80604, 7) test(15675, 7) -11.6857 eval(25080, 7) -12.1978\n",
      "mae np.exp train(61890, 10) test(15675, 10) -6.9866 eval(25080, 10) -7.673\n",
      "mae np.exp train(83668, 4) test(15675, 4) -14.8126 eval(25080, 4) -14.4493\n",
      "mae np.exp train(83363, 7) test(15675, 7) -121.3981 eval(25080, 7) -160.1559\n",
      "mae np.exp train(79407, 7) test(15675, 7) -51.9447 eval(25080, 7) -58.6879\n",
      "mae np.exp train(62056, 12) test(15675, 12) -3.7339 eval(25080, 12) -3.7418\n",
      "mae np.exp train(48790, 9) test(15670, 9) -131.2984 eval(25073, 9) -181.4449\n",
      "mae np.exp train(62053, 8) test(15675, 8) -113.7939 eval(25080, 8) -163.4109\n",
      "mae np.exp train(70744, 8) test(15675, 8) -109.7453 eval(25080, 8) -590.113\n",
      "mae np.exp train(76513, 8) test(15675, 8) -122.2349 eval(25080, 8) -161.878\n",
      "mae np.exp train(53106, 12) test(15675, 12) -7.436 eval(25080, 12) -7.174\n",
      "mae np.exp train(67293, 11) test(15675, 11) -109.7181 eval(25080, 11) -588.4513\n",
      "mae np.exp train(80597, 10) test(15670, 10) -123.2023 eval(25073, 10) -164.1494\n",
      "mae np.exp train(77835, 9) test(15675, 9) -6.5364 eval(25080, 9) -7.2676\n",
      "mae np.exp train(64553, 8) test(15675, 8) -10.7171 eval(25080, 8) -9.0621\n",
      "mae np.exp train(70906, 6) test(15675, 6) -17.0176 eval(25080, 6) -15.8051\n",
      "mae np.exp train(80521, 7) test(15675, 7) -13.2261 eval(25080, 7) -13.7268\n",
      "mae np.exp train(80190, 7) test(15675, 7) -8.8975 eval(25080, 7) -8.9831\n",
      "mae np.exp train(81117, 8) test(15675, 8) -31.8576 eval(25080, 8) -36.0045\n",
      "mae np.exp train(80139, 8) test(15670, 8) -10.7223 eval(25073, 8) -11.1946\n",
      "mae np.exp train(64440, 13) test(15675, 13) -127.3122 eval(25080, 13) -171.3269\n",
      "mae np.exp train(83750, 8) test(15675, 8) -8.1162 eval(25080, 8) -8.2812\n",
      "mae np.exp train(83768, 6) test(15675, 6) -109.7248 eval(25080, 6) -588.8681\n",
      "mae np.exp train(65040, 8) test(15675, 8) -13.3579 eval(25080, 8) -14.9267\n",
      "mae np.exp train(53024, 12) test(15675, 12) -30.2686 eval(25080, 12) -32.801\n",
      "mae np.exp train(80196, 9) test(15670, 9) -107.2462 eval(25073, 9) -138.3651\n",
      "mae np.exp train(80395, 8) test(15675, 8) -20.8367 eval(25080, 8) -21.4228\n",
      "mae np.exp train(56084, 17) test(15675, 17) -3.0827 eval(25080, 17) -3.0741\n",
      "mae np.exp train(64285, 10) test(15670, 10) -126.1439 eval(25073, 10) -170.1997\n",
      "mae np.exp train(49655, 19) test(15675, 19) -3.4101 eval(25080, 19) -3.4839\n",
      "mae np.exp train(64590, 10) test(15675, 10) -5.5637 eval(25080, 10) -5.7607\n",
      "mae np.exp train(80728, 7) test(15675, 7) -6.7021 eval(25080, 7) -5.9485\n",
      "mae np.exp train(71913, 9) test(15675, 9) -8.9019 eval(25080, 9) -9.2378\n",
      "mae np.exp train(74581, 8) test(15670, 8) -128.391 eval(25073, 8) -175.1637\n",
      "mae np.exp train(79876, 9) test(15675, 9) -14.1142 eval(25080, 9) -13.9218\n",
      "mae np.exp train(74730, 10) test(15670, 10) -39.5916 eval(25073, 10) -44.8508\n",
      "mae np.exp train(79762, 8) test(15675, 8) -128.3715 eval(25080, 8) -174.7326\n",
      "mae np.exp train(64218, 7) test(15675, 7) -11.7314 eval(25080, 7) -12.1378\n",
      "mae np.exp train(79406, 7) test(15675, 7) -20.4047 eval(25080, 7) -19.8074\n",
      "mae np.exp train(74983, 10) test(15675, 10) -5.0288 eval(25080, 10) -4.6493\n",
      "mae np.exp train(54890, 8) test(15675, 8) -8.4186 eval(25080, 8) -8.1922\n",
      "mae np.exp train(58451, 10) test(15675, 10) -3.7786 eval(25080, 10) -3.8367\n",
      "mae np.exp train(79802, 7) test(15675, 7) -24.0425 eval(25080, 7) -23.9619\n",
      "mae np.exp train(55989, 6) test(15675, 6) -129.213 eval(25080, 6) -177.5834\n",
      "mae np.exp train(79783, 8) test(15675, 8) -7.0145 eval(25080, 8) -6.6004\n",
      "mae np.exp train(55421, 10) test(15675, 10) -8.2558 eval(25080, 10) -8.4722\n",
      "mae np.exp train(57872, 14) test(15675, 14) -5.011 eval(25080, 14) -5.0906\n",
      "mae np.exp train(49983, 16) test(15675, 16) -2.8483 eval(25080, 16) -2.8245\n",
      "mae np.exp train(77152, 8) test(15675, 8) -22.8057 eval(25080, 8) -23.3694\n",
      "mae np.exp train(68423, 9) test(15675, 9) -9.6059 eval(25080, 9) -9.7503\n",
      "mae np.exp train(80434, 8) test(15675, 8) -5.5786 eval(25080, 8) -4.8861\n",
      "mae np.exp train(55471, 11) test(15675, 11) -111.1823 eval(25080, 11) -161.0752\n",
      "mae np.exp train(61223, 12) test(15675, 12) -10.639 eval(25080, 12) -10.9227\n",
      "mae np.exp train(80897, 8) test(15675, 8) -6.7817 eval(25080, 8) -7.156\n",
      "mae np.exp train(61615, 11) test(15670, 11) -67.4575 eval(25073, 11) -73.7068\n",
      "mae np.exp train(73010, 13) test(15675, 13) -5.972 eval(25080, 13) -6.2801\n",
      "mae np.exp train(80316, 7) test(15675, 7) -121.1139 eval(25080, 7) -179.3494\n",
      "mae np.exp train(64329, 10) test(15675, 10) -6.3984 eval(25080, 10) -5.7464\n",
      "mae np.exp train(49803, 16) test(15675, 16) -7.2489 eval(25080, 16) -7.3036\n",
      "mae np.exp train(80618, 10) test(15675, 10) -11.4818 eval(25080, 10) -11.3572\n",
      "mae np.exp train(58994, 9) test(15675, 9) -109.8556 eval(25080, 9) -596.2254\n",
      "mae np.exp train(67804, 8) test(15675, 8) -9.5476 eval(25080, 8) -10.0371\n",
      "mae np.exp train(83257, 8) test(15675, 8) -5.6133 eval(25080, 8) -5.599\n",
      "mae np.exp train(64987, 15) test(15675, 15) -3.3578 eval(25080, 15) -3.4397\n",
      "mae np.exp train(80434, 8) test(15675, 8) -7.3972 eval(25080, 8) -7.3997\n",
      "mae np.exp train(80128, 10) test(15675, 10) -21.0384 eval(25080, 10) -21.349\n",
      "mae np.exp train(81061, 7) test(15675, 7) -8.2406 eval(25080, 7) -7.6482\n",
      "mae np.exp train(77327, 8) test(15675, 8) -109.8096 eval(25080, 8) -593.8021\n",
      "mae np.exp train(65300, 12) test(15675, 12) -7.1544 eval(25080, 12) -6.7964\n",
      "mae np.exp train(62396, 7) test(15675, 7) -10.6811 eval(25080, 7) -9.2797\n",
      "mae np.exp train(83539, 8) test(15675, 8) -28.1507 eval(25080, 8) -28.0853\n",
      "mae np.exp train(56311, 19) test(15675, 19) -2.8028 eval(25080, 19) -2.6836\n",
      "mae np.exp train(80392, 9) test(15675, 9) -5.9799 eval(25080, 9) -6.1885\n",
      "mae np.exp train(79591, 8) test(15675, 8) -123.1221 eval(25080, 8) -164.382\n",
      "mae np.exp train(54997, 11) test(15675, 11) -18.4321 eval(25080, 11) -18.9283\n",
      "mae np.exp train(58130, 11) test(15675, 11) -124.3317 eval(25080, 11) -191.6547\n",
      "mae np.exp train(80338, 8) test(15675, 8) -8.5652 eval(25080, 8) -8.504\n",
      "mae np.exp train(83390, 7) test(15675, 7) -16.1664 eval(25080, 7) -16.199\n",
      "mae np.exp train(80682, 7) test(15675, 7) -129.054 eval(25080, 7) -185.2155\n",
      "mae np.exp train(70392, 9) test(15675, 9) -128.726 eval(25080, 9) -175.6492\n",
      "mae np.exp train(80863, 9) test(15675, 9) -5.1005 eval(25080, 9) -5.2784\n",
      "mae np.exp train(74527, 9) test(15675, 9) -7.2734 eval(25080, 9) -6.7544\n",
      "mae np.exp train(70506, 9) test(15675, 9) -20.5703 eval(25080, 9) -22.4656\n",
      "mae np.exp train(80890, 6) test(15675, 6) -123.6378 eval(25080, 6) -186.2897\n",
      "mae np.exp train(65307, 10) test(15675, 10) -127.6976 eval(25080, 10) -174.1881\n",
      "mae np.exp train(55228, 9) test(15675, 9) -5.1522 eval(25080, 9) -5.3667\n",
      "mae np.exp train(78043, 9) test(15670, 9) -113.8741 eval(25073, 9) -145.817\n",
      "mae np.exp train(79748, 7) test(15675, 7) -8.8903 eval(25080, 7) -7.6221\n",
      "mae np.exp train(80992, 8) test(15675, 8) -109.8096 eval(25080, 8) -593.8021\n",
      "mae np.exp train(79547, 6) test(15675, 6) -30.9168 eval(25080, 6) -30.478\n",
      "mae np.exp train(55820, 9) test(15675, 9) -11.4548 eval(25080, 9) -11.457\n",
      "mae np.exp train(71342, 10) test(15675, 10) -21.4038 eval(25080, 10) -22.3908\n",
      "mae np.exp train(83192, 8) test(15675, 8) -12.1427 eval(25080, 8) -12.6181\n",
      "mae np.exp train(77085, 8) test(15675, 8) -7.153 eval(25080, 8) -7.1442\n",
      "mae np.exp train(80460, 9) test(15675, 9) -10.9285 eval(25080, 9) -11.3789\n",
      "mae np.exp train(62174, 8) test(15675, 8) -77.6077 eval(25080, 8) -103.8708\n",
      "mae np.exp train(58256, 8) test(15675, 8) -126.0035 eval(25080, 8) -169.6239\n",
      "mae np.exp train(58975, 18) test(15675, 18) -3.0735 eval(25080, 18) -3.0414\n",
      "mae np.exp train(79943, 8) test(15670, 8) -7.3692 eval(25073, 8) -6.7285\n",
      "mae np.exp train(49655, 19) test(15675, 19) -3.44 eval(25080, 19) -3.5069\n",
      "mae np.exp train(49715, 18) test(15675, 18) -3.1705 eval(25080, 18) -3.2149\n",
      "mae np.exp train(79944, 9) test(15675, 9) -126.1403 eval(25080, 9) -170.0596\n",
      "mae np.exp train(52922, 10) test(15675, 10) -11.3389 eval(25080, 10) -11.4571\n",
      "mae np.exp train(56034, 16) test(15675, 16) -3.0334 eval(25080, 16) -3.0159\n",
      "mae np.exp train(83844, 7) test(15675, 7) -25.634 eval(25080, 7) -25.4676\n",
      "mae np.exp train(77250, 8) test(15670, 8) -109.6917 eval(25073, 8) -587.1462\n",
      "mae np.exp train(49655, 18) test(15675, 18) -3.4467 eval(25080, 18) -3.514\n",
      "mae np.exp train(55088, 9) test(15675, 9) -14.2687 eval(25080, 9) -14.2145\n",
      "mae np.exp train(80249, 7) test(15675, 7) -8.1057 eval(25080, 7) -8.2844\n",
      "mae np.exp train(55265, 21) test(15675, 21) -3.9216 eval(25080, 21) -4.0534\n",
      "mae np.exp train(80372, 8) test(15675, 8) -113.9324 eval(25080, 8) -145.8543\n",
      "mae np.exp train(64436, 10) test(15675, 10) -6.0211 eval(25080, 10) -5.3606\n",
      "mae np.exp train(58548, 8) test(15675, 8) -122.2766 eval(25080, 8) -162.1431\n",
      "mae np.exp train(68463, 14) test(15675, 14) -12.0685 eval(25080, 14) -12.4256\n",
      "mae np.exp train(80360, 6) test(15675, 6) -6.6346 eval(25080, 6) -6.9117\n",
      "mae np.exp train(77617, 9) test(15675, 9) -36.5969 eval(25080, 9) -39.7672\n",
      "mae np.exp train(80380, 4) test(15675, 4) -129.2694 eval(25080, 4) -176.9613\n",
      "mae np.exp train(80366, 9) test(15675, 9) -44.7484 eval(25080, 9) -51.2029\n",
      "mae np.exp train(64625, 10) test(15675, 10) -7.4816 eval(25080, 10) -7.6667\n",
      "mae np.exp train(61406, 7) test(15675, 7) -17.6808 eval(25080, 7) -19.7078\n",
      "mae np.exp train(80196, 10) test(15675, 10) -8.922 eval(25080, 10) -9.3522\n",
      "mae np.exp train(62132, 13) test(15675, 13) -3.018 eval(25080, 13) -3.0481\n",
      "mae np.exp train(80726, 6) test(15675, 6) -5.534 eval(25080, 6) -5.6019\n",
      "mae np.exp train(70980, 10) test(15675, 10) -23.8951 eval(25080, 10) -25.0271\n",
      "mae np.exp train(67582, 11) test(15670, 11) -7.5611 eval(25073, 11) -7.0259\n",
      "mae np.exp train(64270, 11) test(15675, 11) -7.6652 eval(25080, 11) -7.4387\n",
      "mae np.exp train(65269, 7) test(15675, 7) -21.199 eval(25080, 7) -23.7865\n",
      "mae np.exp train(77057, 9) test(15675, 9) -12.2473 eval(25080, 9) -12.3587\n",
      "mae np.exp train(79449, 8) test(15675, 8) -111.2619 eval(25080, 8) -166.1004\n",
      "mae np.exp train(79677, 7) test(15675, 7) -6.4552 eval(25080, 7) -5.5242\n",
      "mae np.exp train(79312, 6) test(15675, 6) -39.5067 eval(25080, 6) -37.6911\n",
      "mae np.exp train(80360, 6) test(15675, 6) -132.8275 eval(25080, 6) -185.1908\n",
      "mae np.exp train(80470, 7) test(15675, 7) -12.5754 eval(25080, 7) -12.4258\n",
      "mae np.exp train(53114, 8) test(15675, 8) -110.8447 eval(25080, 8) -145.3348\n",
      "mae np.exp train(70535, 10) test(15675, 10) -7.2003 eval(25080, 10) -7.4791\n",
      "mae np.exp train(80488, 5) test(15675, 5) -11.2198 eval(25080, 5) -11.3176\n",
      "mae np.exp train(80434, 7) test(15675, 7) -17.2753 eval(25080, 7) -17.7326\n",
      "mae np.exp train(55251, 9) test(15675, 9) -31.3477 eval(25080, 9) -33.5476\n",
      "mae np.exp train(79650, 7) test(15675, 7) -16.7577 eval(25080, 7) -18.0292\n",
      "mae np.exp train(58791, 5) test(15675, 5) -4.3576 eval(25080, 5) -4.4669\n",
      "mae np.exp train(80822, 8) test(15675, 8) -4.0759 eval(25080, 8) -3.9785\n",
      "mae np.exp train(79966, 7) test(15675, 7) -27.9857 eval(25080, 7) -29.2892\n",
      "mae np.exp train(65146, 9) test(15675, 9) -109.8398 eval(25080, 9) -595.4208\n",
      "mae np.exp train(52986, 14) test(15675, 14) -109.7522 eval(25080, 14) -590.5263\n",
      "mae np.exp train(52963, 8) test(15675, 8) -115.5837 eval(25080, 8) -149.1559\n",
      "mae np.exp train(79635, 7) test(15675, 7) -6.2972 eval(25080, 7) -6.1138\n",
      "mae np.exp train(64522, 9) test(15675, 9) -109.524 eval(25080, 9) -146.0159\n",
      "mae np.exp train(55858, 20) test(15675, 20) -3.2549 eval(25080, 20) -3.2951\n",
      "mae np.exp train(82898, 6) test(15675, 6) -12.5003 eval(25080, 6) -12.7496\n",
      "mae np.exp train(49655, 19) test(15675, 19) -3.4339 eval(25080, 19) -3.5152\n",
      "mae np.exp train(68377, 10) test(15675, 10) -14.6237 eval(25080, 10) -15.8599\n",
      "mae np.exp train(66927, 12) test(15675, 12) -5.9463 eval(25080, 12) -6.5142\n",
      "mae np.exp train(52047, 9) test(15675, 9) -30.3761 eval(25080, 9) -33.6616\n",
      "mae np.exp train(49655, 20) test(15675, 20) -3.2657 eval(25080, 20) -3.3109\n",
      "mae np.exp train(80921, 8) test(15675, 8) -20.7131 eval(25080, 8) -21.646\n",
      "mae np.exp train(55691, 9) test(15675, 9) -109.7384 eval(25080, 9) -589.6989\n",
      "mae np.exp train(80359, 8) test(15675, 8) -109.8022 eval(25080, 8) -593.3956\n",
      "mae np.exp train(65126, 8) test(15675, 8) -30.3857 eval(25080, 8) -31.9319\n",
      "mae np.exp train(73819, 8) test(15675, 8) -21.474 eval(25080, 8) -22.6319\n",
      "mae np.exp train(55289, 9) test(15675, 9) -18.6335 eval(25080, 9) -19.074\n",
      "mae np.exp train(82441, 7) test(15675, 7) -7.2975 eval(25080, 7) -7.4542\n",
      "mae np.exp train(80251, 6) test(15675, 6) -14.2449 eval(25080, 6) -14.9274\n",
      "mae np.exp train(64470, 7) test(15675, 7) -10.7821 eval(25080, 7) -10.2192\n",
      "mae np.exp train(67511, 7) test(15675, 7) -117.3728 eval(25080, 7) -178.268\n",
      "mae np.exp train(55410, 11) test(15670, 11) -15.3644 eval(25073, 11) -15.5486\n",
      "mae np.exp train(55307, 10) test(15675, 10) -123.799 eval(25080, 10) -165.2016\n",
      "mae np.exp train(68428, 12) test(15670, 12) -11.1153 eval(25073, 12) -11.4149\n",
      "mae np.exp train(80047, 9) test(15675, 9) -122.5907 eval(25080, 9) -188.9325\n",
      "mae np.exp train(49851, 17) test(15675, 17) -2.9668 eval(25080, 17) -2.9455\n",
      "mae np.exp train(49402, 13) test(15670, 13) -127.1513 eval(25073, 13) -172.1932\n",
      "mae np.exp train(55858, 18) test(15675, 18) -3.2628 eval(25080, 18) -3.3087\n",
      "mae np.exp train(61878, 7) test(15675, 7) -55.5044 eval(25080, 7) -73.9039\n",
      "mae np.exp train(49655, 20) test(15675, 20) -3.5137 eval(25080, 20) -3.5984\n",
      "mae np.exp train(48693, 14) test(15675, 14) -14.1519 eval(25080, 14) -14.4741\n",
      "mae np.exp train(61678, 10) test(15675, 10) -39.6266 eval(25080, 10) -44.9222\n",
      "mae np.exp train(58311, 9) test(15675, 9) -9.0749 eval(25080, 9) -9.2814\n",
      "mae np.exp train(84015, 8) test(15675, 8) -128.9935 eval(25080, 8) -179.5272\n",
      "mae np.exp train(80657, 8) test(15675, 8) -22.0485 eval(25080, 8) -23.3378\n",
      "mae np.exp train(76884, 11) test(15675, 11) -8.2739 eval(25080, 11) -8.6399\n",
      "mae np.exp train(80282, 7) test(15675, 7) -4.525 eval(25080, 7) -4.4676\n",
      "mae np.exp train(80144, 7) test(15675, 7) -5.7729 eval(25080, 7) -5.8198\n",
      "mae np.exp train(80583, 8) test(15675, 8) -12.8075 eval(25080, 8) -11.9804\n",
      "mae np.exp train(80262, 7) test(15675, 7) -11.2191 eval(25080, 7) -11.4744\n",
      "mae np.exp train(79301, 8) test(15675, 8) -12.3466 eval(25080, 8) -13.305\n",
      "mae np.exp train(64631, 9) test(15675, 9) -127.9123 eval(25080, 9) -189.0592\n",
      "mae np.exp train(62407, 8) test(15675, 8) -6.2222 eval(25080, 8) -5.7739\n",
      "mae np.exp train(61811, 12) test(15675, 12) -109.8477 eval(25080, 12) -595.8235\n",
      "mae np.exp train(80230, 7) test(15675, 7) -109.7592 eval(25080, 7) -590.9387\n",
      "mae np.exp train(67262, 7) test(15675, 7) -20.8044 eval(25080, 7) -23.1623\n",
      "mae np.exp train(83338, 10) test(15670, 10) -119.5002 eval(25073, 10) -156.6152\n",
      "mae np.exp train(80165, 10) test(15675, 10) -20.1671 eval(25080, 10) -20.7596\n",
      "mae np.exp train(49655, 17) test(15675, 17) -3.3852 eval(25080, 17) -3.4444\n",
      "mae np.exp train(65197, 8) test(15675, 8) -15.9367 eval(25080, 8) -16.3074\n",
      "mae np.exp train(79607, 8) test(15670, 8) -20.4563 eval(25073, 8) -21.1551\n",
      "mae np.exp train(80796, 7) test(15675, 7) -133.2167 eval(25080, 7) -186.8994\n",
      "mae np.exp train(81216, 9) test(15670, 9) -15.0521 eval(25073, 9) -15.6724\n",
      "mae np.exp train(49655, 21) test(15675, 21) -3.3524 eval(25080, 21) -3.4266\n",
      "mae np.exp train(49464, 9) test(15675, 9) -112.9114 eval(25080, 9) -144.0528\n",
      "mae np.exp train(73435, 7) test(15675, 7) -121.5646 eval(25080, 7) -160.7379\n",
      "mae np.exp train(80079, 9) test(15675, 9) -19.3221 eval(25080, 9) -21.0556\n",
      "mae np.exp train(52504, 9) test(15675, 9) -132.607 eval(25080, 9) -184.6243\n",
      "mae np.exp train(54934, 10) test(15675, 10) -16.8537 eval(25080, 10) -18.228\n",
      "mae np.exp train(83207, 7) test(15675, 7) -22.5283 eval(25080, 7) -23.5533\n",
      "mae np.exp train(64142, 8) test(15675, 8) -8.3628 eval(25080, 8) -8.6359\n",
      "mae np.exp train(58187, 9) test(15675, 9) -16.4088 eval(25080, 9) -16.1221\n",
      "mae np.exp train(49655, 22) test(15675, 22) -3.4906 eval(25080, 22) -3.5988\n",
      "mae np.exp train(79600, 7) test(15675, 7) -115.0246 eval(25080, 7) -153.0292\n",
      "mae np.exp train(74653, 9) test(15675, 9) -7.0482 eval(25080, 9) -5.1958\n",
      "mae np.exp train(80744, 9) test(15675, 9) -13.4612 eval(25080, 9) -13.0925\n",
      "mae np.exp train(81117, 7) test(15675, 7) -33.6747 eval(25080, 7) -35.7736\n",
      "mae np.exp train(80056, 7) test(15670, 7) -12.0471 eval(25073, 7) -12.1689\n",
      "mae np.exp train(84074, 6) test(15675, 6) -12.2005 eval(25080, 6) -11.405\n",
      "mae np.exp train(79543, 10) test(15675, 10) -5.2745 eval(25080, 10) -5.2803\n",
      "mae np.exp train(80357, 10) test(15675, 10) -11.6509 eval(25080, 10) -12.5198\n",
      "mae np.exp train(64414, 7) test(15675, 7) -131.452 eval(25080, 7) -181.6507\n",
      "mae np.exp train(79808, 8) test(15675, 8) -128.5588 eval(25080, 8) -175.8149\n",
      "mae np.exp train(80443, 8) test(15675, 8) -10.0845 eval(25080, 8) -10.7555\n",
      "mae np.exp train(83509, 10) test(15675, 10) -6.2418 eval(25080, 10) -6.429\n",
      "mae np.exp train(77966, 7) test(15675, 7) -7.2352 eval(25080, 7) -7.6247\n",
      "mae np.exp train(55586, 10) test(15675, 10) -29.4513 eval(25080, 10) -29.9655\n",
      "mae np.exp train(73851, 9) test(15675, 9) -8.2604 eval(25080, 9) -8.9476\n",
      "mae np.exp train(77010, 13) test(15675, 13) -6.2604 eval(25080, 13) -5.7876\n",
      "mae np.exp train(80104, 7) test(15675, 7) -109.7592 eval(25080, 7) -590.9387\n",
      "mae np.exp train(70955, 9) test(15675, 9) -4.5173 eval(25080, 9) -4.6933\n",
      "mae np.exp train(70421, 7) test(15675, 7) -7.4037 eval(25080, 7) -7.6587\n",
      "mae np.exp train(80223, 8) test(15675, 8) -20.8886 eval(25080, 8) -22.6222\n",
      "mae np.exp train(54931, 11) test(15675, 11) -9.8092 eval(25080, 11) -9.5565\n",
      "mae np.exp train(71504, 9) test(15675, 9) -8.0242 eval(25080, 9) -7.8124\n",
      "mae np.exp train(80276, 8) test(15675, 8) -5.9283 eval(25080, 8) -5.2105\n",
      "mae np.exp train(80646, 7) test(15675, 7) -13.5486 eval(25080, 7) -14.0988\n",
      "mae np.exp train(55433, 19) test(15675, 19) -4.0353 eval(25080, 19) -4.1781\n",
      "mae np.exp train(67838, 8) test(15675, 8) -12.9019 eval(25080, 8) -14.1404\n",
      "mae np.exp train(80584, 8) test(15675, 8) -109.7662 eval(25080, 8) -591.3503\n",
      "mae np.exp train(80572, 7) test(15675, 7) -16.8458 eval(25080, 7) -16.9165\n",
      "mae np.exp train(77343, 8) test(15675, 8) -109.7114 eval(25080, 8) -588.0338\n",
      "mae np.exp train(83135, 8) test(15670, 8) -8.6848 eval(25073, 8) -8.1017\n",
      "mae np.exp train(79591, 7) test(15675, 7) -5.7416 eval(25080, 7) -5.1195\n",
      "mae np.exp train(79826, 8) test(15675, 8) -8.8576 eval(25080, 8) -9.2067\n",
      "mae np.exp train(80455, 6) test(15675, 6) -8.3828 eval(25080, 6) -8.5701\n",
      "mae np.exp train(58747, 6) test(15675, 6) -10.8252 eval(25080, 6) -10.868\n",
      "mae np.exp train(79379, 7) test(15675, 7) -7.309 eval(25080, 7) -7.4797\n",
      "mae np.exp train(70203, 9) test(15675, 9) -9.3535 eval(25080, 9) -9.7173\n",
      "mae np.exp train(83015, 5) test(15675, 5) -9.1102 eval(25080, 5) -8.3864\n",
      "mae np.exp train(79855, 8) test(15675, 8) -120.1867 eval(25080, 8) -157.7229\n",
      "mae np.exp train(64313, 7) test(15675, 7) -5.2048 eval(25080, 7) -4.8503\n",
      "mae np.exp train(80701, 8) test(15675, 8) -129.3777 eval(25080, 8) -177.3491\n",
      "mae np.exp train(64598, 10) test(15675, 10) -12.0674 eval(25080, 10) -12.947\n",
      "mae np.exp train(79117, 8) test(15675, 8) -6.4319 eval(25080, 8) -6.7634\n",
      "mae np.exp train(65153, 6) test(15675, 6) -6.2666 eval(25080, 6) -6.5333\n",
      "mae np.exp train(80762, 9) test(15675, 9) -5.2852 eval(25080, 9) -4.7711\n",
      "mae np.exp train(61934, 8) test(15670, 8) -8.9251 eval(25073, 8) -9.2809\n",
      "mae np.exp train(67625, 6) test(15675, 6) -4.2409 eval(25080, 6) -4.0428\n",
      "mae np.exp train(81110, 6) test(15675, 6) -133.0616 eval(25080, 6) -185.9899\n",
      "mae np.exp train(80726, 7) test(15675, 7) -56.7747 eval(25080, 7) -53.6203\n",
      "mae np.exp train(82819, 3) test(15675, 3) -15.4569 eval(25080, 3) -16.3045\n",
      "mae np.exp train(52551, 11) test(15675, 11) -14.8087 eval(25080, 11) -15.2362\n",
      "mae np.exp train(83492, 6) test(15675, 6) -57.4179 eval(25080, 6) -62.1021\n",
      "mae np.exp train(48667, 15) test(15670, 15) -109.7047 eval(25073, 15) -587.9838\n",
      "mae np.exp train(70819, 9) test(15675, 9) -11.4315 eval(25080, 9) -9.7981\n",
      "mae np.exp train(80322, 6) test(15675, 6) -4.5723 eval(25080, 6) -4.7492\n",
      "mae np.exp train(80814, 9) test(15675, 9) -7.8426 eval(25080, 9) -8.0354\n",
      "mae np.exp train(55700, 9) test(15675, 9) -9.3497 eval(25080, 9) -8.2115\n",
      "mae np.exp train(83151, 8) test(15670, 8) -129.6595 eval(25073, 8) -178.4977\n",
      "mae np.exp train(71652, 8) test(15675, 8) -5.4063 eval(25080, 8) -5.5795\n",
      "mae np.exp train(74526, 11) test(15675, 11) -9.7003 eval(25080, 11) -9.8948\n",
      "mae np.exp train(74227, 8) test(15675, 8) -6.551 eval(25080, 8) -6.852\n",
      "mae np.exp train(77158, 10) test(15675, 10) -33.2447 eval(25080, 10) -37.8413\n",
      "mae np.exp train(67533, 12) test(15675, 12) -22.8251 eval(25080, 12) -25.1826\n",
      "mae np.exp train(55399, 10) test(15675, 10) -17.8421 eval(25080, 10) -19.155\n",
      "mae np.exp train(58003, 9) test(15675, 9) -9.4712 eval(25080, 9) -8.9811\n",
      "mae np.exp train(79762, 7) test(15675, 7) -107.7662 eval(25080, 7) -144.4313\n",
      "mae np.exp train(61595, 11) test(15675, 11) -16.6711 eval(25080, 11) -16.8222\n",
      "mae np.exp train(71400, 10) test(15675, 10) -5.0637 eval(25080, 10) -5.0807\n",
      "mae np.exp train(61793, 10) test(15675, 10) -6.0479 eval(25080, 10) -5.5082\n",
      "mae np.exp train(83310, 7) test(15670, 7) -20.0771 eval(25073, 7) -21.3355\n",
      "mae np.exp train(64641, 10) test(15675, 10) -114.4859 eval(25080, 10) -146.6373\n",
      "mae np.exp train(56120, 8) test(15675, 8) -132.5888 eval(25080, 8) -185.3547\n",
      "mae np.exp train(67653, 10) test(15675, 10) -10.2597 eval(25080, 10) -11.0097\n",
      "mae np.exp train(67437, 10) test(15675, 10) -7.7362 eval(25080, 10) -7.8188\n",
      "mae np.exp train(79587, 10) test(15675, 10) -12.3906 eval(25080, 10) -12.4151\n",
      "mae np.exp train(70320, 8) test(15675, 8) -24.9967 eval(25080, 8) -25.6632\n",
      "mae np.exp train(80734, 7) test(15675, 7) -15.1197 eval(25080, 7) -13.907\n",
      "mae np.exp train(80516, 7) test(15675, 7) -12.4418 eval(25080, 7) -10.4636\n",
      "mae np.exp train(80787, 7) test(15675, 7) -6.5168 eval(25080, 7) -6.1079\n",
      "mae np.exp train(80460, 7) test(15675, 7) -13.0448 eval(25080, 7) -13.6627\n",
      "mae np.exp train(52397, 9) test(15675, 9) -119.291 eval(25080, 9) -167.8747\n",
      "mae np.exp train(79568, 9) test(15675, 9) -120.3286 eval(25080, 9) -165.2892\n",
      "mae np.exp train(55565, 9) test(15670, 9) -8.0015 eval(25073, 9) -8.4151\n",
      "mae np.exp train(63910, 10) test(15675, 10) -109.7181 eval(25080, 10) -588.4513\n",
      "mae np.exp train(65447, 11) test(15675, 11) -6.0033 eval(25080, 11) -6.1917\n",
      "mae np.exp train(64554, 13) test(15675, 13) -7.9309 eval(25080, 13) -8.4017\n",
      "mae np.exp train(61503, 11) test(15675, 11) -51.9265 eval(25080, 11) -61.2684\n",
      "mae np.exp train(58914, 11) test(15675, 11) -7.6801 eval(25080, 11) -8.2242\n",
      "mae np.exp train(80596, 7) test(15675, 7) -17.7179 eval(25080, 7) -18.5996\n",
      "mae np.exp train(80931, 9) test(15675, 9) -8.523 eval(25080, 9) -8.9424\n",
      "mae np.exp train(74133, 10) test(15675, 10) -8.111 eval(25080, 10) -8.4913\n",
      "mae np.exp train(55670, 9) test(15675, 9) -121.9314 eval(25080, 9) -163.0513\n",
      "mae np.exp train(79732, 9) test(15675, 9) -13.1117 eval(25080, 9) -14.4852\n",
      "mae np.exp train(80393, 10) test(15675, 10) -6.8794 eval(25080, 10) -7.0896\n",
      "mae np.exp train(58307, 11) test(15675, 11) -9.368 eval(25080, 11) -9.9771\n",
      "mae np.exp train(77457, 7) test(15675, 7) -21.3312 eval(25080, 7) -23.4838\n",
      "mae np.exp train(52783, 12) test(15675, 12) -16.6141 eval(25080, 12) -14.9327\n",
      "mae np.exp train(80494, 10) test(15670, 10) -5.1336 eval(25073, 10) -5.2748\n",
      "mae np.exp train(79690, 9) test(15675, 9) -14.5628 eval(25080, 9) -14.6666\n",
      "mae np.exp train(80516, 9) test(15675, 9) -109.7803 eval(25080, 9) -592.1709\n",
      "mae np.exp train(58517, 12) test(15675, 12) -6.2737 eval(25080, 12) -5.5236\n",
      "mae np.exp train(80074, 7) test(15675, 7) -13.7682 eval(25080, 7) -12.4268\n",
      "mae np.exp train(52591, 7) test(15675, 7) -6.5881 eval(25080, 7) -7.3708\n",
      "mae np.exp train(79859, 7) test(15675, 7) -8.3166 eval(25080, 7) -8.4767\n",
      "mae np.exp train(62026, 8) test(15675, 8) -5.7168 eval(25080, 8) -5.0765\n",
      "mae np.exp train(64213, 9) test(15675, 9) -11.9579 eval(25080, 9) -10.9479\n",
      "mae np.exp train(80334, 6) test(15675, 6) -15.1702 eval(25080, 6) -15.2282\n",
      "mae np.exp train(52102, 12) test(15675, 12) -7.6323 eval(25080, 12) -7.355\n",
      "mae np.exp train(61438, 9) test(15675, 9) -108.7879 eval(25080, 9) -136.5779\n",
      "mae np.exp train(51951, 11) test(15675, 11) -90.8801 eval(25080, 11) -122.073\n",
      "mae np.exp train(67789, 8) test(15675, 8) -109.6918 eval(25080, 8) -586.7761\n",
      "mae np.exp train(80900, 9) test(15675, 9) -3.7237 eval(25080, 9) -3.3413\n",
      "mae np.exp train(70633, 9) test(15675, 9) -4.7907 eval(25080, 9) -4.9423\n",
      "mae np.exp train(77013, 10) test(15675, 10) -109.6763 eval(25080, 10) -585.722\n",
      "mae np.exp train(55974, 11) test(15675, 11) -9.0708 eval(25080, 11) -9.2376\n",
      "mae np.exp train(62302, 13) test(15675, 13) -5.5339 eval(25080, 13) -5.6532\n",
      "mae np.exp train(79978, 7) test(15675, 7) -11.8354 eval(25080, 7) -12.7842\n",
      "mae np.exp train(80258, 10) test(15675, 10) -5.7567 eval(25080, 10) -5.7844\n",
      "mae np.exp train(48990, 7) test(15670, 7) -18.0705 eval(25073, 7) -18.5755\n",
      "mae np.exp train(79718, 10) test(15675, 10) -125.6795 eval(25080, 10) -169.3132\n",
      "mae np.exp train(80440, 9) test(15675, 9) -7.6478 eval(25080, 9) -7.9181\n",
      "mae np.exp train(52956, 12) test(15675, 12) -11.6472 eval(25080, 12) -12.0343\n",
      "mae np.exp train(65358, 9) test(15675, 9) -5.21 eval(25080, 9) -5.3919\n",
      "mae np.exp train(80439, 7) test(15675, 7) -109.8477 eval(25080, 7) -595.8235\n",
      "mae np.exp train(67630, 9) test(15675, 9) -6.8835 eval(25080, 9) -7.1333\n",
      "mae np.exp train(80714, 8) test(15675, 8) -10.7832 eval(25080, 8) -11.0323\n",
      "mae np.exp train(79664, 8) test(15675, 8) -117.6622 eval(25080, 8) -162.7963\n",
      "mae np.exp train(52754, 11) test(15670, 11) -16.8494 eval(25073, 11) -17.133\n",
      "mae np.exp train(65109, 13) test(15675, 13) -3.6844 eval(25080, 13) -3.6945\n",
      "mae np.exp train(71033, 7) test(15675, 7) -9.5557 eval(25080, 7) -9.4784\n",
      "mae np.exp train(80578, 11) test(15670, 11) -17.5784 eval(25073, 11) -17.8373\n",
      "mae np.exp train(79880, 7) test(15675, 7) -115.8266 eval(25080, 7) -148.8772\n",
      "mae np.exp train(81025, 8) test(15675, 8) -109.8096 eval(25080, 8) -593.8021\n",
      "mae np.exp train(79984, 9) test(15675, 9) -110.2397 eval(25080, 9) -166.2542\n",
      "mae np.exp train(67169, 8) test(15675, 8) -13.989 eval(25080, 8) -14.7592\n",
      "mae np.exp train(74262, 10) test(15675, 10) -11.7269 eval(25080, 10) -12.519\n",
      "mae np.exp train(81161, 9) test(15675, 9) -114.2957 eval(25080, 9) -156.3561\n",
      "mae np.exp train(73279, 9) test(15675, 9) -6.7201 eval(25080, 9) -6.1292\n",
      "mae np.exp train(71419, 12) test(15675, 12) -120.9701 eval(25080, 12) -159.9041\n",
      "mae np.exp train(77985, 10) test(15675, 10) -29.8892 eval(25080, 10) -33.3205\n",
      "mae np.exp train(80723, 11) test(15675, 11) -109.7803 eval(25080, 11) -592.1709\n",
      "mae np.exp train(79361, 7) test(15675, 7) -17.9093 eval(25080, 7) -18.1942\n",
      "mae np.exp train(80936, 7) test(15670, 7) -3.5655 eval(25073, 7) -3.5499\n",
      "mae np.exp train(55707, 9) test(15670, 9) -15.4874 eval(25073, 9) -16.2301\n",
      "mae np.exp train(79745, 9) test(15675, 9) -8.7324 eval(25080, 9) -9.2459\n",
      "mae np.exp train(80658, 8) test(15675, 8) -109.7522 eval(25080, 8) -590.5263\n",
      "mae np.exp train(49091, 10) test(15670, 10) -109.7522 eval(25073, 10) -590.8887\n",
      "mae np.exp train(80528, 10) test(15670, 10) -111.5099 eval(25073, 10) -141.2594\n",
      "mae np.exp train(52786, 8) test(15675, 8) -115.5538 eval(25080, 8) -148.7701\n",
      "mae np.exp train(55336, 9) test(15675, 9) -55.7537 eval(25080, 9) -63.2221\n",
      "mae np.exp train(64727, 8) test(15675, 8) -118.8493 eval(25080, 8) -155.1324\n",
      "mae np.exp train(80438, 6) test(15675, 6) -118.8247 eval(25080, 6) -155.0529\n",
      "mae np.exp train(80611, 8) test(15675, 8) -12.4276 eval(25080, 8) -12.6069\n",
      "mae np.exp train(79827, 11) test(15675, 11) -41.5156 eval(25080, 11) -43.607\n",
      "mae np.exp train(83498, 7) test(15675, 7) -11.7086 eval(25080, 7) -12.2257\n",
      "mae np.exp train(83770, 5) test(15675, 5) -132.7791 eval(25080, 5) -185.8627\n",
      "mae np.exp train(80578, 6) test(15675, 6) -129.2557 eval(25080, 6) -177.0829\n",
      "mae np.exp train(80976, 9) test(15670, 9) -108.704 eval(25073, 9) -159.6653\n",
      "mae np.exp train(83327, 5) test(15675, 5) -6.4746 eval(25080, 5) -6.669\n",
      "mae np.exp train(80086, 8) test(15675, 8) -5.7387 eval(25080, 8) -5.8798\n",
      "mae np.exp train(79951, 7) test(15675, 7) -5.4366 eval(25080, 7) -4.975\n",
      "mae np.exp train(80207, 8) test(15675, 8) -109.8022 eval(25080, 8) -593.3956\n",
      "mae np.exp train(81014, 7) test(15675, 7) -109.7803 eval(25080, 7) -592.1709\n",
      "mae np.exp train(55606, 9) test(15675, 9) -120.9562 eval(25080, 9) -159.3013\n",
      "mae np.exp train(55674, 9) test(15675, 9) -109.6918 eval(25080, 9) -586.7761\n",
      "mae np.exp train(76925, 12) test(15670, 12) -6.3611 eval(25073, 12) -6.5002\n",
      "mae np.exp train(80628, 7) test(15675, 7) -28.5246 eval(25080, 7) -29.1851\n",
      "mae np.exp train(79844, 11) test(15675, 11) -112.2922 eval(25080, 11) -142.7704\n",
      "mae np.exp train(62161, 7) test(15675, 7) -6.2884 eval(25080, 7) -5.3581\n",
      "mae np.exp train(48868, 12) test(15675, 12) -5.573 eval(25080, 12) -5.4283\n",
      "mae np.exp train(82692, 6) test(15675, 6) -10.1366 eval(25080, 6) -10.5228\n",
      "mae np.exp train(80204, 7) test(15675, 7) -11.5403 eval(25080, 7) -10.19\n",
      "mae np.exp train(80280, 7) test(15675, 7) -9.8881 eval(25080, 7) -9.9332\n",
      "mae np.exp train(80067, 8) test(15675, 8) -6.5871 eval(25080, 8) -5.9226\n",
      "mae np.exp train(83021, 5) test(15675, 5) -109.6702 eval(25080, 5) -585.2989\n",
      "mae np.exp train(58703, 11) test(15675, 11) -45.4461 eval(25080, 11) -48.6236\n",
      "mae np.exp train(79321, 6) test(15675, 6) -7.3415 eval(25080, 6) -7.816\n",
      "mae np.exp train(80585, 6) test(15675, 6) -18.4758 eval(25080, 6) -18.2131\n",
      "mae np.exp train(80032, 10) test(15675, 10) -6.6907 eval(25080, 10) -7.0247\n",
      "mae np.exp train(80527, 6) test(15675, 6) -10.9422 eval(25080, 6) -11.0086\n",
      "mae np.exp train(79259, 8) test(15670, 8) -9.4437 eval(25073, 8) -9.709\n",
      "mae np.exp train(80152, 7) test(15675, 7) -5.7734 eval(25080, 7) -5.5803\n",
      "mae np.exp train(70399, 7) test(15675, 7) -123.7947 eval(25080, 7) -164.9589\n",
      "mae np.exp train(58059, 10) test(15675, 10) -16.6293 eval(25080, 10) -18.2427\n",
      "mae np.exp train(77531, 8) test(15675, 8) -3.4064 eval(25080, 8) -3.4427\n",
      "mae np.exp train(82706, 6) test(15675, 6) -130.4759 eval(25080, 6) -179.5681\n",
      "mae np.exp train(80876, 8) test(15670, 8) -4.8692 eval(25073, 8) -4.9311\n",
      "mae np.exp train(76929, 8) test(15675, 8) -117.699 eval(25080, 8) -152.7698\n",
      "mae np.exp train(61739, 11) test(15675, 11) -8.2149 eval(25080, 11) -8.618\n",
      "mae np.exp train(80123, 7) test(15675, 7) -5.5858 eval(25080, 7) -5.0632\n",
      "mae np.exp train(79757, 6) test(15675, 6) -8.6747 eval(25080, 6) -9.0981\n",
      "mae np.exp train(64687, 10) test(15675, 10) -118.5079 eval(25080, 10) -154.5207\n",
      "mae np.exp train(79842, 9) test(15675, 9) -10.2745 eval(25080, 9) -10.9989\n",
      "mae np.exp train(55204, 9) test(15675, 9) -17.5324 eval(25080, 9) -19.2956\n",
      "mae np.exp train(73680, 9) test(15675, 9) -4.4183 eval(25080, 9) -4.489\n",
      "mae np.exp train(80176, 7) test(15675, 7) -38.0321 eval(25080, 7) -39.709\n",
      "mae np.exp train(84392, 8) test(15675, 8) -4.8451 eval(25080, 8) -4.7421\n",
      "mae np.exp train(70249, 10) test(15675, 10) -13.1777 eval(25080, 10) -14.0576\n",
      "mae np.exp train(61248, 9) test(15675, 9) -6.8834 eval(25080, 9) -7.3409\n",
      "mae np.exp train(79406, 8) test(15675, 8) -10.281 eval(25080, 8) -10.6088\n",
      "mae np.exp train(79745, 9) test(15675, 9) -20.0175 eval(25080, 9) -19.3614\n",
      "mae np.exp train(80046, 10) test(15675, 10) -123.4492 eval(25080, 10) -177.7353\n",
      "mae np.exp train(58912, 8) test(15675, 8) -15.33 eval(25080, 8) -15.8553\n",
      "mae np.exp train(58710, 12) test(15670, 12) -10.6289 eval(25073, 12) -11.0258\n",
      "mae np.exp train(58601, 8) test(15675, 8) -112.432 eval(25080, 8) -143.1931\n",
      "mae np.exp train(80546, 8) test(15675, 8) -7.2935 eval(25080, 8) -7.5546\n",
      "mae np.exp train(67395, 9) test(15675, 9) -112.2327 eval(25080, 9) -147.3311\n",
      "mae np.exp train(61734, 9) test(15670, 9) -109.7733 eval(25073, 9) -592.1209\n",
      "mae np.exp train(68039, 10) test(15675, 10) -23.5426 eval(25080, 10) -26.0899\n",
      "mae np.exp train(80085, 8) test(15675, 8) -16.6889 eval(25080, 8) -18.0495\n",
      "mae np.exp train(79916, 8) test(15675, 8) -5.6597 eval(25080, 8) -5.3824\n",
      "mae np.exp train(80749, 8) test(15670, 8) -10.655 eval(25073, 8) -10.99\n",
      "mae np.exp train(68261, 14) test(15675, 14) -11.0708 eval(25080, 14) -11.601\n",
      "mae np.exp train(61637, 10) test(15675, 10) -4.966 eval(25080, 10) -5.1043\n",
      "mae np.exp train(80758, 12) test(15675, 12) -8.0849 eval(25080, 12) -8.7414\n",
      "mae np.exp train(79146, 8) test(15675, 8) -6.6208 eval(25080, 8) -6.3326\n",
      "mae np.exp train(67721, 8) test(15675, 8) -109.6732 eval(25080, 8) -585.5107\n",
      "mae np.exp train(79969, 7) test(15675, 7) -8.3887 eval(25080, 7) -8.6073\n",
      "mae np.exp train(81078, 6) test(15675, 6) -23.9999 eval(25080, 6) -27.057\n",
      "mae np.exp train(83874, 9) test(15670, 9) -113.8756 eval(25073, 9) -164.6864\n",
      "mae np.exp train(55440, 9) test(15675, 9) -10.6688 eval(25080, 9) -10.0962\n",
      "mae np.exp train(82960, 6) test(15675, 6) -112.0727 eval(25080, 6) -161.5671\n",
      "mae np.exp train(79928, 7) test(15675, 7) -119.6977 eval(25080, 7) -176.1613\n",
      "mae np.exp train(52421, 9) test(15675, 9) -17.4516 eval(25080, 9) -18.9159\n",
      "mae np.exp train(79469, 8) test(15675, 8) -21.5068 eval(25080, 8) -22.55\n",
      "mae np.exp train(82991, 7) test(15675, 7) -7.3295 eval(25080, 7) -7.1064\n",
      "mae np.exp train(79896, 10) test(15675, 10) -16.8931 eval(25080, 10) -15.4424\n",
      "mae np.exp train(80257, 7) test(15675, 7) -17.5537 eval(25080, 7) -18.3924\n",
      "mae np.exp train(83439, 10) test(15675, 10) -5.8614 eval(25080, 10) -4.9978\n",
      "mae np.exp train(83972, 10) test(15675, 10) -17.0471 eval(25080, 10) -18.5191\n",
      "mae np.exp train(71658, 11) test(15670, 11) -11.8201 eval(25073, 11) -11.6864\n",
      "mae np.exp train(49802, 9) test(15675, 9) -32.2934 eval(25080, 9) -34.0216\n",
      "mae np.exp train(80511, 7) test(15675, 7) -126.0503 eval(25080, 7) -170.516\n",
      "mae np.exp train(74821, 8) test(15675, 8) -10.6708 eval(25080, 8) -10.6824\n",
      "mae np.exp train(79513, 7) test(15675, 7) -16.3614 eval(25080, 7) -16.8131\n",
      "mae np.exp train(79315, 10) test(15670, 10) -7.9027 eval(25073, 10) -8.3619\n",
      "mae np.exp train(81021, 9) test(15675, 9) -109.7803 eval(25080, 9) -592.1709\n",
      "mae np.exp train(83439, 5) test(15675, 5) -3.8128 eval(25080, 5) -3.5081\n",
      "mae np.exp train(80636, 5) test(15675, 5) -129.1522 eval(25080, 5) -176.5642\n",
      "mae np.exp train(79798, 9) test(15675, 9) -9.2887 eval(25080, 9) -9.8152\n",
      "mae np.exp train(61846, 9) test(15675, 9) -6.5702 eval(25080, 9) -5.8567\n",
      "mae np.exp train(84160, 8) test(15670, 8) -8.5868 eval(25073, 8) -7.5741\n",
      "mae np.exp train(58776, 9) test(15675, 9) -61.5945 eval(25080, 9) -77.2582\n",
      "mae np.exp train(48983, 8) test(15675, 8) -55.4704 eval(25080, 8) -64.1927\n",
      "mae np.exp train(80432, 6) test(15675, 6) -13.4665 eval(25080, 6) -13.9963\n",
      "mae np.exp train(70814, 8) test(15675, 8) -11.0819 eval(25080, 8) -10.9382\n",
      "mae np.exp train(80108, 7) test(15675, 7) -12.292 eval(25080, 7) -12.7281\n",
      "mae np.exp train(77226, 8) test(15675, 8) -5.645 eval(25080, 8) -5.803\n",
      "mae np.exp train(81121, 7) test(15675, 7) -4.0003 eval(25080, 7) -3.7406\n",
      "mae np.exp train(83460, 10) test(15670, 10) -124.9387 eval(25073, 10) -167.8929\n",
      "mae np.exp train(79918, 6) test(15675, 6) -5.7454 eval(25080, 6) -6.0627\n",
      "mae np.exp train(82909, 5) test(15675, 5) -9.9277 eval(25080, 5) -10.0424\n",
      "mae np.exp train(55425, 7) test(15675, 7) -6.3529 eval(25080, 7) -6.1234\n",
      "mae np.exp train(64530, 9) test(15675, 9) -121.4648 eval(25080, 9) -160.3949\n",
      "mae np.exp train(80353, 11) test(15675, 11) -16.9986 eval(25080, 11) -16.0402\n",
      "mae np.exp train(79408, 5) test(15675, 5) -5.5044 eval(25080, 5) -5.4218\n",
      "mae np.exp train(80161, 11) test(15675, 11) -9.8432 eval(25080, 11) -10.1724\n",
      "mae np.exp train(83077, 6) test(15675, 6) -107.7597 eval(25080, 6) -135.0179\n",
      "mae np.exp train(74600, 8) test(15675, 8) -47.6032 eval(25080, 8) -54.3283\n",
      "mae np.exp train(59284, 10) test(15675, 10) -133.2553 eval(25080, 10) -186.5112\n",
      "mae np.exp train(80810, 6) test(15675, 6) -6.7239 eval(25080, 6) -6.7219\n",
      "mae np.exp train(79671, 9) test(15675, 9) -23.1957 eval(25080, 9) -23.8693\n",
      "mae np.exp train(73183, 9) test(15675, 9) -9.0775 eval(25080, 9) -8.8667\n",
      "mae np.exp train(68178, 11) test(15675, 11) -11.7571 eval(25080, 11) -11.6078\n",
      "mae np.exp train(80516, 7) test(15675, 7) -10.239 eval(25080, 7) -9.41\n",
      "mae np.exp train(77323, 7) test(15675, 7) -41.7249 eval(25080, 7) -47.4018\n",
      "mae np.exp train(79499, 8) test(15670, 8) -113.4581 eval(25073, 8) -144.4994\n",
      "mae np.exp train(61011, 9) test(15675, 9) -9.258 eval(25080, 9) -9.9331\n",
      "mae np.exp train(80743, 10) test(15675, 10) -7.7196 eval(25080, 10) -8.1627\n",
      "mae np.exp train(80753, 8) test(15675, 8) -6.1813 eval(25080, 8) -5.9462\n",
      "mae np.exp train(64373, 8) test(15675, 8) -7.0895 eval(25080, 8) -5.9117\n",
      "mae np.exp train(80425, 9) test(15675, 9) -28.5873 eval(25080, 9) -29.3169\n",
      "mae np.exp train(80157, 8) test(15675, 8) -9.058 eval(25080, 8) -8.1917\n",
      "mae np.exp train(80006, 7) test(15675, 7) -115.3122 eval(25080, 7) -170.7084\n",
      "mae np.exp train(73999, 6) test(15675, 6) -7.115 eval(25080, 6) -7.3214\n",
      "mae np.exp train(83278, 7) test(15675, 7) -7.1226 eval(25080, 7) -7.3551\n",
      "mae np.exp train(81240, 7) test(15675, 7) -6.4034 eval(25080, 7) -6.5678\n",
      "mae np.exp train(67853, 9) test(15675, 9) -9.1726 eval(25080, 9) -9.4073\n",
      "mae np.exp train(64315, 8) test(15675, 8) -109.7697 eval(25080, 8) -591.5556\n",
      "mae np.exp train(76644, 8) test(15675, 8) -29.6062 eval(25080, 8) -32.5981\n",
      "mae np.exp train(64810, 8) test(15675, 8) -19.4203 eval(25080, 8) -19.9741\n",
      "mae np.exp train(61641, 6) test(15675, 6) -24.8497 eval(25080, 6) -28.0248\n",
      "mae np.exp train(80254, 9) test(15670, 9) -5.7395 eval(25073, 9) -5.4994\n",
      "mae np.exp train(79594, 9) test(15675, 9) -7.0879 eval(25080, 9) -7.6061\n",
      "mae np.exp train(74681, 8) test(15675, 8) -42.9893 eval(25080, 8) -47.8045\n",
      "mae np.exp train(79827, 7) test(15675, 7) -27.5857 eval(25080, 7) -29.6688\n",
      "mae np.exp train(82578, 8) test(15675, 8) -14.7515 eval(25080, 8) -14.7587\n",
      "mae np.exp train(79433, 11) test(15675, 11) -9.776 eval(25080, 11) -10.0046\n",
      "mae np.exp train(56086, 7) test(15675, 7) -109.7948 eval(25080, 7) -592.9881\n",
      "mae np.exp train(80848, 9) test(15675, 9) -108.8722 eval(25080, 9) -152.8138\n",
      "mae np.exp train(71669, 9) test(15675, 9) -32.4663 eval(25080, 9) -33.49\n",
      "mae np.exp train(76413, 10) test(15670, 10) -130.6704 eval(25073, 10) -180.1336\n",
      "mae np.exp train(55212, 7) test(15675, 7) -6.6889 eval(25080, 7) -7.0285\n",
      "mae np.exp train(73662, 11) test(15675, 11) -119.6899 eval(25080, 11) -157.2718\n",
      "mae np.exp train(64836, 8) test(15675, 8) -6.4658 eval(25080, 8) -6.8603\n",
      "mae np.exp train(80646, 7) test(15675, 7) -6.6829 eval(25080, 7) -6.8051\n",
      "mae np.exp train(49561, 8) test(15675, 8) -80.4682 eval(25080, 8) -96.5047\n",
      "mae np.exp train(71095, 8) test(15675, 8) -5.5609 eval(25080, 8) -5.581\n",
      "mae np.exp train(80067, 7) test(15675, 7) -8.6549 eval(25080, 7) -7.5199\n",
      "mae np.exp train(64200, 9) test(15675, 9) -17.9407 eval(25080, 9) -19.233\n",
      "mae np.exp train(74684, 11) test(15675, 11) -5.7706 eval(25080, 11) -5.6697\n",
      "mae np.exp train(64500, 9) test(15675, 9) -7.4101 eval(25080, 9) -6.1964\n",
      "mae np.exp train(67782, 7) test(15675, 7) -20.9302 eval(25080, 7) -23.478\n",
      "mae np.exp train(74312, 10) test(15675, 10) -123.0376 eval(25080, 10) -163.8422\n",
      "mae np.exp train(80422, 6) test(15675, 6) -7.2575 eval(25080, 6) -7.1916\n",
      "mae np.exp train(71637, 10) test(15675, 10) -114.0095 eval(25080, 10) -146.2493\n",
      "mae np.exp train(55808, 9) test(15675, 9) -6.2574 eval(25080, 9) -5.7371\n",
      "mae np.exp train(49435, 8) test(15675, 8) -6.0326 eval(25080, 8) -6.4389\n",
      "mae np.exp train(64577, 11) test(15675, 11) -6.9464 eval(25080, 11) -7.0849\n",
      "mae np.exp train(61982, 10) test(15675, 10) -6.8085 eval(25080, 10) -5.8461\n",
      "mae np.exp train(80830, 8) test(15675, 8) -129.0108 eval(25080, 8) -174.8726\n",
      "mae np.exp train(68253, 10) test(15675, 10) -50.7196 eval(25080, 10) -58.3069\n",
      "mae np.exp train(56229, 10) test(15675, 10) -15.5947 eval(25080, 10) -15.9966\n",
      "mae np.exp train(80000, 10) test(15675, 10) -119.2888 eval(25080, 10) -155.8994\n",
      "mae np.exp train(80178, 10) test(15675, 10) -5.5357 eval(25080, 10) -5.6874\n",
      "mae np.exp train(67575, 6) test(15675, 6) -7.8102 eval(25080, 6) -8.2926\n",
      "mae np.exp train(62443, 9) test(15675, 9) -46.6609 eval(25080, 9) -53.4037\n",
      "mae np.exp train(81216, 10) test(15675, 10) -17.5288 eval(25080, 10) -18.4591\n",
      "mae np.exp train(67572, 7) test(15675, 7) -23.2313 eval(25080, 7) -23.8283\n",
      "mae np.exp train(52216, 10) test(15675, 10) -126.0354 eval(25080, 10) -169.9856\n",
      "mae np.exp train(64786, 5) test(15675, 5) -6.9641 eval(25080, 5) -7.2808\n",
      "mae np.exp train(65232, 11) test(15670, 11) -12.6192 eval(25073, 11) -11.2426\n",
      "mae np.exp train(61852, 9) test(15675, 9) -22.9126 eval(25080, 9) -21.6161\n",
      "mae np.exp train(68200, 10) test(15675, 10) -130.3288 eval(25080, 10) -179.542\n",
      "mae np.exp train(65637, 7) test(15675, 7) -7.448 eval(25080, 7) -6.8155\n",
      "mae np.exp train(61757, 8) test(15675, 8) -7.7297 eval(25080, 8) -6.9989\n",
      "mae np.exp train(61576, 14) test(15675, 14) -116.2896 eval(25080, 14) -149.8707\n",
      "mae np.exp train(83460, 8) test(15675, 8) -28.3261 eval(25080, 8) -32.1641\n",
      "mae np.exp train(62078, 8) test(15675, 8) -51.5 eval(25080, 8) -50.053\n",
      "mae np.exp train(80309, 12) test(15670, 12) -127.2703 eval(25073, 12) -172.8101\n",
      "mae np.exp train(80230, 7) test(15675, 7) -9.2122 eval(25080, 7) -9.4239\n",
      "mae np.exp train(83015, 9) test(15675, 9) -8.1669 eval(25080, 9) -7.7529\n",
      "mae np.exp train(80661, 11) test(15675, 11) -29.7923 eval(25080, 11) -32.6768\n",
      "mae np.exp train(79942, 6) test(15675, 6) -11.3203 eval(25080, 6) -10.6756\n",
      "mae np.exp train(61415, 10) test(15675, 10) -8.6202 eval(25080, 10) -7.4929\n",
      "mae np.exp train(79966, 5) test(15675, 5) -131.5612 eval(25080, 5) -182.5662\n",
      "mae np.exp train(81081, 7) test(15675, 7) -6.3209 eval(25080, 7) -5.9137\n",
      "mae np.exp train(58089, 8) test(15675, 8) -5.0711 eval(25080, 8) -5.2694\n",
      "mae np.exp train(73458, 9) test(15675, 9) -7.0908 eval(25080, 9) -6.5696\n",
      "mae np.exp train(57953, 8) test(15670, 8) -18.6224 eval(25073, 8) -17.9827\n",
      "mae np.exp train(82917, 8) test(15675, 8) -32.4421 eval(25080, 8) -36.3626\n",
      "mae np.exp train(61672, 9) test(15675, 9) -128.575 eval(25080, 9) -174.988\n",
      "mae np.exp train(79744, 6) test(15675, 6) -8.5764 eval(25080, 6) -8.7991\n",
      "mae np.exp train(49097, 10) test(15675, 10) -31.8336 eval(25080, 10) -35.5501\n",
      "mae np.exp train(52741, 8) test(15675, 8) -13.6978 eval(25080, 8) -14.863\n",
      "mae np.exp train(81032, 8) test(15675, 8) -8.3989 eval(25080, 8) -6.9275\n",
      "mae np.exp train(73747, 7) test(15675, 7) -125.4487 eval(25080, 7) -168.7099\n",
      "mae np.exp train(57808, 10) test(15675, 10) -120.7798 eval(25080, 10) -158.7992\n",
      "mae np.exp train(64993, 10) test(15675, 10) -13.2179 eval(25080, 10) -13.8131\n",
      "mae np.exp train(80354, 8) test(15675, 8) -43.073 eval(25080, 8) -48.3349\n",
      "mae np.exp train(64670, 9) test(15670, 9) -8.4257 eval(25073, 9) -8.2874\n",
      "mae np.exp train(83675, 7) test(15675, 7) -30.2622 eval(25080, 7) -33.517\n",
      "mae np.exp train(81192, 9) test(15675, 9) -5.2908 eval(25080, 9) -5.5135\n",
      "mae np.exp train(68094, 8) test(15675, 8) -109.6983 eval(25080, 8) -587.1962\n",
      "mae np.exp train(73936, 11) test(15675, 11) -7.7949 eval(25080, 11) -7.9788\n",
      "mae np.exp train(62095, 11) test(15675, 11) -4.5684 eval(25080, 11) -4.0069\n",
      "mae np.exp train(65134, 10) test(15670, 10) -133.041 eval(25073, 10) -186.042\n",
      "mae np.exp train(79764, 9) test(15675, 9) -49.8189 eval(25080, 9) -56.6147\n",
      "mae np.exp train(61358, 9) test(15675, 9) -125.9888 eval(25080, 9) -184.6031\n",
      "mae np.exp train(53106, 9) test(15675, 9) -134.6598 eval(25080, 9) -189.0469\n",
      "mae np.exp train(80534, 9) test(15675, 9) -3.3958 eval(25080, 9) -3.3841\n",
      "mae np.exp train(79456, 7) test(15675, 7) -10.0933 eval(25080, 7) -10.6084\n",
      "mae np.exp train(80769, 8) test(15675, 8) -131.0065 eval(25080, 8) -181.1247\n",
      "mae np.exp train(80840, 6) test(15675, 6) -16.5194 eval(25080, 6) -17.8888\n",
      "mae np.exp train(83093, 5) test(15675, 5) -111.0239 eval(25080, 5) -140.5264\n",
      "mae np.exp train(56014, 19) test(15675, 19) -3.1798 eval(25080, 19) -3.1666\n",
      "mae np.exp train(80396, 7) test(15675, 7) -13.3759 eval(25080, 7) -13.7114\n",
      "mae np.exp train(55541, 10) test(15675, 10) -129.4305 eval(25080, 10) -193.7904\n",
      "mae np.exp train(58867, 7) test(15675, 7) -17.0611 eval(25080, 7) -17.6123\n",
      "mae np.exp train(58921, 9) test(15675, 9) -31.5206 eval(25080, 9) -35.3869\n",
      "mae np.exp train(55049, 9) test(15675, 9) -12.4897 eval(25080, 9) -14.8997\n",
      "mae np.exp train(83098, 7) test(15675, 7) -109.6855 eval(25080, 7) -586.3552\n",
      "mae np.exp train(80914, 6) test(15675, 6) -6.4924 eval(25080, 6) -6.5444\n",
      "mae np.exp train(58867, 9) test(15675, 9) -10.9256 eval(25080, 9) -10.8224\n",
      "mae np.exp train(65186, 7) test(15675, 7) -7.2626 eval(25080, 7) -7.675\n",
      "mae np.exp train(59224, 7) test(15675, 7) -126.9863 eval(25080, 7) -172.3207\n",
      "mae np.exp train(52968, 18) test(15675, 18) -2.9293 eval(25080, 18) -2.8951\n",
      "mae np.exp train(80766, 10) test(15675, 10) -10.083 eval(25080, 10) -10.4907\n",
      "mae np.exp train(80323, 8) test(15670, 8) -6.1518 eval(25073, 8) -5.7431\n",
      "mae np.exp train(58690, 11) test(15675, 11) -18.5744 eval(25080, 11) -18.5581\n",
      "mae np.exp train(59410, 13) test(15675, 13) -17.2161 eval(25080, 13) -18.2614\n",
      "mae np.exp train(62234, 8) test(15675, 8) -5.0917 eval(25080, 8) -4.3615\n",
      "mae np.exp train(55238, 10) test(15675, 10) -6.2321 eval(25080, 10) -6.2812\n",
      "mae np.exp train(71453, 6) test(15675, 6) -10.7311 eval(25080, 6) -11.657\n",
      "mae np.exp train(80264, 8) test(15675, 8) -10.8882 eval(25080, 8) -12.0657\n",
      "mae np.exp train(55521, 10) test(15675, 10) -9.048 eval(25080, 10) -9.1041\n",
      "mae np.exp train(80066, 10) test(15675, 10) -6.417 eval(25080, 10) -6.1196\n",
      "mae np.exp train(61899, 7) test(15675, 7) -109.7384 eval(25080, 7) -589.6989\n",
      "mae np.exp train(61406, 8) test(15675, 8) -109.7181 eval(25080, 8) -588.4513\n",
      "mae np.exp train(68884, 18) test(15675, 18) -2.9642 eval(25080, 18) -2.8765\n",
      "mae np.exp train(80034, 10) test(15675, 10) -116.7531 eval(25080, 10) -158.4588\n",
      "mae np.exp train(79609, 8) test(15675, 8) -20.9501 eval(25080, 8) -23.7252\n",
      "mae np.exp train(79450, 7) test(15675, 7) -6.9173 eval(25080, 7) -7.1015\n",
      "mae np.exp train(79398, 9) test(15670, 9) -45.7746 eval(25073, 9) -53.6546\n",
      "mae np.exp train(80118, 8) test(15675, 8) -7.724 eval(25080, 8) -7.9511\n",
      "mae np.exp train(68248, 12) test(15675, 12) -5.3461 eval(25080, 12) -5.352\n",
      "mae np.exp train(80283, 11) test(15675, 11) -4.6617 eval(25080, 11) -4.6139\n",
      "mae np.exp train(80427, 9) test(15675, 9) -11.5444 eval(25080, 9) -12.1441\n",
      "mae np.exp train(74676, 9) test(15675, 9) -11.6324 eval(25080, 9) -12.2474\n",
      "mae np.exp train(82161, 8) test(15675, 8) -18.5702 eval(25080, 8) -19.4393\n",
      "mae np.exp train(67668, 9) test(15675, 9) -5.3704 eval(25080, 9) -5.6102\n",
      "mae np.exp train(74966, 11) test(15675, 11) -6.6852 eval(25080, 11) -6.9849\n",
      "mae np.exp train(79764, 9) test(15670, 9) -11.4698 eval(25073, 9) -11.6206\n",
      "mae np.exp train(80607, 7) test(15675, 7) -133.5919 eval(25080, 7) -186.9169\n",
      "mae np.exp train(58676, 9) test(15675, 9) -130.8814 eval(25080, 9) -180.8914\n",
      "mae np.exp train(80274, 7) test(15675, 7) -11.3004 eval(25080, 7) -11.4857\n",
      "mae np.exp train(81136, 8) test(15675, 8) -122.9293 eval(25080, 8) -171.541\n",
      "mae np.exp train(79743, 8) test(15675, 8) -35.5336 eval(25080, 8) -39.0418\n",
      "mae np.exp train(79811, 7) test(15675, 7) -10.6588 eval(25080, 7) -10.71\n",
      "mae np.exp train(80176, 8) test(15675, 8) -5.6991 eval(25080, 8) -5.6994\n",
      "mae np.exp train(80903, 9) test(15675, 9) -54.8051 eval(25080, 9) -61.1077\n",
      "mae np.exp train(79483, 7) test(15675, 7) -11.9543 eval(25080, 7) -12.5741\n",
      "mae np.exp train(61803, 15) test(15675, 15) -3.2926 eval(25080, 15) -3.3703\n",
      "mae np.exp train(80175, 10) test(15675, 10) -4.6993 eval(25080, 10) -4.6585\n",
      "mae np.exp train(68000, 9) test(15675, 9) -5.423 eval(25080, 9) -5.566\n",
      "mae np.exp train(64366, 16) test(15675, 16) -4.014 eval(25080, 16) -4.1529\n",
      "mae np.exp train(61398, 9) test(15675, 9) -113.5756 eval(25080, 9) -145.1336\n",
      "mae np.exp train(58671, 10) test(15675, 10) -123.3375 eval(25080, 10) -163.631\n",
      "mae np.exp train(64871, 11) test(15670, 11) -12.1524 eval(25073, 11) -12.8357\n",
      "mae np.exp train(83631, 7) test(15675, 7) -7.5534 eval(25080, 7) -7.7567\n",
      "mae np.exp train(79097, 7) test(15675, 7) -7.224 eval(25080, 7) -7.5118\n",
      "mae np.exp train(83499, 8) test(15675, 8) -4.7168 eval(25080, 8) -4.5764\n",
      "mae np.exp train(70387, 10) test(15675, 10) -11.5486 eval(25080, 10) -12.5843\n",
      "mae np.exp train(61467, 7) test(15675, 7) -111.7622 eval(25080, 7) -141.6693\n",
      "mae np.exp train(80622, 7) test(15675, 7) -131.0017 eval(25080, 7) -190.731\n",
      "mae np.exp train(68367, 12) test(15670, 12) -8.3562 eval(25073, 12) -8.8415\n",
      "mae np.exp train(67177, 8) test(15675, 8) -6.2927 eval(25080, 8) -6.3126\n",
      "mae np.exp train(61765, 10) test(15675, 10) -22.2919 eval(25080, 10) -24.4488\n",
      "mae np.exp train(80351, 7) test(15675, 7) -116.3773 eval(25080, 7) -150.4365\n",
      "mae np.exp train(55961, 7) test(15675, 7) -8.6683 eval(25080, 7) -8.8996\n",
      "mae np.exp train(68875, 8) test(15675, 8) -109.7875 eval(25080, 8) -592.58\n",
      "mae np.exp train(52505, 9) test(15675, 9) -125.3824 eval(25080, 9) -169.047\n",
      "mae np.exp train(80964, 7) test(15675, 7) -14.3491 eval(25080, 7) -12.5322\n",
      "mae np.exp train(79796, 10) test(15675, 10) -22.528 eval(25080, 10) -24.6143\n",
      "mae np.exp train(79648, 7) test(15675, 7) -124.9968 eval(25080, 7) -176.3684\n",
      "mae np.exp train(83783, 7) test(15675, 7) -121.2729 eval(25080, 7) -186.3287\n",
      "mae np.exp train(80801, 6) test(15675, 6) -9.6455 eval(25080, 6) -8.6852\n",
      "mae np.exp train(74343, 8) test(15675, 8) -109.8022 eval(25080, 8) -593.3956\n",
      "mae np.exp train(80174, 10) test(15675, 10) -23.359 eval(25080, 10) -22.4573\n",
      "mae np.exp train(76752, 11) test(15670, 11) -15.2695 eval(25073, 11) -16.4486\n",
      "mae np.exp train(70782, 12) test(15670, 12) -22.5729 eval(25073, 12) -24.571\n",
      "mae np.exp train(49430, 8) test(15675, 8) -5.8779 eval(25080, 8) -6.159\n",
      "mae np.exp train(70824, 9) test(15675, 9) -4.281 eval(25080, 9) -4.0109\n",
      "mae np.exp train(80023, 7) test(15675, 7) -9.0816 eval(25080, 7) -9.0833\n",
      "mae np.exp train(70941, 11) test(15675, 11) -6.8483 eval(25080, 11) -7.2439\n",
      "mae np.exp train(80643, 9) test(15670, 9) -109.8725 eval(25073, 9) -597.376\n",
      "mae np.exp train(80323, 8) test(15675, 8) -11.5038 eval(25080, 8) -11.9367\n",
      "mae np.exp train(80383, 10) test(15675, 10) -37.7205 eval(25080, 10) -42.2579\n",
      "mae np.exp train(62319, 11) test(15675, 11) -16.9345 eval(25080, 11) -16.9354\n",
      "mae np.exp train(67501, 10) test(15675, 10) -7.0996 eval(25080, 10) -7.486\n",
      "mae np.exp train(58492, 9) test(15675, 9) -4.9567 eval(25080, 9) -4.6638\n",
      "mae np.exp train(61716, 9) test(15675, 9) -8.2556 eval(25080, 9) -8.7096\n",
      "mae np.exp train(64983, 8) test(15675, 8) -118.4687 eval(25080, 8) -154.7816\n",
      "mae np.exp train(77401, 7) test(15675, 7) -16.1501 eval(25080, 7) -15.9079\n",
      "mae np.exp train(61354, 9) test(15675, 9) -8.1085 eval(25080, 9) -8.2675\n",
      "mae np.exp train(79932, 5) test(15675, 5) -6.1165 eval(25080, 5) -5.7605\n",
      "mae np.exp train(68226, 6) test(15675, 6) -11.1036 eval(25080, 6) -11.0169\n",
      "mae np.exp train(61607, 13) test(15675, 13) -126.1314 eval(25080, 13) -170.6923\n",
      "mae np.exp train(79503, 8) test(15675, 8) -9.6028 eval(25080, 8) -9.6668\n",
      "mae np.exp train(79614, 7) test(15675, 7) -41.9318 eval(25080, 7) -47.934\n",
      "mae np.exp train(80285, 11) test(15675, 11) -29.0742 eval(25080, 11) -26.5103\n",
      "mae np.exp train(64832, 9) test(15675, 9) -17.1876 eval(25080, 9) -17.7325\n",
      "mae np.exp train(83188, 8) test(15675, 8) -23.3069 eval(25080, 8) -25.7175\n",
      "mae np.exp train(79681, 8) test(15675, 8) -33.9131 eval(25080, 8) -37.2525\n",
      "mae np.exp train(68056, 8) test(15675, 8) -17.5229 eval(25080, 8) -17.545\n",
      "mae np.exp train(70879, 9) test(15675, 9) -19.3016 eval(25080, 9) -19.9824\n",
      "mae np.exp train(58213, 11) test(15675, 11) -11.221 eval(25080, 11) -12.2191\n",
      "mae np.exp train(65444, 9) test(15675, 9) -3.6701 eval(25080, 9) -3.1339\n",
      "mae np.exp train(51919, 11) test(15675, 11) -9.189 eval(25080, 11) -9.9121\n",
      "mae np.exp train(80651, 7) test(15675, 7) -12.9667 eval(25080, 7) -13.0013\n",
      "mae np.exp train(62181, 9) test(15675, 9) -7.7425 eval(25080, 9) -8.1895\n",
      "mae np.exp train(79770, 6) test(15675, 6) -31.0644 eval(25080, 6) -31.0069\n",
      "mae np.exp train(68173, 11) test(15675, 11) -8.3995 eval(25080, 11) -8.2097\n",
      "mae np.exp train(82753, 5) test(15675, 5) -116.3571 eval(25080, 5) -150.1644\n",
      "mae np.exp train(55176, 9) test(15670, 9) -10.6252 eval(25073, 9) -8.7926\n",
      "mae np.exp train(80128, 8) test(15675, 8) -8.506 eval(25080, 8) -8.6541\n",
      "mae np.exp train(58352, 9) test(15675, 9) -20.8518 eval(25080, 9) -23.272\n",
      "mae np.exp train(79790, 9) test(15675, 9) -28.2611 eval(25080, 9) -31.4818\n",
      "mae np.exp train(80294, 6) test(15675, 6) -121.3831 eval(25080, 6) -160.468\n",
      "mae np.exp train(70320, 7) test(15675, 7) -129.3598 eval(25080, 7) -176.4483\n",
      "mae np.exp train(58676, 9) test(15675, 9) -111.9419 eval(25080, 9) -142.2758\n",
      "mae np.exp train(79730, 10) test(15675, 10) -10.5608 eval(25080, 10) -11.0647\n",
      "mae np.exp train(82819, 8) test(15675, 8) -5.962 eval(25080, 8) -6.1335\n",
      "mae np.exp train(82820, 7) test(15675, 7) -125.26 eval(25080, 7) -198.3109\n",
      "mae np.exp train(52232, 8) test(15675, 8) -36.1829 eval(25080, 8) -38.0629\n",
      "mae np.exp train(80068, 8) test(15675, 8) -16.1248 eval(25080, 8) -16.5379\n",
      "mae np.exp train(79525, 6) test(15675, 6) -14.7767 eval(25080, 6) -15.3176\n",
      "mae np.exp train(61710, 8) test(15675, 8) -13.3139 eval(25080, 8) -13.7989\n",
      "mae np.exp train(61759, 8) test(15675, 8) -17.9876 eval(25080, 8) -19.257\n",
      "mae np.exp train(55117, 9) test(15675, 9) -16.569 eval(25080, 9) -18.4897\n",
      "mae np.exp train(59068, 12) test(15670, 12) -11.3458 eval(25073, 12) -11.5934\n",
      "mae np.exp train(56039, 7) test(15675, 7) -18.0425 eval(25080, 7) -17.7234\n",
      "mae np.exp train(81230, 10) test(15670, 10) -35.2322 eval(25073, 10) -36.0608\n",
      "mae np.exp train(79626, 7) test(15675, 7) -127.8109 eval(25080, 7) -181.0034\n",
      "mae np.exp train(74982, 10) test(15675, 10) -4.6708 eval(25080, 10) -4.3124\n",
      "mae np.exp train(56312, 9) test(15675, 9) -9.2258 eval(25080, 9) -9.9011\n",
      "mae np.exp train(58338, 11) test(15675, 11) -6.5969 eval(25080, 11) -6.9722\n",
      "mae np.exp train(81117, 6) test(15675, 6) -110.7663 eval(25080, 6) -162.6317\n",
      "mae np.exp train(80935, 7) test(15675, 7) -9.0371 eval(25080, 7) -8.8871\n",
      "mae np.exp train(79708, 8) test(15675, 8) -113.0424 eval(25080, 8) -153.0039\n",
      "mae np.exp train(83418, 6) test(15675, 6) -109.8398 eval(25080, 6) -595.4208\n",
      "mae np.exp train(80242, 8) test(15675, 8) -10.7602 eval(25080, 8) -11.0308\n",
      "mae np.exp train(80309, 8) test(15675, 8) -43.3702 eval(25080, 8) -52.1651\n",
      "mae np.exp train(61213, 11) test(15675, 11) -119.712 eval(25080, 11) -156.7496\n",
      "mae np.exp train(49809, 19) test(15675, 19) -3.0704 eval(25080, 19) -3.0812\n",
      "mae np.exp train(49445, 8) test(15675, 8) -5.419 eval(25080, 8) -5.7155\n",
      "mae np.exp train(80002, 9) test(15675, 9) -36.9392 eval(25080, 9) -39.6393\n",
      "mae np.exp train(80540, 8) test(15675, 8) -109.7592 eval(25080, 8) -590.9387\n",
      "mae np.exp train(58058, 10) test(15670, 10) -7.8233 eval(25073, 10) -7.9075\n",
      "mae np.exp train(70629, 8) test(15675, 8) -114.7791 eval(25080, 8) -147.3834\n",
      "mae np.exp train(74406, 8) test(15675, 8) -5.7564 eval(25080, 8) -5.8138\n",
      "mae np.exp train(80891, 6) test(15675, 6) -6.9561 eval(25080, 6) -7.347\n",
      "mae np.exp train(56332, 7) test(15675, 7) -4.9641 eval(25080, 7) -4.1486\n",
      "mae np.exp train(59141, 10) test(15675, 10) -14.5481 eval(25080, 10) -14.0841\n",
      "mae np.exp train(81342, 8) test(15675, 8) -15.3918 eval(25080, 8) -15.237\n",
      "mae np.exp train(65300, 10) test(15675, 10) -29.002 eval(25080, 10) -30.5921\n",
      "mae np.exp train(61223, 9) test(15675, 9) -20.5081 eval(25080, 9) -22.7352\n",
      "mae np.exp train(68074, 12) test(15675, 12) -109.7248 eval(25080, 12) -588.8681\n",
      "mae np.exp train(55010, 8) test(15675, 8) -13.4683 eval(25080, 8) -15.6837\n",
      "mae np.exp train(80335, 11) test(15670, 11) -9.3231 eval(25073, 11) -9.7\n",
      "mae np.exp train(67280, 8) test(15675, 8) -109.7316 eval(25080, 8) -589.2838\n",
      "mae np.exp train(80386, 10) test(15670, 10) -39.0592 eval(25073, 10) -46.1498\n",
      "mae np.exp train(52032, 10) test(15675, 10) -13.9108 eval(25080, 10) -14.4915\n",
      "mae np.exp train(83571, 4) test(15675, 4) -127.3986 eval(25080, 4) -181.4011\n",
      "mae np.exp train(80726, 7) test(15675, 7) -5.0793 eval(25080, 7) -4.8538\n",
      "mae np.exp train(80314, 8) test(15675, 8) -7.1578 eval(25080, 8) -7.2982\n",
      "mae np.exp train(80364, 8) test(15675, 8) -5.4088 eval(25080, 8) -4.9182\n",
      "mae np.exp train(83329, 6) test(15675, 6) -8.2292 eval(25080, 6) -8.5004\n",
      "mae np.exp train(71424, 10) test(15670, 10) -127.3013 eval(25073, 10) -173.0597\n",
      "mae np.exp train(80114, 5) test(15675, 5) -17.7849 eval(25080, 5) -18.3135\n",
      "mae np.exp train(81072, 10) test(15675, 10) -13.1742 eval(25080, 10) -13.7705\n",
      "mae np.exp train(49341, 9) test(15675, 9) -5.7294 eval(25080, 9) -6.0349\n",
      "mae np.exp train(59463, 9) test(15675, 9) -18.5591 eval(25080, 9) -19.1137\n",
      "mae np.exp train(55620, 9) test(15675, 9) -129.7403 eval(25080, 9) -178.0765\n",
      "mae np.exp train(52142, 9) test(15675, 9) -10.4361 eval(25080, 9) -10.7001\n",
      "mae np.exp train(73626, 9) test(15670, 9) -16.4188 eval(25073, 9) -17.3524\n",
      "mae np.exp train(67713, 10) test(15675, 10) -131.863 eval(25080, 10) -182.5512\n",
      "mae np.exp train(80618, 8) test(15675, 8) -131.695 eval(25080, 8) -182.4499\n",
      "mae np.exp train(53057, 9) test(15675, 9) -4.926 eval(25080, 9) -4.5352\n",
      "mae np.exp train(80109, 6) test(15675, 6) -5.626 eval(25080, 6) -5.8339\n",
      "mae np.exp train(80434, 7) test(15675, 7) -4.4579 eval(25080, 7) -4.6363\n",
      "mae np.exp train(60985, 11) test(15675, 11) -125.1395 eval(25080, 11) -167.4519\n",
      "mae np.exp train(58371, 10) test(15675, 10) -128.9655 eval(25080, 10) -176.0997\n",
      "mae np.exp train(80003, 7) test(15675, 7) -23.6006 eval(25080, 7) -22.3347\n",
      "mae np.exp train(58508, 9) test(15675, 9) -4.5137 eval(25080, 9) -4.6009\n",
      "mae np.exp train(79227, 9) test(15675, 9) -48.2548 eval(25080, 9) -55.382\n",
      "mae np.exp train(71714, 8) test(15675, 8) -19.6212 eval(25080, 8) -18.0052\n",
      "mae np.exp train(71320, 9) test(15675, 9) -15.8155 eval(25080, 9) -15.5059\n",
      "mae np.exp train(67847, 7) test(15675, 7) -10.84 eval(25080, 7) -11.4959\n",
      "mae np.exp train(79477, 8) test(15675, 8) -110.902 eval(25080, 8) -140.2301\n",
      "mae np.exp train(49655, 20) test(15670, 20) -3.344 eval(25073, 20) -3.4128\n",
      "mae np.exp train(68783, 8) test(15675, 8) -133.8412 eval(25080, 8) -188.1574\n",
      "mae np.exp train(58918, 9) test(15675, 9) -6.4594 eval(25080, 9) -6.775\n",
      "mae np.exp train(58305, 9) test(15675, 9) -129.6059 eval(25080, 9) -177.5611\n",
      "mae np.exp train(58745, 7) test(15675, 7) -6.8392 eval(25080, 7) -7.0805\n",
      "mae np.exp train(58686, 12) test(15675, 12) -4.1911 eval(25080, 12) -3.8037\n",
      "mae np.exp train(61737, 9) test(15675, 9) -9.5997 eval(25080, 9) -10.1397\n",
      "mae np.exp train(74090, 12) test(15675, 12) -16.961 eval(25080, 12) -18.6276\n",
      "mae np.exp train(82609, 6) test(15675, 6) -6.039 eval(25080, 6) -6.0863\n",
      "mae np.exp train(84007, 6) test(15675, 6) -4.6252 eval(25080, 6) -3.9376\n",
      "mae np.exp train(64873, 13) test(15675, 13) -10.4662 eval(25080, 13) -10.3566\n",
      "mae np.exp train(55410, 8) test(15675, 8) -7.0372 eval(25080, 8) -7.1902\n",
      "mae np.exp train(80216, 6) test(15675, 6) -118.0131 eval(25080, 6) -153.6875\n",
      "mae np.exp train(79638, 10) test(15675, 10) -9.7653 eval(25080, 10) -8.1343\n",
      "mae np.exp train(80571, 7) test(15670, 7) -115.0426 eval(25073, 7) -148.172\n",
      "mae np.exp train(80031, 7) test(15675, 7) -14.1618 eval(25080, 7) -13.8877\n",
      "mae np.exp train(58364, 8) test(15675, 8) -7.4961 eval(25080, 8) -7.6494\n",
      "mae np.exp train(74291, 8) test(15675, 8) -62.6322 eval(25080, 8) -73.4839\n",
      "mae np.exp train(80446, 6) test(15675, 6) -29.1703 eval(25080, 6) -32.0274\n",
      "mae np.exp train(64518, 10) test(15675, 10) -12.6722 eval(25080, 10) -11.4013\n",
      "mae np.exp train(82861, 8) test(15675, 8) -116.3042 eval(25080, 8) -190.3961\n",
      "mae np.exp train(68256, 9) test(15675, 9) -7.8918 eval(25080, 9) -8.1832\n",
      "mae np.exp train(76470, 8) test(15675, 8) -18.08 eval(25080, 8) -19.7039\n",
      "mae np.exp train(80148, 8) test(15675, 8) -40.6908 eval(25080, 8) -46.8481\n",
      "mae np.exp train(49447, 18) test(15675, 18) -3.6638 eval(25080, 18) -3.7669\n",
      "mae np.exp train(71451, 9) test(15675, 9) -4.9058 eval(25080, 9) -5.0865\n",
      "mae np.exp train(71623, 10) test(15675, 10) -5.2088 eval(25080, 10) -4.6816\n",
      "mae np.exp train(79331, 7) test(15675, 7) -7.7261 eval(25080, 7) -7.8196\n",
      "mae np.exp train(80632, 11) test(15675, 11) -17.7479 eval(25080, 11) -18.7714\n",
      "mae np.exp train(80543, 6) test(15675, 6) -9.2078 eval(25080, 6) -9.4998\n",
      "mae np.exp train(80085, 8) test(15675, 8) -91.5325 eval(25080, 8) -112.2971\n",
      "mae np.exp train(80444, 6) test(15675, 6) -114.1257 eval(25080, 6) -146.0372\n",
      "mae np.exp train(55651, 6) test(15675, 6) -10.633 eval(25080, 6) -9.2208\n",
      "mae np.exp train(77086, 7) test(15675, 7) -127.3644 eval(25080, 7) -172.5865\n",
      "mae np.exp train(49660, 10) test(15675, 10) -4.8517 eval(25080, 10) -5.1698\n",
      "mae np.exp train(64570, 6) test(15675, 6) -10.2305 eval(25080, 6) -10.4964\n",
      "mae np.exp train(68668, 6) test(15675, 6) -121.645 eval(25080, 6) -183.1117\n",
      "mae np.exp train(64341, 11) test(15675, 11) -6.1031 eval(25080, 11) -6.3387\n",
      "mae np.exp train(65011, 7) test(15675, 7) -13.7821 eval(25080, 7) -14.5952\n",
      "mae np.exp train(58272, 9) test(15675, 9) -121.0874 eval(25080, 9) -159.447\n",
      "mae np.exp train(77631, 8) test(15675, 8) -5.0879 eval(25080, 8) -4.4134\n",
      "mae np.exp train(80087, 6) test(15675, 6) -8.7672 eval(25080, 6) -7.5148\n",
      "mae np.exp train(79950, 6) test(15675, 6) -8.7132 eval(25080, 6) -8.2531\n",
      "mae np.exp train(80719, 12) test(15675, 12) -10.8837 eval(25080, 12) -10.7224\n",
      "mae np.exp train(67215, 9) test(15670, 9) -8.8809 eval(25073, 9) -9.8384\n",
      "mae np.exp train(65220, 12) test(15675, 12) -9.8549 eval(25080, 12) -10.0261\n",
      "mae np.exp train(50155, 18) test(15675, 18) -2.5777 eval(25080, 18) -2.4788\n",
      "mae np.exp train(61691, 9) test(15675, 9) -114.0611 eval(25080, 9) -145.7652\n",
      "mae np.exp train(67352, 10) test(15675, 10) -8.8106 eval(25080, 10) -8.711\n",
      "mae np.exp train(71576, 10) test(15675, 10) -6.9032 eval(25080, 10) -6.6539\n",
      "mae np.exp train(52129, 10) test(15670, 10) -8.2122 eval(25073, 10) -8.3575\n",
      "mae np.exp train(55667, 12) test(15675, 12) -5.7521 eval(25080, 12) -5.8033\n",
      "mae np.exp train(77393, 10) test(15670, 10) -9.2405 eval(25073, 10) -9.6196\n",
      "mae np.exp train(81013, 8) test(15670, 8) -17.6677 eval(25073, 8) -18.1399\n",
      "mae np.exp train(71047, 10) test(15675, 10) -34.2848 eval(25080, 10) -34.5531\n",
      "mae np.exp train(79499, 7) test(15675, 7) -9.904 eval(25080, 7) -10.175\n",
      "mae np.exp train(49809, 20) test(15675, 20) -3.1644 eval(25080, 20) -3.1867\n",
      "mae np.exp train(53289, 14) test(15675, 14) -2.6846 eval(25080, 14) -2.5552\n",
      "mae np.exp train(79980, 9) test(15675, 9) -114.1791 eval(25080, 9) -153.9564\n",
      "mae np.exp train(79696, 9) test(15675, 9) -9.9157 eval(25080, 9) -10.2937\n",
      "mae np.exp train(48667, 17) test(15670, 17) -12.133 eval(25073, 17) -12.6203\n",
      "mae np.exp train(70602, 10) test(15675, 10) -6.1827 eval(25080, 10) -5.6559\n",
      "mae np.exp train(80442, 9) test(15675, 9) -11.8575 eval(25080, 9) -12.22\n",
      "mae np.exp train(61382, 8) test(15675, 8) -11.8644 eval(25080, 8) -12.3135\n",
      "mae np.exp train(68395, 7) test(15675, 7) -45.2965 eval(25080, 7) -46.5736\n",
      "mae np.exp train(79890, 8) test(15675, 8) -109.7732 eval(25080, 8) -591.761\n",
      "mae np.exp train(62331, 10) test(15675, 10) -6.8665 eval(25080, 10) -7.0706\n",
      "mae np.exp train(79955, 8) test(15675, 8) -130.7747 eval(25080, 8) -180.0814\n",
      "mae np.exp train(80573, 5) test(15675, 5) -3.4303 eval(25080, 5) -3.4358\n",
      "mae np.exp train(77978, 9) test(15675, 9) -7.202 eval(25080, 9) -7.5275\n",
      "mae np.exp train(79950, 9) test(15675, 9) -19.8843 eval(25080, 9) -19.8893\n",
      "mae np.exp train(49291, 9) test(15675, 9) -5.6556 eval(25080, 9) -5.9686\n",
      "mae np.exp train(80233, 10) test(15675, 10) -112.4187 eval(25080, 10) -142.9388\n",
      "mae np.exp train(61602, 10) test(15675, 10) -125.0701 eval(25080, 10) -167.1973\n",
      "mae np.exp train(79363, 7) test(15675, 7) -12.5213 eval(25080, 7) -12.3494\n",
      "mae np.exp train(83408, 6) test(15675, 6) -17.8217 eval(25080, 6) -17.7116\n",
      "mae np.exp train(55185, 8) test(15675, 8) -29.2596 eval(25080, 8) -32.0791\n",
      "mae np.exp train(79653, 9) test(15675, 9) -8.3012 eval(25080, 9) -8.7336\n",
      "mae np.exp train(80718, 12) test(15675, 12) -12.7208 eval(25080, 12) -10.9114\n",
      "mae np.exp train(74324, 11) test(15675, 11) -6.1744 eval(25080, 11) -6.3956\n",
      "mae np.exp train(48989, 8) test(15675, 8) -6.1226 eval(25080, 8) -6.4294\n",
      "mae np.exp train(68026, 9) test(15675, 9) -15.0763 eval(25080, 9) -15.3278\n",
      "mae np.exp train(71265, 11) test(15675, 11) -12.1359 eval(25080, 11) -10.7857\n",
      "mae np.exp train(55160, 9) test(15675, 9) -109.6855 eval(25080, 9) -586.3552\n",
      "mae np.exp train(58015, 11) test(15675, 11) -121.1203 eval(25080, 11) -159.8003\n",
      "mae np.exp train(67330, 9) test(15675, 9) -119.6786 eval(25080, 9) -157.1663\n",
      "mae np.exp train(62295, 9) test(15675, 9) -10.6223 eval(25080, 9) -10.5995\n",
      "mae np.exp train(65359, 10) test(15670, 10) -132.079 eval(25073, 10) -183.8667\n",
      "mae np.exp train(52766, 9) test(15675, 9) -6.0651 eval(25080, 9) -6.3993\n",
      "mae np.exp train(49247, 10) test(15675, 10) -13.7467 eval(25080, 10) -13.9927\n",
      "mae np.exp train(56034, 13) test(15670, 13) -7.7293 eval(25073, 13) -8.1444\n",
      "mae np.exp train(59076, 7) test(15675, 7) -40.4443 eval(25080, 7) -46.0984\n",
      "mae np.exp train(67288, 7) test(15675, 7) -12.3082 eval(25080, 7) -12.8139\n",
      "mae np.exp train(49119, 12) test(15670, 12) -9.3087 eval(25073, 12) -9.6707\n",
      "mae np.exp train(73158, 8) test(15675, 8) -27.7694 eval(25080, 8) -29.6158\n",
      "mae np.exp train(80213, 7) test(15675, 7) -117.5932 eval(25080, 7) -152.7538\n",
      "mae np.exp train(80460, 6) test(15675, 6) -109.7803 eval(25080, 6) -592.1709\n",
      "mae np.exp train(70750, 10) test(15675, 10) -9.1515 eval(25080, 10) -9.5307\n",
      "mae np.exp train(61072, 8) test(15675, 8) -5.069 eval(25080, 8) -5.3023\n",
      "mae np.exp train(49138, 7) test(15675, 7) -6.37 eval(25080, 7) -5.8535\n",
      "mae np.exp train(80048, 8) test(15675, 8) -111.8446 eval(25080, 8) -154.7529\n",
      "mae np.exp train(62583, 9) test(15675, 9) -17.6939 eval(25080, 9) -17.1476\n",
      "mae np.exp train(83722, 8) test(15675, 8) -24.0188 eval(25080, 8) -25.1303\n",
      "mae np.exp train(52553, 10) test(15675, 10) -112.3692 eval(25080, 10) -143.0089\n",
      "mae np.exp train(80403, 13) test(15675, 13) -5.6597 eval(25080, 13) -5.0073\n",
      "mae np.exp train(77806, 10) test(15675, 10) -8.6772 eval(25080, 10) -8.5848\n",
      "mae np.exp train(80358, 8) test(15675, 8) -7.1167 eval(25080, 8) -5.9306\n",
      "mae np.exp train(80951, 8) test(15675, 8) -11.7269 eval(25080, 8) -12.3446\n",
      "mae np.exp train(82196, 7) test(15675, 7) -11.7139 eval(25080, 7) -11.9683\n",
      "mae np.exp train(80857, 9) test(15675, 9) -7.7717 eval(25080, 9) -7.7513\n",
      "mae np.exp train(83710, 7) test(15675, 7) -9.2338 eval(25080, 7) -8.829\n",
      "mae np.exp train(55240, 10) test(15675, 10) -7.4191 eval(25080, 10) -7.6428\n",
      "mae np.exp train(77647, 8) test(15675, 8) -13.6462 eval(25080, 8) -12.5088\n",
      "mae np.exp train(71246, 10) test(15675, 10) -132.5983 eval(25080, 10) -184.6898\n",
      "mae np.exp train(61349, 9) test(15675, 9) -43.6995 eval(25080, 9) -50.3972\n",
      "mae np.exp train(73310, 8) test(15675, 8) -130.8097 eval(25080, 8) -180.5583\n",
      "mae np.exp train(71113, 11) test(15675, 11) -123.1386 eval(25080, 11) -165.0712\n",
      "mae np.exp train(73761, 9) test(15670, 9) -29.3571 eval(25073, 9) -33.2577\n",
      "mae np.exp train(80173, 10) test(15675, 10) -126.8586 eval(25080, 10) -171.109\n",
      "mae np.exp train(79383, 7) test(15675, 7) -129.8789 eval(25080, 7) -186.7969\n",
      "mae np.exp train(53107, 10) test(15675, 10) -11.0412 eval(25080, 10) -11.4076\n",
      "mae np.exp train(80061, 7) test(15675, 7) -8.0261 eval(25080, 7) -7.9874\n",
      "mae np.exp train(68278, 10) test(15675, 10) -114.7402 eval(25080, 10) -147.7348\n",
      "mae np.exp train(52787, 8) test(15675, 8) -6.2358 eval(25080, 8) -6.316\n",
      "mae np.exp train(55702, 8) test(15675, 8) -9.0201 eval(25080, 8) -8.0583\n",
      "mae np.exp train(80271, 9) test(15675, 9) -22.3338 eval(25080, 9) -21.1513\n",
      "mae np.exp train(49928, 19) test(15675, 19) -2.9069 eval(25080, 19) -2.8838\n",
      "mae np.exp train(52624, 7) test(15675, 7) -113.3658 eval(25080, 7) -144.9238\n",
      "mae np.exp train(80867, 7) test(15675, 7) -10.5923 eval(25080, 7) -10.5372\n",
      "mae np.exp train(79973, 7) test(15675, 7) -7.3246 eval(25080, 7) -7.3677\n",
      "mae np.exp train(77985, 12) test(15670, 12) -11.2674 eval(25073, 12) -9.2806\n",
      "mae np.exp train(67795, 11) test(15675, 11) -5.7915 eval(25080, 11) -5.3301\n",
      "mae np.exp train(58162, 6) test(15675, 6) -109.6794 eval(25080, 6) -585.9334\n",
      "mae np.exp train(68225, 9) test(15675, 9) -5.8921 eval(25080, 9) -5.5555\n",
      "mae np.exp train(80207, 7) test(15675, 7) -19.3497 eval(25080, 7) -19.9902\n",
      "mae np.exp train(62402, 7) test(15675, 7) -5.6322 eval(25080, 7) -5.8093\n",
      "mae np.exp train(81352, 5) test(15675, 5) -10.9327 eval(25080, 5) -11.0558\n",
      "mae np.exp train(79899, 7) test(15675, 7) -5.2676 eval(25080, 7) -5.4963\n",
      "mae np.exp train(84076, 8) test(15675, 8) -13.4544 eval(25080, 8) -13.836\n",
      "mae np.exp train(80606, 5) test(15675, 5) -112.1204 eval(25080, 5) -142.5394\n",
      "mae np.exp train(79540, 9) test(15675, 9) -109.6983 eval(25080, 9) -587.1962\n",
      "mae np.exp train(59464, 11) test(15675, 11) -3.7658 eval(25080, 11) -3.7133\n",
      "mae np.exp train(55328, 9) test(15675, 9) -11.5604 eval(25080, 9) -12.0503\n",
      "mae np.exp train(68337, 14) test(15675, 14) -3.0299 eval(25080, 14) -3.0423\n",
      "mae np.exp train(64941, 8) test(15675, 8) -16.2914 eval(25080, 8) -17.3063\n",
      "mae np.exp train(80851, 6) test(15675, 6) -18.2013 eval(25080, 6) -19.4614\n",
      "mae np.exp train(65244, 9) test(15675, 9) -9.0517 eval(25080, 9) -8.915\n",
      "mae np.exp train(74025, 8) test(15675, 8) -38.9044 eval(25080, 8) -41.691\n",
      "mae np.exp train(79799, 8) test(15675, 8) -109.7114 eval(25080, 8) -588.0338\n",
      "mae np.exp train(73371, 10) test(15670, 10) -118.3224 eval(25073, 10) -154.1729\n",
      "mae np.exp train(67809, 7) test(15675, 7) -119.039 eval(25080, 7) -155.6236\n",
      "mae np.exp train(79674, 6) test(15675, 6) -8.186 eval(25080, 6) -8.2327\n",
      "mae np.exp train(73500, 10) test(15675, 10) -4.0333 eval(25080, 10) -4.1901\n",
      "mae np.exp train(80433, 8) test(15675, 8) -7.2077 eval(25080, 8) -7.3428\n",
      "mae np.exp train(79991, 6) test(15675, 6) -22.2839 eval(25080, 6) -22.3073\n",
      "mae np.exp train(81060, 5) test(15675, 5) -12.7468 eval(25080, 5) -11.6006\n",
      "mae np.exp train(65296, 8) test(15675, 8) -9.3527 eval(25080, 8) -7.9394\n",
      "mae np.exp train(80309, 7) test(15675, 7) -9.8027 eval(25080, 7) -7.7239\n",
      "mae np.exp train(64236, 9) test(15675, 9) -23.9131 eval(25080, 9) -26.2067\n",
      "mae np.exp train(71498, 6) test(15675, 6) -132.1217 eval(25080, 6) -183.9233\n",
      "mae np.exp train(64532, 8) test(15670, 8) -17.8615 eval(25073, 8) -18.4241\n",
      "mae np.exp train(58199, 9) test(15675, 9) -126.0331 eval(25080, 9) -179.7681\n",
      "mae np.exp train(79397, 8) test(15675, 8) -6.1858 eval(25080, 8) -6.5262\n",
      "mae np.exp train(80389, 8) test(15675, 8) -108.0849 eval(25080, 8) -160.7733\n",
      "mae np.exp train(80947, 15) test(15675, 15) -3.0265 eval(25080, 15) -2.9714\n",
      "mae np.exp train(80423, 8) test(15675, 8) -126.1885 eval(25080, 8) -170.2639\n",
      "mae np.exp train(76946, 9) test(15675, 9) -4.8707 eval(25080, 9) -5.1491\n",
      "mae np.exp train(62326, 11) test(15675, 11) -8.2003 eval(25080, 11) -8.1503\n",
      "mae np.exp train(80354, 11) test(15670, 11) -17.4371 eval(25073, 11) -17.7224\n",
      "mae np.exp train(79898, 10) test(15670, 10) -10.2824 eval(25073, 10) -10.5211\n",
      "mae np.exp train(67657, 11) test(15675, 11) -5.331 eval(25080, 11) -4.9429\n",
      "mae np.exp train(67930, 8) test(15675, 8) -8.5436 eval(25080, 8) -7.7561\n",
      "mae np.exp train(83347, 5) test(15675, 5) -7.6779 eval(25080, 5) -8.1311\n",
      "mae np.exp train(79609, 5) test(15675, 5) -6.1395 eval(25080, 5) -6.433\n",
      "mae np.exp train(79231, 10) test(15675, 10) -11.5359 eval(25080, 10) -12.1939\n",
      "mae np.exp train(58784, 8) test(15675, 8) -112.3337 eval(25080, 8) -151.556\n",
      "mae np.exp train(79359, 7) test(15675, 7) -110.3133 eval(25080, 7) -139.0475\n",
      "mae np.exp train(80800, 10) test(15675, 10) -19.1945 eval(25080, 10) -19.0562\n",
      "mae np.exp train(84306, 7) test(15670, 7) -14.3001 eval(25073, 7) -14.7768\n",
      "mae np.exp train(83014, 5) test(15675, 5) -16.6293 eval(25080, 5) -16.1253\n",
      "mae np.exp train(76399, 11) test(15675, 11) -8.7374 eval(25080, 11) -9.3643\n",
      "mae np.exp train(83020, 7) test(15675, 7) -53.0256 eval(25080, 7) -62.2029\n",
      "mae np.exp train(76077, 10) test(15675, 10) -21.3624 eval(25080, 10) -22.1947\n",
      "mae np.exp train(70937, 8) test(15675, 8) -13.4701 eval(25080, 8) -13.7559\n",
      "mae np.exp train(80233, 7) test(15675, 7) -18.8856 eval(25080, 7) -20.1216\n",
      "mae np.exp train(79941, 7) test(15675, 7) -6.6639 eval(25080, 7) -7.0711\n",
      "mae np.exp train(80893, 9) test(15670, 9) -12.2415 eval(25073, 9) -12.9291\n",
      "mae np.exp train(80662, 8) test(15675, 8) -122.2407 eval(25080, 8) -162.0126\n",
      "mae np.exp train(68070, 10) test(15675, 10) -67.6293 eval(25080, 10) -79.5454\n",
      "mae np.exp train(58995, 7) test(15675, 7) -109.7248 eval(25080, 7) -588.8681\n",
      "mae np.exp train(79561, 8) test(15675, 8) -12.4961 eval(25080, 8) -13.0903\n",
      "mae np.exp train(80149, 9) test(15675, 9) -109.7453 eval(25080, 9) -590.113\n",
      "mae np.exp train(81136, 7) test(15675, 7) -33.1323 eval(25080, 7) -36.8553\n",
      "mae np.exp train(79753, 8) test(15670, 8) -7.0003 eval(25073, 8) -6.7444\n",
      "mae np.exp train(79613, 6) test(15675, 6) -111.4506 eval(25080, 6) -141.1584\n",
      "mae np.exp train(58535, 7) test(15675, 7) -28.0882 eval(25080, 7) -29.8408\n",
      "mae np.exp train(79718, 11) test(15675, 11) -4.8629 eval(25080, 11) -5.1571\n",
      "mae np.exp train(68217, 10) test(15675, 10) -5.7886 eval(25080, 10) -5.408\n",
      "mae np.exp train(80552, 11) test(15675, 11) -118.6311 eval(25080, 11) -160.3655\n",
      "mae np.exp train(80063, 7) test(15675, 7) -17.9763 eval(25080, 7) -16.5704\n",
      "mae np.exp train(80801, 7) test(15675, 7) -24.1719 eval(25080, 7) -25.8608\n",
      "mae np.exp train(80713, 9) test(15675, 9) -132.1405 eval(25080, 9) -184.1436\n",
      "mae np.exp train(76234, 9) test(15675, 9) -8.251 eval(25080, 9) -8.6711\n",
      "mae np.exp train(58857, 8) test(15675, 8) -20.2283 eval(25080, 8) -21.4338\n",
      "mae np.exp train(70884, 9) test(15675, 9) -4.4052 eval(25080, 9) -4.2237\n",
      "mae np.exp train(56179, 16) test(15675, 16) -137.2701 eval(25080, 16) -196.6702\n",
      "mae np.exp train(74017, 6) test(15675, 6) -9.7284 eval(25080, 6) -10.1391\n",
      "mae np.exp train(62182, 12) test(15675, 12) -7.7771 eval(25080, 12) -7.2172\n",
      "mae np.exp train(80760, 8) test(15675, 8) -5.437 eval(25080, 8) -4.8658\n",
      "mae np.exp train(80788, 6) test(15675, 6) -25.2421 eval(25080, 6) -25.5938\n",
      "mae np.exp train(59014, 8) test(15675, 8) -131.2311 eval(25080, 8) -181.3045\n",
      "mae np.exp train(79806, 10) test(15675, 10) -7.6463 eval(25080, 10) -7.9099\n",
      "mae np.exp train(80950, 8) test(15675, 8) -5.3844 eval(25080, 8) -5.4623\n",
      "mae np.exp train(80621, 7) test(15675, 7) -9.8436 eval(25080, 7) -10.1517\n",
      "mae np.exp train(83834, 8) test(15675, 8) -7.4985 eval(25080, 8) -7.5875\n",
      "mae np.exp train(65350, 7) test(15675, 7) -5.4593 eval(25080, 7) -5.2332\n",
      "mae np.exp train(80522, 8) test(15670, 8) -15.9233 eval(25073, 8) -14.928\n",
      "mae np.exp train(74673, 11) test(15675, 11) -11.3579 eval(25080, 11) -10.3112\n",
      "mae np.exp train(55979, 18) test(15675, 18) -3.6984 eval(25080, 18) -3.636\n",
      "mae np.exp train(55485, 11) test(15675, 11) -6.8432 eval(25080, 11) -7.1095\n",
      "mae np.exp train(81212, 9) test(15675, 9) -4.9744 eval(25080, 9) -4.4939\n",
      "mae np.exp train(59199, 11) test(15675, 11) -5.7354 eval(25080, 11) -4.7792\n",
      "mae np.exp train(74188, 7) test(15675, 7) -7.6647 eval(25080, 7) -7.6759\n",
      "mae np.exp train(79994, 7) test(15675, 7) -77.6581 eval(25080, 7) -96.0415\n",
      "mae np.exp train(80739, 10) test(15675, 10) -127.7537 eval(25080, 10) -173.6435\n",
      "mae np.exp train(80550, 6) test(15675, 6) -4.4854 eval(25080, 6) -4.5485\n",
      "mae np.exp train(55968, 9) test(15675, 9) -10.4285 eval(25080, 9) -10.1603\n",
      "mae np.exp train(80895, 7) test(15670, 7) -12.2959 eval(25073, 7) -13.3508\n",
      "mae np.exp train(61623, 10) test(15675, 10) -72.9549 eval(25080, 10) -97.9046\n",
      "mae np.exp train(62087, 11) test(15675, 11) -6.6614 eval(25080, 11) -6.5281\n",
      "mae np.exp train(73623, 8) test(15675, 8) -29.5408 eval(25080, 8) -29.3282\n",
      "mae np.exp train(80588, 7) test(15675, 7) -22.0311 eval(25080, 7) -22.6304\n",
      "mae np.exp train(65428, 9) test(15670, 9) -7.6498 eval(25073, 9) -7.9263\n",
      "mae np.exp train(79935, 8) test(15675, 8) -109.7803 eval(25080, 8) -592.1709\n",
      "mae np.exp train(61122, 10) test(15675, 10) -18.6865 eval(25080, 10) -18.7202\n",
      "mae np.exp train(73072, 9) test(15675, 9) -109.7181 eval(25080, 9) -588.4513\n",
      "mae np.exp train(80075, 7) test(15675, 7) -11.0859 eval(25080, 7) -11.386\n",
      "mae np.exp train(73618, 9) test(15675, 9) -38.3586 eval(25080, 9) -40.5524\n",
      "mae np.exp train(79554, 7) test(15675, 7) -9.937 eval(25080, 7) -10.0051\n",
      "mae np.exp train(79816, 9) test(15675, 9) -12.8589 eval(25080, 9) -13.1548\n",
      "mae np.exp train(80164, 7) test(15675, 7) -116.6301 eval(25080, 7) -169.7314\n",
      "mae np.exp train(74318, 9) test(15675, 9) -3.6677 eval(25080, 9) -3.6118\n",
      "mae np.exp train(76636, 9) test(15670, 9) -11.2826 eval(25073, 9) -11.6965\n",
      "mae np.exp train(61856, 10) test(15675, 10) -129.3227 eval(25080, 10) -176.3727\n",
      "mae np.exp train(53081, 8) test(15675, 8) -6.5652 eval(25080, 8) -6.7366\n",
      "mae np.exp train(58990, 12) test(15675, 12) -10.2418 eval(25080, 12) -8.993\n",
      "mae np.exp train(79469, 7) test(15675, 7) -12.336 eval(25080, 7) -12.0622\n",
      "mae np.exp train(79822, 9) test(15675, 9) -9.2899 eval(25080, 9) -9.6021\n",
      "mae np.exp train(80196, 10) test(15675, 10) -7.7056 eval(25080, 10) -7.3984\n",
      "mae np.exp train(64962, 9) test(15675, 9) -124.9957 eval(25080, 9) -180.2256\n",
      "mae np.exp train(67283, 8) test(15675, 8) -46.8452 eval(25080, 8) -54.2672\n",
      "mae np.exp train(55858, 19) test(15675, 19) -3.2751 eval(25080, 19) -3.3243\n",
      "mae np.exp train(80218, 8) test(15670, 8) -109.6668 eval(25073, 8) -585.4606\n",
      "mae np.exp train(68409, 10) test(15675, 10) -10.8212 eval(25080, 10) -11.0239\n",
      "mae np.exp train(82459, 6) test(15675, 6) -126.7142 eval(25080, 6) -171.305\n",
      "mae np.exp train(58304, 9) test(15675, 9) -23.3287 eval(25080, 9) -25.9121\n",
      "mae np.exp train(81173, 8) test(15675, 8) -118.1621 eval(25080, 8) -154.0476\n",
      "mae np.exp train(80726, 8) test(15675, 8) -23.9529 eval(25080, 8) -26.0349\n",
      "mae np.exp train(79379, 7) test(15675, 7) -8.2426 eval(25080, 7) -8.5656\n",
      "mae np.exp train(52968, 19) test(15675, 19) -2.9507 eval(25080, 19) -2.8859\n",
      "mae np.exp train(80222, 7) test(15675, 7) -4.3188 eval(25080, 7) -4.4381\n",
      "mae np.exp train(73647, 7) test(15675, 7) -4.8242 eval(25080, 7) -5.1455\n",
      "mae np.exp train(49655, 13) test(15670, 13) -20.9987 eval(25073, 13) -23.1885\n",
      "mae np.exp train(68440, 9) test(15675, 9) -26.3591 eval(25080, 9) -29.7774\n",
      "mae np.exp train(80372, 6) test(15675, 6) -19.6378 eval(25080, 6) -21.7393\n",
      "mae np.exp train(71109, 9) test(15675, 9) -8.1069 eval(25080, 9) -6.2655\n",
      "mae np.exp train(83507, 6) test(15675, 6) -5.9236 eval(25080, 6) -6.0736\n",
      "mae np.exp train(83918, 5) test(15675, 5) -26.0732 eval(25080, 5) -28.7703\n",
      "mae np.exp train(55774, 8) test(15675, 8) -124.5855 eval(25080, 8) -196.919\n",
      "mae np.exp train(80394, 6) test(15675, 6) -5.7267 eval(25080, 6) -6.0374\n",
      "mae np.exp train(65157, 8) test(15675, 8) -69.9672 eval(25080, 8) -75.724\n",
      "mae np.exp train(73452, 8) test(15675, 8) -10.5252 eval(25080, 8) -10.846\n",
      "mae np.exp train(67841, 8) test(15675, 8) -11.9656 eval(25080, 8) -12.5439\n",
      "mae np.exp train(67335, 10) test(15675, 10) -23.4314 eval(25080, 10) -26.194\n",
      "mae np.exp train(49022, 13) test(15670, 13) -127.9133 eval(25073, 13) -174.0313\n",
      "mae np.exp train(80542, 7) test(15675, 7) -132.5232 eval(25080, 7) -185.2041\n",
      "mae np.exp train(56113, 12) test(15670, 12) -5.4963 eval(25073, 12) -5.569\n",
      "mae np.exp train(83933, 8) test(15675, 8) -15.1857 eval(25080, 8) -13.4403\n",
      "mae np.exp train(79440, 7) test(15675, 7) -8.0566 eval(25080, 7) -8.0855\n",
      "mae np.exp train(80029, 6) test(15675, 6) -109.8096 eval(25080, 6) -593.8021\n",
      "mae np.exp train(68594, 5) test(15675, 5) -19.2926 eval(25080, 5) -20.8692\n",
      "mae np.exp train(80086, 11) test(15675, 11) -112.5825 eval(25080, 11) -143.3242\n",
      "mae np.exp train(83407, 7) test(15675, 7) -6.9096 eval(25080, 7) -7.2107\n",
      "mae np.exp train(80886, 10) test(15670, 10) -9.4848 eval(25073, 10) -9.897\n",
      "mae np.exp train(56011, 12) test(15675, 12) -115.164 eval(25080, 12) -148.6702\n",
      "mae np.exp train(80716, 7) test(15675, 7) -17.0314 eval(25080, 7) -17.4561\n",
      "mae np.exp train(58388, 9) test(15675, 9) -7.2493 eval(25080, 9) -7.6384\n",
      "mae np.exp train(80457, 9) test(15675, 9) -7.7011 eval(25080, 9) -7.6414\n",
      "mae np.exp train(80823, 8) test(15675, 8) -109.7248 eval(25080, 8) -588.8681\n",
      "mae np.exp train(80099, 10) test(15670, 10) -84.426 eval(25073, 10) -95.0705\n",
      "mae np.exp train(59040, 8) test(15675, 8) -113.8818 eval(25080, 8) -145.7814\n",
      "mae np.exp train(79500, 7) test(15675, 7) -8.4488 eval(25080, 7) -8.7679\n",
      "mae np.exp train(78286, 7) test(15675, 7) -5.5214 eval(25080, 7) -5.5517\n",
      "mae np.exp train(62133, 8) test(15675, 8) -109.7732 eval(25080, 8) -591.761\n",
      "mae np.exp train(83638, 6) test(15675, 6) -25.0909 eval(25080, 6) -25.5704\n",
      "mae np.exp train(71647, 10) test(15675, 10) -11.4208 eval(25080, 10) -9.044\n",
      "mae np.exp train(81197, 10) test(15675, 10) -10.5505 eval(25080, 10) -10.2672\n",
      "mae np.exp train(52080, 8) test(15675, 8) -5.4476 eval(25080, 8) -4.9915\n",
      "mae np.exp train(83135, 7) test(15675, 7) -5.7885 eval(25080, 7) -5.649\n",
      "mae np.exp train(80322, 7) test(15675, 7) -118.7407 eval(25080, 7) -155.414\n",
      "mae np.exp train(72037, 8) test(15675, 8) -109.7948 eval(25080, 8) -592.9881\n",
      "mae np.exp train(79899, 8) test(15675, 8) -7.2607 eval(25080, 8) -8.3122\n",
      "mae np.exp train(51925, 11) test(15675, 11) -128.5722 eval(25080, 11) -175.4109\n",
      "mae np.exp train(80042, 8) test(15675, 8) -14.1745 eval(25080, 8) -14.9772\n",
      "mae np.exp train(49523, 10) test(15675, 10) -8.5099 eval(25080, 10) -9.0335\n",
      "mae np.exp train(79972, 9) test(15675, 9) -7.7874 eval(25080, 9) -8.4484\n",
      "mae np.exp train(76860, 9) test(15675, 9) -7.6801 eval(25080, 9) -7.8452\n",
      "mae np.exp train(71174, 10) test(15670, 10) -131.7991 eval(25073, 10) -183.1748\n",
      "mae np.exp train(62263, 7) test(15675, 7) -3.0024 eval(25080, 7) -3.0443\n",
      "mae np.exp train(80217, 9) test(15675, 9) -125.6131 eval(25080, 9) -188.5628\n",
      "mae np.exp train(52516, 11) test(15670, 11) -8.4384 eval(25073, 11) -8.8537\n",
      "mae np.exp train(67420, 13) test(15670, 13) -124.6596 eval(25073, 13) -166.7372\n",
      "mae np.exp train(61462, 8) test(15675, 8) -26.3528 eval(25080, 8) -28.0345\n",
      "mae np.exp train(58851, 12) test(15670, 12) -5.2122 eval(25073, 12) -5.3243\n",
      "mae np.exp train(80857, 9) test(15670, 9) -15.5631 eval(25073, 9) -14.2875\n",
      "mae np.exp train(79347, 8) test(15675, 8) -11.1178 eval(25080, 8) -10.794\n",
      "mae np.exp train(58346, 10) test(15675, 10) -119.7151 eval(25080, 10) -157.0329\n",
      "mae np.exp train(77004, 9) test(15675, 9) -10.012 eval(25080, 9) -10.3363\n",
      "mae np.exp train(52192, 10) test(15675, 10) -126.2493 eval(25080, 10) -170.0255\n",
      "mae np.exp train(81320, 7) test(15675, 7) -109.7948 eval(25080, 7) -592.9881\n",
      "mae np.exp train(80571, 8) test(15675, 8) -9.0128 eval(25080, 8) -9.0358\n",
      "mae np.exp train(79925, 6) test(15675, 6) -10.9242 eval(25080, 6) -11.9746\n",
      "mae np.exp train(81289, 9) test(15675, 9) -17.9051 eval(25080, 9) -17.8372\n",
      "mae np.exp train(80289, 7) test(15670, 7) -3.518 eval(25073, 7) -3.5568\n",
      "mae np.exp train(58418, 10) test(15675, 10) -85.2373 eval(25080, 10) -101.5444\n",
      "mae np.exp train(79925, 9) test(15675, 9) -117.499 eval(25080, 9) -152.4672\n",
      "mae np.exp train(82868, 7) test(15675, 7) -8.8088 eval(25080, 7) -9.2673\n",
      "mae np.exp train(80614, 7) test(15675, 7) -20.6346 eval(25080, 7) -21.1805\n",
      "mae np.exp train(55830, 10) test(15675, 10) -5.1835 eval(25080, 10) -5.0464\n",
      "mae np.exp train(58823, 10) test(15675, 10) -113.2248 eval(25080, 10) -144.4658\n",
      "mae np.exp train(80701, 8) test(15675, 8) -22.3537 eval(25080, 8) -22.6176\n",
      "mae np.exp train(52840, 10) test(15675, 10) -9.6083 eval(25080, 10) -9.8846\n",
      "mae np.exp train(67015, 8) test(15675, 8) -35.3292 eval(25080, 8) -39.1845\n",
      "mae np.exp train(58243, 11) test(15675, 11) -123.828 eval(25080, 11) -165.1905\n",
      "mae np.exp train(79209, 4) test(15675, 4) -29.95 eval(25080, 4) -34.7773\n",
      "mae np.exp train(80905, 9) test(15670, 9) -11.4192 eval(25073, 9) -11.1229\n",
      "mae np.exp train(80728, 8) test(15675, 8) -4.9542 eval(25080, 8) -4.3624\n",
      "mae np.exp train(64843, 7) test(15675, 7) -12.4692 eval(25080, 7) -13.01\n",
      "mae np.exp train(82954, 7) test(15675, 7) -15.3612 eval(25080, 7) -15.855\n",
      "mae np.exp train(73787, 8) test(15675, 8) -129.0902 eval(25080, 8) -176.6118\n",
      "mae np.exp train(80609, 10) test(15675, 10) -7.7298 eval(25080, 10) -7.2691\n",
      "mae np.exp train(79545, 8) test(15670, 8) -8.3023 eval(25073, 8) -8.2756\n",
      "mae np.exp train(74447, 8) test(15675, 8) -109.88 eval(25080, 8) -597.4261\n",
      "mae np.exp train(48870, 13) test(15675, 13) -21.0302 eval(25080, 13) -21.1249\n",
      "mae np.exp train(77857, 9) test(15675, 9) -109.7732 eval(25080, 9) -591.761\n",
      "mae np.exp train(61750, 11) test(15675, 11) -8.4795 eval(25080, 11) -7.7639\n",
      "mae np.exp train(52893, 7) test(15675, 7) -8.6294 eval(25080, 7) -7.7018\n",
      "mae np.exp train(80078, 5) test(15675, 5) -7.8925 eval(25080, 5) -8.5484\n",
      "mae np.exp train(81145, 7) test(15675, 7) -124.5839 eval(25080, 7) -167.1563\n",
      "mae np.exp train(83390, 8) test(15675, 8) -26.6493 eval(25080, 8) -28.4916\n",
      "mae np.exp train(80415, 9) test(15675, 9) -15.4247 eval(25080, 9) -16.3174\n",
      "mae np.exp train(74699, 10) test(15675, 10) -7.9886 eval(25080, 10) -7.2426\n",
      "mae np.exp train(80812, 7) test(15675, 7) -6.4607 eval(25080, 7) -6.1148\n",
      "mae np.exp train(48736, 8) test(15670, 8) -39.4698 eval(25073, 8) -42.5287\n",
      "mae np.exp train(83904, 5) test(15675, 5) -4.6536 eval(25080, 5) -4.8424\n",
      "mae np.exp train(80067, 8) test(15675, 8) -7.982 eval(25080, 8) -8.1918\n",
      "mae np.exp train(80212, 8) test(15675, 8) -16.221 eval(25080, 8) -17.009\n",
      "mae np.exp train(55384, 10) test(15675, 10) -109.6671 eval(25080, 10) -585.0872\n",
      "mae np.exp train(80743, 10) test(15675, 10) -109.7803 eval(25080, 10) -592.1709\n",
      "mae np.exp train(70645, 7) test(15675, 7) -124.9746 eval(25080, 7) -167.9567\n",
      "mae np.exp train(71213, 6) test(15675, 6) -4.2686 eval(25080, 6) -4.2999\n",
      "mae np.exp train(81295, 8) test(15675, 8) -29.8033 eval(25080, 8) -31.6809\n",
      "mae np.exp train(61107, 10) test(15675, 10) -33.4699 eval(25080, 10) -38.1933\n",
      "mae np.exp train(80805, 6) test(15675, 6) -6.6215 eval(25080, 6) -6.681\n",
      "mae np.exp train(83847, 9) test(15675, 9) -117.1566 eval(25080, 9) -152.4558\n",
      "mae np.exp train(79556, 5) test(15675, 5) -10.6098 eval(25080, 5) -10.9916\n",
      "mae np.exp train(80607, 7) test(15675, 7) -8.3531 eval(25080, 7) -8.5017\n",
      "mae np.exp train(52870, 8) test(15675, 8) -7.4088 eval(25080, 8) -7.6738\n",
      "mae np.exp train(79962, 8) test(15675, 8) -109.7453 eval(25080, 8) -590.113\n",
      "mae np.exp train(68070, 7) test(15675, 7) -117.5976 eval(25080, 7) -153.616\n",
      "mae np.exp train(55379, 10) test(15675, 10) -6.7967 eval(25080, 10) -6.515\n",
      "mae np.exp train(65064, 9) test(15675, 9) -14.0539 eval(25080, 9) -14.6759\n",
      "mae np.exp train(52530, 8) test(15675, 8) -14.772 eval(25080, 8) -15.8401\n",
      "mae np.exp train(65365, 13) test(15675, 13) -2.8999 eval(25080, 13) -2.8653\n",
      "mae np.exp train(79833, 10) test(15675, 10) -4.7546 eval(25080, 10) -4.3757\n",
      "mae np.exp train(82775, 8) test(15675, 8) -6.3634 eval(25080, 8) -6.8589\n",
      "mae np.exp train(80775, 10) test(15675, 10) -6.1301 eval(25080, 10) -6.2413\n",
      "mae np.exp train(79918, 7) test(15675, 7) -109.7384 eval(25080, 7) -589.6989\n",
      "mae np.exp train(61778, 10) test(15675, 10) -7.1571 eval(25080, 10) -6.5864\n",
      "mae np.exp train(80142, 6) test(15675, 6) -5.4167 eval(25080, 6) -5.6881\n",
      "mae np.exp train(76823, 8) test(15675, 8) -128.9362 eval(25080, 8) -177.3609\n",
      "mae np.exp train(68243, 8) test(15675, 8) -8.2044 eval(25080, 8) -7.2921\n",
      "mae np.exp train(80896, 7) test(15675, 7) -109.7948 eval(25080, 7) -592.9881\n",
      "mae np.exp train(76681, 10) test(15675, 10) -20.5155 eval(25080, 10) -21.9838\n",
      "mae np.exp train(62106, 10) test(15675, 10) -14.604 eval(25080, 10) -13.5201\n",
      "mae np.exp train(83796, 7) test(15675, 7) -7.3318 eval(25080, 7) -7.2575\n",
      "mae np.exp train(64140, 9) test(15675, 9) -18.7832 eval(25080, 9) -20.227\n",
      "mae np.exp train(81179, 8) test(15675, 8) -6.3494 eval(25080, 8) -6.5343\n",
      "mae np.exp train(80245, 9) test(15675, 9) -18.1263 eval(25080, 9) -19.1336\n",
      "mae np.exp train(73838, 8) test(15675, 8) -109.6671 eval(25080, 8) -585.0872\n",
      "mae np.exp train(80609, 8) test(15675, 8) -23.9229 eval(25080, 8) -25.208\n",
      "mae np.exp train(81232, 9) test(15670, 9) -7.04 eval(25073, 9) -5.9806\n",
      "mae np.exp train(79556, 9) test(15675, 9) -130.1288 eval(25080, 9) -179.0896\n",
      "mae np.exp train(61533, 10) test(15675, 10) -115.6807 eval(25080, 10) -155.9465\n",
      "mae np.exp train(79969, 8) test(15675, 8) -68.2095 eval(25080, 8) -79.8026\n",
      "mae np.exp train(55414, 8) test(15675, 8) -16.0164 eval(25080, 8) -15.9929\n",
      "mae np.exp train(79387, 9) test(15675, 9) -8.7381 eval(25080, 9) -9.1412\n",
      "mae np.exp train(74413, 9) test(15675, 9) -26.2566 eval(25080, 9) -29.4723\n",
      "mae np.exp train(67663, 9) test(15675, 9) -16.3639 eval(25080, 9) -17.1327\n",
      "mae np.exp train(58118, 10) test(15675, 10) -9.8804 eval(25080, 10) -10.2071\n",
      "mae np.exp train(80683, 12) test(15675, 12) -21.3096 eval(25080, 12) -23.4428\n",
      "mae np.exp train(61666, 9) test(15675, 9) -10.4851 eval(25080, 9) -10.4306\n",
      "mae np.exp train(55851, 9) test(15675, 9) -14.0401 eval(25080, 9) -14.4876\n",
      "mae np.exp train(62043, 9) test(15675, 9) -13.5836 eval(25080, 9) -14.7228\n",
      "mae np.exp train(60948, 8) test(15675, 8) -109.7114 eval(25080, 8) -588.0338\n",
      "mae np.exp train(55503, 10) test(15675, 10) -26.7731 eval(25080, 10) -30.6085\n",
      "mae np.exp train(51925, 11) test(15670, 11) -7.8457 eval(25073, 11) -8.3016\n",
      "mae np.exp train(79324, 8) test(15675, 8) -8.0099 eval(25080, 8) -8.1326\n",
      "mae np.exp train(71226, 10) test(15670, 10) -6.0603 eval(25073, 10) -6.1226\n",
      "mae np.exp train(61018, 9) test(15675, 9) -7.635 eval(25080, 9) -7.906\n",
      "mae np.exp train(80358, 8) test(15675, 8) -117.6119 eval(25080, 8) -152.7682\n",
      "mae np.exp train(58739, 8) test(15675, 8) -17.0483 eval(25080, 8) -15.6631\n",
      "mae np.exp train(64370, 11) test(15670, 11) -5.4635 eval(25073, 11) -5.0069\n",
      "mae np.exp train(80740, 8) test(15675, 8) -16.9877 eval(25080, 8) -17.0126\n",
      "mae np.exp train(83964, 8) test(15675, 8) -63.9657 eval(25080, 8) -68.4689\n",
      "mae np.exp train(58685, 10) test(15675, 10) -119.2773 eval(25080, 10) -156.2936\n",
      "mae np.exp train(83078, 10) test(15675, 10) -7.9975 eval(25080, 10) -7.1178\n",
      "mae np.exp train(52124, 7) test(15675, 7) -8.6158 eval(25080, 7) -9.374\n",
      "mae np.exp train(65267, 9) test(15675, 9) -17.3865 eval(25080, 9) -16.2591\n",
      "mae np.exp train(80076, 8) test(15675, 8) -7.8985 eval(25080, 8) -7.8314\n",
      "mae np.exp train(80132, 6) test(15675, 6) -6.4864 eval(25080, 6) -6.833\n",
      "mae np.exp train(67786, 9) test(15675, 9) -6.8832 eval(25080, 9) -7.5638\n",
      "mae np.exp train(80682, 8) test(15675, 8) -21.9048 eval(25080, 8) -21.8029\n",
      "mae np.exp train(52861, 7) test(15675, 7) -9.2388 eval(25080, 7) -9.6717\n",
      "mae np.exp train(67389, 8) test(15675, 8) -109.7453 eval(25080, 8) -590.113\n",
      "mae np.exp train(64306, 8) test(15675, 8) -48.1037 eval(25080, 8) -52.2475\n",
      "mae np.exp train(79918, 8) test(15675, 8) -8.5727 eval(25080, 8) -8.7814\n",
      "mae np.exp train(78017, 8) test(15675, 8) -109.8245 eval(25080, 8) -594.613\n",
      "mae np.exp train(58857, 6) test(15675, 6) -115.8645 eval(25080, 6) -149.3366\n",
      "mae np.exp train(67916, 10) test(15675, 10) -67.2019 eval(25080, 10) -75.4329\n",
      "mae np.exp train(67686, 9) test(15675, 9) -129.5645 eval(25080, 9) -177.7758\n",
      "mae np.exp train(70032, 6) test(15675, 6) -5.7908 eval(25080, 6) -5.983\n",
      "mae np.exp train(58509, 10) test(15675, 10) -66.5666 eval(25080, 10) -95.3166\n",
      "mae np.exp train(73113, 7) test(15675, 7) -31.0358 eval(25080, 7) -33.5071\n",
      "mae np.exp train(80285, 5) test(15675, 5) -130.9289 eval(25080, 5) -180.3355\n",
      "mae np.exp train(67974, 9) test(15675, 9) -131.0745 eval(25080, 9) -192.345\n",
      "mae np.exp train(76640, 8) test(15675, 8) -7.7797 eval(25080, 8) -7.8689\n",
      "mae np.exp train(80138, 9) test(15675, 9) -11.6229 eval(25080, 9) -12.3554\n",
      "mae np.exp train(64639, 5) test(15675, 5) -14.6312 eval(25080, 5) -16.0538\n",
      "mae np.exp train(58509, 10) test(15675, 10) -9.0017 eval(25080, 10) -8.6853\n",
      "mae np.exp train(53083, 9) test(15675, 9) -29.4546 eval(25080, 9) -29.078\n",
      "mae np.exp train(80050, 8) test(15675, 8) -21.1101 eval(25080, 8) -21.1807\n",
      "mae np.exp train(64718, 7) test(15675, 7) -10.042 eval(25080, 7) -9.591\n",
      "mae np.exp train(61707, 8) test(15675, 8) -121.0149 eval(25080, 8) -159.614\n",
      "mae np.exp train(80522, 8) test(15675, 8) -8.7181 eval(25080, 8) -8.7667\n",
      "mae np.exp train(49419, 8) test(15675, 8) -15.0344 eval(25080, 8) -14.7241\n",
      "mae np.exp train(80703, 8) test(15675, 8) -8.7766 eval(25080, 8) -9.0387\n",
      "mae np.exp train(55980, 21) test(15675, 21) -3.0751 eval(25080, 21) -3.0815\n",
      "mae np.exp train(80407, 10) test(15675, 10) -5.6935 eval(25080, 10) -5.6993\n",
      "mae np.exp train(64532, 9) test(15675, 9) -11.7991 eval(25080, 9) -12.3482\n",
      "mae np.exp train(80257, 7) test(15675, 7) -10.7677 eval(25080, 7) -9.89\n",
      "mae np.exp train(58263, 10) test(15675, 10) -7.9264 eval(25080, 10) -7.6165\n",
      "mae np.exp train(80092, 8) test(15675, 8) -8.847 eval(25080, 8) -9.1869\n",
      "mae np.exp train(71003, 12) test(15670, 12) -6.9476 eval(25073, 12) -6.6582\n",
      "mae np.exp train(83620, 7) test(15675, 7) -109.7592 eval(25080, 7) -590.9387\n",
      "mae np.exp train(61432, 11) test(15675, 11) -9.3283 eval(25080, 11) -9.6397\n",
      "mae np.exp train(53105, 9) test(15675, 9) -33.1578 eval(25080, 9) -37.1769\n",
      "mae np.exp train(80178, 8) test(15675, 8) -10.5824 eval(25080, 8) -10.9647\n",
      "mae np.exp train(77613, 7) test(15675, 7) -8.1095 eval(25080, 7) -7.7422\n",
      "mae np.exp train(80574, 9) test(15675, 9) -109.7384 eval(25080, 9) -589.6989\n",
      "mae np.exp train(80984, 7) test(15675, 7) -13.1123 eval(25080, 7) -13.2906\n",
      "mae np.exp train(67666, 9) test(15675, 9) -7.0447 eval(25080, 9) -7.1675\n",
      "mae np.exp train(61498, 8) test(15675, 8) -7.1705 eval(25080, 8) -6.1685\n",
      "mae np.exp train(65023, 10) test(15675, 10) -124.5938 eval(25080, 10) -166.8385\n",
      "mae np.exp train(80137, 10) test(15675, 10) -14.9468 eval(25080, 10) -16.1157\n",
      "mae np.exp train(83359, 6) test(15675, 6) -23.0923 eval(25080, 6) -23.5174\n",
      "mae np.exp train(67793, 12) test(15675, 12) -114.8948 eval(25080, 12) -147.6458\n",
      "mae np.exp train(68621, 7) test(15675, 7) -109.7948 eval(25080, 7) -592.9881\n",
      "mae np.exp train(80364, 9) test(15675, 9) -134.1996 eval(25080, 9) -188.5176\n",
      "mae np.exp train(55726, 10) test(15675, 10) -31.9883 eval(25080, 10) -33.2992\n",
      "mae np.exp train(80105, 10) test(15675, 10) -7.4884 eval(25080, 10) -7.8412\n",
      "mae np.exp train(80181, 9) test(15675, 9) -120.0753 eval(25080, 9) -157.7388\n",
      "mae np.exp train(49489, 11) test(15675, 11) -3.4182 eval(25080, 11) -3.3132\n",
      "mae np.exp train(58747, 10) test(15675, 10) -6.4893 eval(25080, 10) -6.1146\n",
      "mae np.exp train(77739, 11) test(15675, 11) -18.386 eval(25080, 11) -18.7235\n",
      "mae np.exp train(79458, 9) test(15675, 9) -20.4282 eval(25080, 9) -21.7275\n",
      "mae np.exp train(65376, 8) test(15675, 8) -15.1665 eval(25080, 8) -16.3082\n",
      "mae np.exp train(79808, 11) test(15670, 11) -24.5336 eval(25073, 11) -22.9601\n",
      "mae np.exp train(68147, 9) test(15675, 9) -14.3346 eval(25080, 9) -14.8759\n",
      "mae np.exp train(58317, 9) test(15675, 9) -109.7875 eval(25080, 9) -592.58\n",
      "mae np.exp train(64872, 9) test(15675, 9) -12.6435 eval(25080, 9) -13.1463\n",
      "mae np.exp train(82751, 8) test(15675, 8) -10.2648 eval(25080, 8) -10.6315\n",
      "mae np.exp train(83263, 7) test(15675, 7) -7.4435 eval(25080, 7) -6.8148\n",
      "mae np.exp train(80129, 6) test(15675, 6) -4.6785 eval(25080, 6) -4.8098\n",
      "mae np.exp train(62264, 8) test(15675, 8) -111.3038 eval(25080, 8) -140.8867\n",
      "mae np.exp train(55307, 11) test(15675, 11) -28.6067 eval(25080, 11) -30.3182\n",
      "mae np.exp train(55317, 10) test(15675, 10) -11.2493 eval(25080, 10) -11.8717\n",
      "mae np.exp train(79766, 8) test(15675, 8) -6.6761 eval(25080, 8) -6.7625\n",
      "mae np.exp train(80263, 9) test(15675, 9) -8.8331 eval(25080, 9) -9.4091\n",
      "mae np.exp train(79599, 8) test(15675, 8) -14.9925 eval(25080, 8) -16.1857\n",
      "mae np.exp train(74312, 11) test(15675, 11) -8.0138 eval(25080, 11) -7.269\n",
      "mae np.exp train(64760, 8) test(15675, 8) -26.5478 eval(25080, 8) -28.3232\n",
      "mae np.exp train(79688, 7) test(15675, 7) -14.7491 eval(25080, 7) -14.9178\n",
      "mae np.exp train(79658, 7) test(15675, 7) -9.2432 eval(25080, 7) -9.727\n",
      "mae np.exp train(65046, 7) test(15675, 7) -4.0888 eval(25080, 7) -4.0708\n",
      "mae np.exp train(80801, 8) test(15675, 8) -109.8096 eval(25080, 8) -593.8021\n",
      "mae np.exp train(83489, 8) test(15675, 8) -6.1463 eval(25080, 8) -6.1956\n",
      "mae np.exp train(80246, 5) test(15675, 5) -15.4768 eval(25080, 5) -15.5175\n",
      "mae np.exp train(81233, 11) test(15675, 11) -9.1365 eval(25080, 11) -9.5366\n",
      "mae np.exp train(71277, 9) test(15675, 9) -9.5308 eval(25080, 9) -9.3351\n",
      "mae np.exp train(77815, 9) test(15675, 9) -6.5145 eval(25080, 9) -6.8538\n",
      "mae np.exp train(80328, 7) test(15675, 7) -119.7299 eval(25080, 7) -182.6829\n",
      "mae np.exp train(80809, 9) test(15670, 9) -8.2494 eval(25073, 9) -8.4624\n",
      "mae np.exp train(65712, 9) test(15675, 9) -5.3722 eval(25080, 9) -4.5913\n",
      "mae np.exp train(80926, 10) test(15670, 10) -5.2825 eval(25073, 10) -4.6513\n",
      "mae np.exp train(80851, 6) test(15675, 6) -19.0545 eval(25080, 6) -18.3481\n",
      "mae np.exp train(73587, 9) test(15675, 9) -13.357 eval(25080, 9) -13.575\n",
      "mae np.exp train(67525, 9) test(15675, 9) -5.4544 eval(25080, 9) -5.6687\n",
      "mae np.exp train(79837, 9) test(15675, 9) -117.1047 eval(25080, 9) -151.9187\n",
      "mae np.exp train(59084, 9) test(15675, 9) -7.7309 eval(25080, 9) -7.5358\n",
      "mae np.exp train(79705, 8) test(15675, 8) -109.6794 eval(25080, 8) -585.9334\n",
      "mae np.exp train(71072, 8) test(15675, 8) -25.8018 eval(25080, 8) -27.7368\n",
      "mae np.exp train(77381, 11) test(15675, 11) -10.8221 eval(25080, 11) -11.4963\n",
      "mae np.exp train(79491, 6) test(15670, 6) -7.1879 eval(25073, 6) -7.3977\n",
      "mae np.exp train(80491, 7) test(15675, 7) -126.1725 eval(25080, 7) -170.3399\n",
      "mae np.exp train(80640, 9) test(15675, 9) -7.8792 eval(25080, 9) -8.1339\n",
      "mae np.exp train(74040, 10) test(15675, 10) -6.3275 eval(25080, 10) -6.6319\n",
      "mae np.exp train(52712, 7) test(15675, 7) -21.6043 eval(25080, 7) -22.7606\n",
      "mae np.exp train(77014, 8) test(15675, 8) -6.3322 eval(25080, 8) -6.4063\n",
      "mae np.exp train(78038, 9) test(15675, 9) -6.2561 eval(25080, 9) -6.2784\n",
      "mae np.exp train(80003, 7) test(15675, 7) -21.9392 eval(25080, 7) -21.6661\n",
      "mae np.exp train(52843, 9) test(15675, 9) -109.8245 eval(25080, 9) -594.613\n",
      "mae np.exp train(80018, 7) test(15670, 7) -27.9157 eval(25073, 7) -29.999\n",
      "mae np.exp train(80665, 6) test(15675, 6) -11.2217 eval(25080, 6) -12.147\n",
      "mae np.exp train(80149, 7) test(15675, 7) -8.4365 eval(25080, 7) -8.3813\n",
      "mae np.exp train(64221, 8) test(15675, 8) -6.3938 eval(25080, 8) -5.8252\n",
      "mae np.exp train(79515, 7) test(15675, 7) -26.5542 eval(25080, 7) -27.4745\n",
      "mae np.exp train(79350, 10) test(15670, 10) -125.5265 eval(25073, 10) -168.6512\n",
      "mae np.exp train(70450, 8) test(15675, 8) -4.3176 eval(25080, 8) -4.4666\n",
      "mae np.exp train(80958, 9) test(15675, 9) -27.297 eval(25080, 9) -28.6341\n",
      "mae np.exp train(79522, 8) test(15675, 8) -12.2413 eval(25080, 8) -11.5533\n",
      "mae np.exp train(81179, 8) test(15675, 8) -55.0924 eval(25080, 8) -63.3808\n",
      "mae np.exp train(76720, 7) test(15675, 7) -5.1481 eval(25080, 7) -5.1574\n",
      "mae np.exp train(74692, 8) test(15675, 8) -34.9423 eval(25080, 8) -37.9003\n",
      "mae np.exp train(79540, 7) test(15675, 7) -24.5509 eval(25080, 7) -23.8998\n",
      "mae np.exp train(74503, 9) test(15675, 9) -9.4706 eval(25080, 9) -9.6871\n",
      "mae np.exp train(67768, 9) test(15675, 9) -17.9801 eval(25080, 9) -17.9996\n",
      "mae np.exp train(80716, 9) test(15670, 9) -25.8623 eval(25073, 9) -26.5851\n",
      "mae np.exp train(83264, 6) test(15675, 6) -6.0012 eval(25080, 6) -6.0174\n",
      "mae np.exp train(79372, 11) test(15670, 11) -12.6455 eval(25073, 11) -12.5642\n",
      "mae np.exp train(79356, 9) test(15675, 9) -128.254 eval(25080, 9) -174.4945\n",
      "mae np.exp train(79319, 9) test(15675, 9) -5.7756 eval(25080, 9) -5.7773\n",
      "mae np.exp train(80493, 6) test(15675, 6) -29.0339 eval(25080, 6) -30.3163\n",
      "mae np.exp train(80593, 10) test(15675, 10) -8.901 eval(25080, 10) -9.2497\n",
      "-0.024787913751838114\n"
     ]
    }
   ],
   "source": [
    "manage_features = ManageFeatures(feature_objects)\n",
    "manage_features.set_model_pbounds(model_pbounds)\n",
    "\n",
    "pbounds = manage_features.get_pbounds()\n",
    "\n",
    "pbounds = {**pbounds, 'lower_quantile': (0, 0.01), 'upper_quantile': (0.98, 1)}\n",
    "\n",
    "# acquisition_function = UtilityFunction(kind=\"ucb\")\n",
    "# acquisition_function = UtilityFunction(kind=\"poi\")\n",
    "# acquisition_function = UtilityFunction(kind=\"ucb\", kappa=0.1)\n",
    "# acquisition_function = UtilityFunction(kind=\"ucb\", kappa=1)\n",
    "# bounds_transformer = SequentialDomainReductionTransformer(minimum_window=0.5)\n",
    "\n",
    "objective = \"mae\"\n",
    "optimize_this_partial = partial(\n",
    "    optimize_this,\n",
    "    objective=objective,\n",
    "    pbounds=pbounds,\n",
    "    manage_data_split=manage_data_split,\n",
    "    manage_features=manage_features,\n",
    "    df_train=df_train,\n",
    "    build_callbacks=build_callbacks,\n",
    "    target_shift=0\n",
    ")\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=optimize_this_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=0,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=42,\n",
    "    # n_restarts_optimizer=50,\n",
    "    # bounds_transformer=bounds_transformer\n",
    ")\n",
    "\n",
    "# optimizer.set_gp_params(alpha=1e-2, n_restarts_optimizer=10)\n",
    "\n",
    "# load_logs(optimizer, logs=['../data/bayesian_optimizer/2023-03-05_14-19-15_logs.json'])\n",
    "\n",
    "# optimize_res = copy.deepcopy(optimizer.res)\n",
    "\n",
    "# df_optimizer_params = pd.DataFrame([x[\"params\"] for x in optimize_res])\n",
    "# df_optimizer_target = pd.DataFrame(\n",
    "#     [x[\"target\"] for x in optimize_res], columns=[\"target\"]\n",
    "# )\n",
    "\n",
    "# df_optimizer = pd.concat([df_optimizer_target, df_optimizer_params], axis=1)\n",
    "\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=optimize_this_partial,\n",
    "#     pbounds=pbounds,\n",
    "#     verbose=0,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "#     random_state=6,\n",
    "#     # bounds_transformer=bounds_transformer\n",
    "# )\n",
    "\n",
    "dt = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "logger = JSONLogger(path=\"../data/bayesian_optimizer/{}_logs.json\".format(dt))\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)\n",
    "\n",
    "# load_logs(optimizer, logs=[\"../data/bayesian_optimizer/2023-03-05_23-16-17_logs.json\"])\n",
    "\n",
    "# for idx, row in df_optimizer.sort_values(\"target\").tail(15).iterrows():\n",
    "#     optimizer.probe(\n",
    "#         params=optimize_res[idx][\"params\"]\n",
    "#     )\n",
    "\n",
    "# optimizer.set_gp_params(alpha=1, n_restarts_optimizer=10)\n",
    "optimizer.maximize(\n",
    "    init_points=20, n_iter=2000, \n",
    "    # acquisition_function=acquisition_function\n",
    ")\n",
    "\n",
    "print(optimizer.max[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b97d52a-8f13-4c53-99fc-29d86c4c65a3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae -75.89701859123127 -76.47537013717546\n",
      "train (25080, 13) eval (25080, 13) test (15675, 13)\n",
      "mae -80.33973469214504 -80.56631616342395\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -5.110388920027523 -5.096425411362867\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -25.838593148698973 -26.255594015680174\n",
      "train (25080, 7) eval (25080, 7) test (15675, 7)\n",
      "mae -8.5435102128912 -8.44279239370594\n",
      "train (25080, 4) eval (25080, 4) test (15675, 4)\n",
      "mae -8.514238249328105 -8.480635471445982\n",
      "train (25073, 12) eval (25073, 12) test (15670, 12)\n",
      "mae -43.30871784984235 -43.05880109662354\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -144.1429513469267 -4.312611648681245\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -84.7575129654299 -84.98978472075035\n",
      "train (25080, 14) eval (25080, 14) test (15675, 14)\n",
      "mae -6.377700244260449 -6.393772682706325\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -15.420186729198699 -15.40403720142901\n",
      "train (25080, 7) eval (25080, 7) test (15675, 7)\n",
      "mae -21.495528251940687 -21.324449994861848\n",
      "train (25073, 11) eval (25073, 11) test (15670, 11)\n",
      "mae -4.720749431835866 -4.6709321128485985\n",
      "train (25073, 9) eval (25073, 9) test (15670, 9)\n",
      "mae -93.16741593345166 -94.42538469226582\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -30.35335480861962 -30.414561371803465\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -80.87698059103613 -81.62160334350038\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -6.256473617378504 -6.178850489206946\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -93.51549594398507 -94.62013687048919\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -3.48570829869415 -3.5470427099579918\n",
      "train (25073, 18) eval (25073, 18) test (15670, 18)\n",
      "mae -4.491221269427087 -4.43800502609355\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -7.524741569780536 -7.4353263532682785\n",
      "train (25073, 13) eval (25073, 13) test (15670, 13)\n",
      "mae -6.0995253812754955 -5.580765936748098\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -5.8063951723600145 -5.683740472108729\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -91.24688553351925 -92.31361686850087\n",
      "train (25073, 13) eval (25073, 13) test (15670, 13)\n",
      "mae -9.386868110480746 -9.360885719943498\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -5.216398997161087 -5.226765692089466\n",
      "train (25080, 14) eval (25080, 14) test (15675, 14)\n",
      "mae -57.80347919969834 -57.41893263878418\n",
      "train (25073, 10) eval (25073, 10) test (15670, 10)\n",
      "mae -5.1866279784032185 -5.043223044925822\n",
      "train (25073, 18) eval (25073, 18) test (15670, 18)\n",
      "mae -4.324241331134096 -4.3682730908498915\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -9.242593592078697 -9.231131932371627\n",
      "train (25073, 10) eval (25073, 10) test (15670, 10)\n",
      "mae -145.04972576692805 -12.14506199202845\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -50.737802769997074 -50.96157359137885\n",
      "train (25080, 5) eval (25080, 5) test (15675, 5)\n",
      "mae -12.637589547723199 -12.566347563609998\n",
      "train (25073, 12) eval (25073, 12) test (15670, 12)\n",
      "mae -66.60597438128019 -66.91474704036611\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -3.1343399297664236 -3.1569857092206868\n",
      "train (25073, 10) eval (25073, 10) test (15670, 10)\n",
      "mae -6.32645439304138 -6.330447588706954\n",
      "train (25080, 4) eval (25080, 4) test (15675, 4)\n",
      "mae -4.2480664671482105 -4.097133470457275\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -15.209257369106004 -15.128206153046085\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -2.8335227701601062 -2.8178304160993686\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -15.488486068899222 -15.305285199365716\n",
      "train (25073, 12) eval (25073, 12) test (15670, 12)\n",
      "mae -54.26665707710603 -72.29542909506362\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -6.313913772104355 -6.182399769650071\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -4.735039213222808 -4.782895226054325\n",
      "train (25080, 7) eval (25080, 7) test (15675, 7)\n",
      "mae -15.04680402512303 -15.257497299101058\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -73.90142750548208 -74.26184624967112\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -3.8274426761864095 -3.868128239235949\n",
      "train (25073, 7) eval (25073, 7) test (15670, 7)\n",
      "mae -8.06929716241288 -7.99460804345469\n",
      "train (25073, 8) eval (25073, 8) test (15670, 8)\n",
      "mae -3.898384854536691 -3.841677057031413\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -87.81922405021538 -88.40982716166701\n",
      "train (25073, 9) eval (25073, 9) test (15670, 9)\n",
      "mae -25.13242410652819 -25.03679385615151\n",
      "train (25080, 14) eval (25080, 14) test (15675, 14)\n",
      "mae -5.849205663546648 -5.798748927125824\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -69.50016512798693 -69.94156347561123\n",
      "train (25080, 14) eval (25080, 14) test (15675, 14)\n",
      "mae -7.608717949625923 -7.595110170898644\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -2.042415542530198 -2.0957981319545635\n",
      "train (25080, 3) eval (25080, 3) test (15675, 3)\n",
      "mae -54.313559737697005 -54.553548643519385\n",
      "train (25073, 8) eval (25073, 8) test (15670, 8)\n",
      "mae -143.4607733754149 -3.0661326078025977\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -8.39272972491143 -8.45861820374193\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -3.5004048834294075 -3.4749891240538577\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -6.940924345789566 -7.004181206615576\n",
      "train (25080, 4) eval (25080, 4) test (15675, 4)\n",
      "mae -83.02452565765603 -83.20857984227267\n",
      "train (25073, 11) eval (25073, 11) test (15670, 11)\n",
      "mae -5.975668302712773 -5.886284164877358\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -54.27106597236908 -72.19120151061269\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -54.26544518127707 -72.32554188215474\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -5.204215259198306 -5.269473584501963\n",
      "train (25080, 7) eval (25080, 7) test (15675, 7)\n",
      "mae -7.653739363688416 -7.6464257146617225\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -76.28956636670056 -76.00929078591818\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -58.4912368373229 -58.54764090045074\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -54.26655062621843 -72.29806291664755\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -53.6484392901943 -54.104888590109745\n",
      "train (25073, 10) eval (25073, 10) test (15670, 10)\n",
      "mae -2.986027017607587 -2.9630894059187884\n",
      "train (25073, 12) eval (25073, 12) test (15670, 12)\n",
      "mae -12.548643781263257 -12.413435042950647\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -54.26106303475192 -72.25143908317395\n",
      "train (25073, 8) eval (25073, 8) test (15670, 8)\n",
      "mae -21.984707572750757 -21.905084330878022\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -5.055860705834994 -5.053477360177001\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -3.637682002675662 -3.734409140314635\n",
      "train (25073, 10) eval (25073, 10) test (15670, 10)\n",
      "mae -3.6560644777283424 -3.632620112690341\n",
      "train (25073, 10) eval (25073, 10) test (15670, 10)\n",
      "mae -142.76207552355237 -3.114205522130045\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -3.2053268304010536 -3.1959332972901016\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -6.237966160320503 -6.282116816438513\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -4.9191596292948265 -4.788823357163924\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -51.40837701880068 -51.507537440067594\n",
      "train (25080, 5) eval (25080, 5) test (15675, 5)\n",
      "mae -54.26465435403307 -72.34537057842066\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -5.731398292715069 -5.6954909964131\n",
      "train (25080, 13) eval (25080, 13) test (15675, 13)\n",
      "mae -10.642848260651043 -10.437531749931754\n",
      "train (25080, 7) eval (25080, 7) test (15675, 7)\n",
      "mae -2.7982032965669825 -2.8448766498770746\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -4.500395682111965 -4.465066085516979\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -3.925462836247946 -3.954370317100501\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -7.913080379225298 -7.578484402096642\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -6.165816457099983 -6.122354852184111\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -72.01843061892549 -72.46782160367815\n",
      "train (25073, 8) eval (25073, 8) test (15670, 8)\n",
      "mae -3.954998483210461 -4.04561465020564\n",
      "train (25073, 11) eval (25073, 11) test (15670, 11)\n",
      "mae -7.2810704277271014 -7.261067028530893\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -76.16658512424841 -76.73572517578451\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -4.05778188835415 -4.126181592312871\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -54.27533449349748 -72.1027050138469\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -34.609166237636124 -31.384634947730166\n",
      "train (25080, 7) eval (25080, 7) test (15675, 7)\n",
      "mae -54.27342734177571 -72.14069353353027\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -6.393068208341731 -6.308217966734133\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -16.874617863618152 -16.88089681670177\n",
      "train (25073, 13) eval (25073, 13) test (15670, 13)\n",
      "mae -3.778902733373374 -3.771845859601834\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -4.8219960779895645 -4.869779194183731\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -74.54707150619585 -75.0596570370443\n",
      "train (25080, 7) eval (25080, 7) test (15675, 7)\n",
      "mae -3.9893893445090423 -3.9016143809371195\n",
      "train (25080, 5) eval (25080, 5) test (15675, 5)\n",
      "mae -56.85123762432657 -56.47708204516946\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -5.628269542384127 -5.623911427380895\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -74.84710981371694 -75.10206527333891\n",
      "train (25080, 15) eval (25080, 15) test (15675, 15)\n",
      "mae -17.772711264238726 -16.681239006847907\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -143.12716927273436 -3.2415878964642886\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -4.010795244882442 -3.9283597924708413\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -8.72613080031032 -8.767170941444874\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -27.382916478147862 -26.989497667411058\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -4.848041113381505 -4.8388795221503775\n",
      "train (25080, 5) eval (25080, 5) test (15675, 5)\n",
      "mae -2.4075589896499006 -2.475051674822355\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -6.030859814370004 -5.872816184959936\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -66.00779299340593 -66.16487702036723\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -12.824279660636375 -12.832648949957063\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -4.5377775926426045 -4.44028156533739\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -3.66982853922389 -3.767782889102673\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -92.35711893599404 -92.8608260796981\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -11.347132755662916 -11.431585321395287\n",
      "train (25073, 11) eval (25073, 11) test (15670, 11)\n",
      "mae -72.57240000835586 -72.22471955153082\n",
      "train (25080, 6) eval (25080, 6) test (15675, 6)\n",
      "mae -20.474342259481723 -20.453673139180765\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -57.08237374785359 -57.21243606828805\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -4.283507603779136 -4.318198170681227\n",
      "train (25073, 14) eval (25073, 14) test (15670, 14)\n",
      "mae -5.488501358633291 -5.551905673810823\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -5.1237942620489365 -5.175003597867946\n",
      "train (25073, 13) eval (25073, 13) test (15670, 13)\n",
      "mae -60.44868265665308 -59.96589474116309\n",
      "train (25080, 11) eval (25080, 11) test (15675, 11)\n",
      "mae -5.130527624086942 -5.182347578901478\n",
      "train (25073, 11) eval (25073, 11) test (15670, 11)\n",
      "mae -3.2672247249922592 -3.337691148136853\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -47.8826860886911 -48.50943039291007\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -4.530478277884508 -4.553635036013694\n",
      "train (25073, 9) eval (25073, 9) test (15670, 9)\n",
      "mae -5.260137544135491 -5.100648902517023\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -46.91546156901402 -47.131278381863176\n",
      "train (25080, 7) eval (25080, 7) test (15675, 7)\n",
      "mae -6.866936595842872 -6.863518850347965\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -3.0320598179634555 -3.0292484579926255\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -79.6658066559756 -80.33661054620754\n",
      "train (25080, 13) eval (25080, 13) test (15675, 13)\n",
      "mae -69.76897630418516 -70.15809776863527\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -4.7999458397196015 -4.762395899265502\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -7.2557097084037965 -7.19320006432405\n",
      "train (25080, 15) eval (25080, 15) test (15675, 15)\n",
      "mae -95.35655348633202 -95.5763793315289\n",
      "train (25080, 13) eval (25080, 13) test (15675, 13)\n",
      "mae -5.39403177656947 -5.449114330547963\n",
      "train (25073, 6) eval (25073, 6) test (15670, 6)\n",
      "mae -7.465911164642035 -7.241987098527859\n",
      "train (25073, 9) eval (25073, 9) test (15670, 9)\n",
      "mae -9.416932112077511 -9.487599326907329\n",
      "train (25080, 8) eval (25080, 8) test (15675, 8)\n",
      "mae -3.865685852581664 -3.923758295313236\n",
      "train (25073, 12) eval (25073, 12) test (15670, 12)\n",
      "mae -5.893367283359393 -5.968016786703857\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -5.933889144906704 -6.012901341585641\n",
      "train (25080, 9) eval (25080, 9) test (15675, 9)\n",
      "mae -4.135361031510897 -4.153850034910026\n",
      "train (25080, 12) eval (25080, 12) test (15675, 12)\n",
      "mae -4.041772631350882 -4.085668112838645\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n",
      "mae -6.752324104866586 -6.75455862603106\n",
      "train (25080, 10) eval (25080, 10) test (15675, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m acquisition_function \u001B[38;5;241m=\u001B[39m UtilityFunction(kind\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mucb\u001B[39m\u001B[38;5;124m\"\u001B[39m, kappa\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_points\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43macquisition_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43macquisition_function\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/bayes_opt/bayesian_optimization.py:311\u001B[0m, in \u001B[0;36mBayesianOptimization.maximize\u001B[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001B[0m\n\u001B[1;32m    309\u001B[0m     x_probe \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuggest(util)\n\u001B[1;32m    310\u001B[0m     iteration \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_probe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlazy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bounds_transformer \u001B[38;5;129;01mand\u001B[39;00m iteration \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;66;03m# The bounds transformer should only modify the bounds after\u001B[39;00m\n\u001B[1;32m    315\u001B[0m     \u001B[38;5;66;03m# the init_points points (only for the true iterations)\u001B[39;00m\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_bounds(\n\u001B[1;32m    317\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bounds_transformer\u001B[38;5;241m.\u001B[39mtransform(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_space))\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/bayes_opt/bayesian_optimization.py:208\u001B[0m, in \u001B[0;36mBayesianOptimization.probe\u001B[0;34m(self, params, lazy)\u001B[0m\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_queue\u001B[38;5;241m.\u001B[39madd(params)\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 208\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_space\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch(Events\u001B[38;5;241m.\u001B[39mOPTIMIZATION_STEP)\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/bayes_opt/target_space.py:236\u001B[0m, in \u001B[0;36mTargetSpace.probe\u001B[0;34m(self, params)\u001B[0m\n\u001B[1;32m    234\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_as_array(params)\n\u001B[1;32m    235\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_keys, x))\n\u001B[0;32m--> 236\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constraint \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister(x, target)\n",
      "File \u001B[0;32m/mnt/e/data/godaddy-microbusiness-density-forecasting/notebooks/library/optimize_this.py:26\u001B[0m, in \u001B[0;36moptimize_this\u001B[0;34m(objective, pbounds, manage_data_split, manage_features, df_train, build_callbacks, print_loss, return_booster, **bayes_kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m         params[key] \u001B[38;5;241m=\u001B[39m _tuple[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# print(params)\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# print(bayes_kwargs)\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m lgb_train, lgb_eval, lgb_test, model_params, df_features, df_target \u001B[38;5;241m=\u001B[39m \u001B[43mmanage_data_split\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model_input\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmanage_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjective\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbayes_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbayes_kwargs\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# callbacks = build_callbacks()\u001B[39;00m\n\u001B[1;32m     31\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m build_callbacks(early_stopping\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m)\n",
      "File \u001B[0;32m/mnt/e/data/godaddy-microbusiness-density-forecasting/notebooks/library/classes/manage_data_split.py:54\u001B[0m, in \u001B[0;36mManageDataSplit.get_model_input\u001B[0;34m(self, manage_features, df_train, objective, bayes_kwargs)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model_input\u001B[39m(\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;28mself\u001B[39m, manage_features: ManageFeatures, df_train, objective\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, bayes_kwargs: \u001B[38;5;28mdict\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     53\u001B[0m ):\n\u001B[0;32m---> 54\u001B[0m     df_features \u001B[38;5;241m=\u001B[39m \u001B[43mmanage_features\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbayes_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     df_target \u001B[38;5;241m=\u001B[39m manage_features\u001B[38;5;241m.\u001B[39mgenerate_target(df_train)\n\u001B[1;32m     57\u001B[0m     dict_split_df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_data(df_features, df_target, objective)\n",
      "File \u001B[0;32m/mnt/e/data/godaddy-microbusiness-density-forecasting/notebooks/library/classes/manage_features.py:62\u001B[0m, in \u001B[0;36mManageFeatures.generate_features\u001B[0;34m(self, bay_params)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# Some features are used, some not\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m df_mapped_feature\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 62\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mfeature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdf_mapped_feature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf_mapped_feature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m        \u001B[49m\u001B[43mf_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfeature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_kwargs\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m     70\u001B[0m             r\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow_id\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     71\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll features need to have row_id as index\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     73\u001B[0m     res\u001B[38;5;241m.\u001B[39mappend(r)\n",
      "File \u001B[0;32m/mnt/e/data/godaddy-microbusiness-density-forecasting/notebooks/library/feature_func.py:28\u001B[0m, in \u001B[0;36mf_rolling_mean\u001B[0;34m(df, df_mapped_feature, target_col, f_col, groupby_col, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m     rolling_mean\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m rolling_mean\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_loop_new_cols\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_mapped_feature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_col\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroupby_col\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/mnt/e/data/godaddy-microbusiness-density-forecasting/notebooks/library/utils.py:144\u001B[0m, in \u001B[0;36m_loop_new_cols\u001B[0;34m(df, df_mapped_feature, f, target_col, groupby_col)\u001B[0m\n\u001B[1;32m    142\u001B[0m res \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, row \u001B[38;5;129;01min\u001B[39;00m df_mapped_feature\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[0;32m--> 144\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_col\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mround\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparams\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroupby_col\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     res\u001B[38;5;241m.\u001B[39mappend(r)\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mconcat(res, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/mnt/e/data/godaddy-microbusiness-density-forecasting/notebooks/library/feature_func.py:20\u001B[0m, in \u001B[0;36mf_rolling_mean.<locals>._f\u001B[0;34m(df, col, target_col, window, groupby_col)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_f\u001B[39m(df: pd\u001B[38;5;241m.\u001B[39mDataFrame, col: \u001B[38;5;28mstr\u001B[39m, target_col: \u001B[38;5;28mstr\u001B[39m, window: \u001B[38;5;28mint\u001B[39m, groupby_col: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m window \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWindow has to be above 0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     16\u001B[0m     rolling_mean \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     17\u001B[0m         \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mgroupby_col\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfirst_day_of_month\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mgroupby_col\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget_col\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrolling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwindow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mleft\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m---> 20\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;241m.\u001B[39mrename(col)\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     23\u001B[0m     )\n\u001B[1;32m     24\u001B[0m     rolling_mean\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m rolling_mean\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/window/rolling.py:2223\u001B[0m, in \u001B[0;36mRolling.mean\u001B[0;34m(self, numeric_only, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2221\u001B[0m maybe_warn_args_and_kwargs(\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, args, kwargs)\n\u001B[1;32m   2222\u001B[0m nv\u001B[38;5;241m.\u001B[39mvalidate_rolling_func(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, args, kwargs)\n\u001B[0;32m-> 2223\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2224\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2226\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2227\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2228\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/window/rolling.py:1551\u001B[0m, in \u001B[0;36mRollingAndExpandingMixin.mean\u001B[0;34m(self, numeric_only, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1549\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_numba_apply(sliding_mean, engine_kwargs)\n\u001B[1;32m   1550\u001B[0m window_func \u001B[38;5;241m=\u001B[39m window_aggregations\u001B[38;5;241m.\u001B[39mroll_mean\n\u001B[0;32m-> 1551\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1552\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwindow_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmean\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   1553\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/window/rolling.py:757\u001B[0m, in \u001B[0;36mBaseWindowGroupby._apply\u001B[0;34m(self, func, name, numeric_only, numba_args, **kwargs)\u001B[0m\n\u001B[1;32m    749\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\n\u001B[1;32m    750\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    751\u001B[0m     func: Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, Any],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    755\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    756\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m--> 757\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    758\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    759\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnumba_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    763\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    764\u001B[0m     \u001B[38;5;66;03m# Reconstruct the resulting MultiIndex\u001B[39;00m\n\u001B[1;32m    765\u001B[0m     \u001B[38;5;66;03m# 1st set of levels = group by labels\u001B[39;00m\n\u001B[1;32m    766\u001B[0m     \u001B[38;5;66;03m# 2nd set of levels = original DataFrame/Series index\u001B[39;00m\n\u001B[1;32m    767\u001B[0m     grouped_object_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/window/rolling.py:663\u001B[0m, in \u001B[0;36mBaseWindow._apply\u001B[0;34m(self, func, name, numeric_only, numba_args, **kwargs)\u001B[0m\n\u001B[1;32m    660\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msingle\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 663\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_blockwise\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhomogeneous_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    664\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    665\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_tablewise(homogeneous_func, name, numeric_only)\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/window/rolling.py:503\u001B[0m, in \u001B[0;36mBaseWindow._apply_blockwise\u001B[0;34m(self, homogeneous_func, name, numeric_only)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_numeric_only(name, numeric_only)\n\u001B[1;32m    502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selected_obj\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 503\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_series\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhomogeneous_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_data(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selected_obj, numeric_only)\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcount\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    507\u001B[0m     \u001B[38;5;66;03m# GH 12541: Special case for count where we support date-like types\u001B[39;00m\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/window/rolling.py:487\u001B[0m, in \u001B[0;36mBaseWindow._apply_series\u001B[0;34m(self, homogeneous_func, name)\u001B[0m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mNotImplementedError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    485\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DataError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo numeric types to aggregate\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m--> 487\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mhomogeneous_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    488\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_slice_axis_for_step(obj\u001B[38;5;241m.\u001B[39mindex, result)\n\u001B[1;32m    489\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor(result, index\u001B[38;5;241m=\u001B[39mindex, name\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mname)\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/window/rolling.py:658\u001B[0m, in \u001B[0;36mBaseWindow._apply.<locals>.homogeneous_func\u001B[0;34m(values)\u001B[0m\n\u001B[1;32m    655\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(x, start, end, min_periods, \u001B[38;5;241m*\u001B[39mnumba_args)\n\u001B[1;32m    657\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 658\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mcalc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    660\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/window/rolling.py:646\u001B[0m, in \u001B[0;36mBaseWindow._apply.<locals>.homogeneous_func.<locals>.calc\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    645\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalc\u001B[39m(x):\n\u001B[0;32m--> 646\u001B[0m     start, end \u001B[38;5;241m=\u001B[39m \u001B[43mwindow_indexer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_window_bounds\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    647\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    648\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_periods\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmin_periods\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcenter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcenter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclosed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    651\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    652\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    653\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_window_bounds(start, end, \u001B[38;5;28mlen\u001B[39m(x))\n\u001B[1;32m    655\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(x, start, end, min_periods, \u001B[38;5;241m*\u001B[39mnumba_args)\n",
      "File \u001B[0;32m~/mambaforge-pypy3/envs/dev/lib/python3.11/site-packages/pandas/core/indexers/objects.py:361\u001B[0m, in \u001B[0;36mGroupbyIndexer.get_window_bounds\u001B[0;34m(self, num_values, min_periods, center, closed, step)\u001B[0m\n\u001B[1;32m    353\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_indexer(\n\u001B[1;32m    354\u001B[0m     index_array\u001B[38;5;241m=\u001B[39mindex_array,\n\u001B[1;32m    355\u001B[0m     window_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size,\n\u001B[1;32m    356\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindexer_kwargs,\n\u001B[1;32m    357\u001B[0m )\n\u001B[1;32m    358\u001B[0m start, end \u001B[38;5;241m=\u001B[39m indexer\u001B[38;5;241m.\u001B[39mget_window_bounds(\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28mlen\u001B[39m(indices), min_periods, center, closed, step\n\u001B[1;32m    360\u001B[0m )\n\u001B[0;32m--> 361\u001B[0m start \u001B[38;5;241m=\u001B[39m start\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mint64)\n\u001B[1;32m    362\u001B[0m end \u001B[38;5;241m=\u001B[39m end\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mint64)\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(start) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\n\u001B[1;32m    364\u001B[0m     end\n\u001B[1;32m    365\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthese should be equal in length from get_window_bounds\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "acquisition_function = UtilityFunction(kind=\"ucb\", kappa=0.5)\n",
    "optimizer.maximize(\n",
    "    init_points=0, n_iter=2000, \n",
    "    acquisition_function=acquisition_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2bfb737-e995-4c54-8773-abc6170e97db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/bayesian_optimizer/2023-03-08_02-29-47_logs.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"../data/bayesian_optimizer/{}_logs.json\".format(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eacd0c85-26e6-46b9-90a2-850804b73ec4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_optimizer_params = pd.DataFrame([x['params'] for x in optimizer.res])\n",
    "df_optimizer_target = pd.DataFrame([x['target'] for x in optimizer.res], columns=['target'])\n",
    "\n",
    "df_optimizer = pd.concat([df_optimizer_target, df_optimizer_params], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea5a24f6-3ff3-46d4-b709-36f34f31a924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enabled_cols = [x for x in df_optimizer.columns if 'enabled_' in x]\n",
    "# df_optimizer[enabled_cols].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b763a7de-b558-430a-bba6-5eec6710e5af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>enabled_cfips_</th>\n",
       "      <th>enabled_cfips_microbusiness_density_rolling_mean_0</th>\n",
       "      <th>enabled_cfips_microbusiness_density_rolling_mean_1</th>\n",
       "      <th>enabled_cfips_microbusiness_density_rolling_mean_2</th>\n",
       "      <th>enabled_cfips_microbusiness_density_rolling_mean_3</th>\n",
       "      <th>enabled_county_</th>\n",
       "      <th>enabled_lat_</th>\n",
       "      <th>enabled_lng_</th>\n",
       "      <th>enabled_median_hh_inc_</th>\n",
       "      <th>enabled_microbusiness_density_diff_</th>\n",
       "      <th>enabled_microbusiness_density_pct_change_</th>\n",
       "      <th>enabled_microbusiness_density_shift_0</th>\n",
       "      <th>enabled_microbusiness_density_shift_1</th>\n",
       "      <th>enabled_microbusiness_density_shift_2</th>\n",
       "      <th>enabled_microbusiness_density_shift_3</th>\n",
       "      <th>enabled_original_microbusiness_density_shift_0</th>\n",
       "      <th>enabled_original_microbusiness_density_shift_1</th>\n",
       "      <th>enabled_original_microbusiness_density_shift_2</th>\n",
       "      <th>enabled_original_microbusiness_density_shift_3</th>\n",
       "      <th>enabled_pct_bb_</th>\n",
       "      <th>enabled_pct_college_</th>\n",
       "      <th>enabled_pct_foreign_born_</th>\n",
       "      <th>enabled_pct_it_workers_</th>\n",
       "      <th>enabled_rot_15_x_</th>\n",
       "      <th>enabled_rot_15_y_</th>\n",
       "      <th>enabled_rot_30_x_</th>\n",
       "      <th>enabled_rot_30_y_</th>\n",
       "      <th>enabled_rot_45_x_</th>\n",
       "      <th>enabled_rot_45_y_</th>\n",
       "      <th>enabled_state_</th>\n",
       "      <th>enabled_target_census_over_18_population_x1000_</th>\n",
       "      <th>enabled_target_census_population_x1000_</th>\n",
       "      <th>enabled_time_arrow_</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>lambda_l1</th>\n",
       "      <th>lambda_l2</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>lower_quantile</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>min_sum_hessian_in_leaf</th>\n",
       "      <th>num_iterations</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>params_cfips_microbusiness_density_rolling_mean_0</th>\n",
       "      <th>params_cfips_microbusiness_density_rolling_mean_1</th>\n",
       "      <th>params_cfips_microbusiness_density_rolling_mean_2</th>\n",
       "      <th>params_cfips_microbusiness_density_rolling_mean_3</th>\n",
       "      <th>params_microbusiness_density_shift_0</th>\n",
       "      <th>params_microbusiness_density_shift_1</th>\n",
       "      <th>params_microbusiness_density_shift_2</th>\n",
       "      <th>params_microbusiness_density_shift_3</th>\n",
       "      <th>params_original_microbusiness_density_shift_0</th>\n",
       "      <th>params_original_microbusiness_density_shift_1</th>\n",
       "      <th>params_original_microbusiness_density_shift_2</th>\n",
       "      <th>params_original_microbusiness_density_shift_3</th>\n",
       "      <th>path_smooth</th>\n",
       "      <th>upper_quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>-0.036237</td>\n",
       "      <td>0.882815</td>\n",
       "      <td>450.198362</td>\n",
       "      <td>0.795720</td>\n",
       "      <td>0.529293</td>\n",
       "      <td>0.019884</td>\n",
       "      <td>0.145980</td>\n",
       "      <td>0.206118</td>\n",
       "      <td>0.808912</td>\n",
       "      <td>0.291202</td>\n",
       "      <td>0.120747</td>\n",
       "      <td>0.328032</td>\n",
       "      <td>0.193926</td>\n",
       "      <td>0.232675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.468819</td>\n",
       "      <td>0.402029</td>\n",
       "      <td>0.067431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.746386</td>\n",
       "      <td>0.103699</td>\n",
       "      <td>0.489015</td>\n",
       "      <td>0.417343</td>\n",
       "      <td>0.291748</td>\n",
       "      <td>0.127420</td>\n",
       "      <td>0.309854</td>\n",
       "      <td>0.244378</td>\n",
       "      <td>0.163359</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.467289</td>\n",
       "      <td>0.133641</td>\n",
       "      <td>0.180508</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.610632</td>\n",
       "      <td>0.644818</td>\n",
       "      <td>0.031358</td>\n",
       "      <td>0.969019</td>\n",
       "      <td>108.968303</td>\n",
       "      <td>134.832860</td>\n",
       "      <td>1.712576</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>76.585341</td>\n",
       "      <td>1326.325342</td>\n",
       "      <td>323.015460</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>20.296026</td>\n",
       "      <td>1.620234</td>\n",
       "      <td>3.557352</td>\n",
       "      <td>1.704538</td>\n",
       "      <td>6.479380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.969252</td>\n",
       "      <td>7.655470</td>\n",
       "      <td>2.285911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.232797</td>\n",
       "      <td>8.497110</td>\n",
       "      <td>452.198852</td>\n",
       "      <td>0.999302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.036940</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>234.442983</td>\n",
       "      <td>0.442988</td>\n",
       "      <td>0.405021</td>\n",
       "      <td>0.358016</td>\n",
       "      <td>0.077524</td>\n",
       "      <td>0.410925</td>\n",
       "      <td>0.756191</td>\n",
       "      <td>0.049557</td>\n",
       "      <td>0.511296</td>\n",
       "      <td>0.197433</td>\n",
       "      <td>0.497688</td>\n",
       "      <td>0.506822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320625</td>\n",
       "      <td>0.343188</td>\n",
       "      <td>0.262035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936076</td>\n",
       "      <td>0.176021</td>\n",
       "      <td>0.108296</td>\n",
       "      <td>0.499658</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.541858</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.530516</td>\n",
       "      <td>0.023818</td>\n",
       "      <td>0.489869</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.419319</td>\n",
       "      <td>0.520253</td>\n",
       "      <td>0.256259</td>\n",
       "      <td>0.667763</td>\n",
       "      <td>0.627799</td>\n",
       "      <td>0.513982</td>\n",
       "      <td>0.739087</td>\n",
       "      <td>97.647669</td>\n",
       "      <td>424.056930</td>\n",
       "      <td>0.556111</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>93.796948</td>\n",
       "      <td>654.563838</td>\n",
       "      <td>483.238515</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>67.735334</td>\n",
       "      <td>1.600089</td>\n",
       "      <td>8.387131</td>\n",
       "      <td>4.241464</td>\n",
       "      <td>3.162764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.116762</td>\n",
       "      <td>4.997322</td>\n",
       "      <td>9.924016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.068960</td>\n",
       "      <td>2.303557</td>\n",
       "      <td>295.688732</td>\n",
       "      <td>0.996772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>-0.039043</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>213.081618</td>\n",
       "      <td>0.891956</td>\n",
       "      <td>0.546802</td>\n",
       "      <td>0.156231</td>\n",
       "      <td>0.547378</td>\n",
       "      <td>0.059538</td>\n",
       "      <td>0.873181</td>\n",
       "      <td>0.152099</td>\n",
       "      <td>0.033508</td>\n",
       "      <td>0.208690</td>\n",
       "      <td>0.199923</td>\n",
       "      <td>0.396123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>0.028221</td>\n",
       "      <td>0.441624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.607956</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.038816</td>\n",
       "      <td>0.243959</td>\n",
       "      <td>0.284043</td>\n",
       "      <td>0.038342</td>\n",
       "      <td>0.505452</td>\n",
       "      <td>0.336760</td>\n",
       "      <td>0.031231</td>\n",
       "      <td>0.076665</td>\n",
       "      <td>0.346940</td>\n",
       "      <td>0.378916</td>\n",
       "      <td>0.397857</td>\n",
       "      <td>0.386840</td>\n",
       "      <td>0.731973</td>\n",
       "      <td>0.915329</td>\n",
       "      <td>0.020934</td>\n",
       "      <td>0.621647</td>\n",
       "      <td>42.524265</td>\n",
       "      <td>277.590630</td>\n",
       "      <td>1.080909</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>20.619595</td>\n",
       "      <td>879.004232</td>\n",
       "      <td>433.440648</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>167.496949</td>\n",
       "      <td>9.400186</td>\n",
       "      <td>6.808991</td>\n",
       "      <td>1.295828</td>\n",
       "      <td>3.490004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.711313</td>\n",
       "      <td>3.889233</td>\n",
       "      <td>4.531573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.962882</td>\n",
       "      <td>7.933050</td>\n",
       "      <td>391.411732</td>\n",
       "      <td>0.983178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>-0.039473</td>\n",
       "      <td>0.810348</td>\n",
       "      <td>378.957633</td>\n",
       "      <td>0.586587</td>\n",
       "      <td>0.148818</td>\n",
       "      <td>0.312188</td>\n",
       "      <td>0.497603</td>\n",
       "      <td>0.517811</td>\n",
       "      <td>0.705311</td>\n",
       "      <td>0.343366</td>\n",
       "      <td>0.479607</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>0.500069</td>\n",
       "      <td>0.408370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105192</td>\n",
       "      <td>0.488155</td>\n",
       "      <td>0.338509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>0.185202</td>\n",
       "      <td>0.100411</td>\n",
       "      <td>0.104880</td>\n",
       "      <td>0.482190</td>\n",
       "      <td>0.261041</td>\n",
       "      <td>0.426480</td>\n",
       "      <td>0.407317</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.092989</td>\n",
       "      <td>0.338476</td>\n",
       "      <td>0.539963</td>\n",
       "      <td>0.264152</td>\n",
       "      <td>0.226271</td>\n",
       "      <td>0.793390</td>\n",
       "      <td>0.575494</td>\n",
       "      <td>0.392459</td>\n",
       "      <td>0.476613</td>\n",
       "      <td>180.722545</td>\n",
       "      <td>49.421819</td>\n",
       "      <td>0.011903</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>13.965846</td>\n",
       "      <td>1056.379885</td>\n",
       "      <td>103.438206</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>88.806857</td>\n",
       "      <td>3.861155</td>\n",
       "      <td>8.021494</td>\n",
       "      <td>1.047040</td>\n",
       "      <td>1.488755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.624923</td>\n",
       "      <td>4.171323</td>\n",
       "      <td>4.835619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.907654</td>\n",
       "      <td>8.132610</td>\n",
       "      <td>107.484023</td>\n",
       "      <td>0.997523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>-0.041960</td>\n",
       "      <td>0.980787</td>\n",
       "      <td>472.450989</td>\n",
       "      <td>0.450301</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.271682</td>\n",
       "      <td>0.518999</td>\n",
       "      <td>0.368802</td>\n",
       "      <td>0.408235</td>\n",
       "      <td>0.079007</td>\n",
       "      <td>0.215462</td>\n",
       "      <td>0.211603</td>\n",
       "      <td>0.273656</td>\n",
       "      <td>0.384955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.505330</td>\n",
       "      <td>0.455839</td>\n",
       "      <td>0.419501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796426</td>\n",
       "      <td>0.186542</td>\n",
       "      <td>0.261848</td>\n",
       "      <td>0.219883</td>\n",
       "      <td>0.373122</td>\n",
       "      <td>0.533641</td>\n",
       "      <td>0.136647</td>\n",
       "      <td>0.167823</td>\n",
       "      <td>0.073945</td>\n",
       "      <td>0.344412</td>\n",
       "      <td>0.424761</td>\n",
       "      <td>0.529831</td>\n",
       "      <td>0.431764</td>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.864762</td>\n",
       "      <td>0.978508</td>\n",
       "      <td>0.088180</td>\n",
       "      <td>0.682004</td>\n",
       "      <td>17.075982</td>\n",
       "      <td>121.664540</td>\n",
       "      <td>1.170692</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>70.460739</td>\n",
       "      <td>429.543495</td>\n",
       "      <td>422.239797</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>166.773483</td>\n",
       "      <td>3.912122</td>\n",
       "      <td>5.511245</td>\n",
       "      <td>5.014849</td>\n",
       "      <td>6.866023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.931244</td>\n",
       "      <td>7.822793</td>\n",
       "      <td>2.597802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.492968</td>\n",
       "      <td>8.278917</td>\n",
       "      <td>215.548618</td>\n",
       "      <td>0.983667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-0.041976</td>\n",
       "      <td>0.746352</td>\n",
       "      <td>51.491337</td>\n",
       "      <td>0.637995</td>\n",
       "      <td>0.327184</td>\n",
       "      <td>0.302564</td>\n",
       "      <td>0.531826</td>\n",
       "      <td>0.394414</td>\n",
       "      <td>0.647066</td>\n",
       "      <td>0.293325</td>\n",
       "      <td>0.122960</td>\n",
       "      <td>0.328632</td>\n",
       "      <td>0.261236</td>\n",
       "      <td>0.428946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269857</td>\n",
       "      <td>0.384704</td>\n",
       "      <td>0.475832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428246</td>\n",
       "      <td>0.136043</td>\n",
       "      <td>0.421242</td>\n",
       "      <td>0.068464</td>\n",
       "      <td>0.253784</td>\n",
       "      <td>0.212912</td>\n",
       "      <td>0.107234</td>\n",
       "      <td>0.464577</td>\n",
       "      <td>0.212352</td>\n",
       "      <td>0.423801</td>\n",
       "      <td>0.531821</td>\n",
       "      <td>0.055384</td>\n",
       "      <td>0.160150</td>\n",
       "      <td>0.303631</td>\n",
       "      <td>0.788177</td>\n",
       "      <td>0.675019</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>208.054024</td>\n",
       "      <td>347.772484</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>1.794119</td>\n",
       "      <td>231.782686</td>\n",
       "      <td>32.390526</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>78.231976</td>\n",
       "      <td>3.324344</td>\n",
       "      <td>7.492266</td>\n",
       "      <td>3.127598</td>\n",
       "      <td>2.455173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.065963</td>\n",
       "      <td>9.709920</td>\n",
       "      <td>9.101259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.322260</td>\n",
       "      <td>4.491572</td>\n",
       "      <td>235.956967</td>\n",
       "      <td>0.988124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>-0.043604</td>\n",
       "      <td>0.582655</td>\n",
       "      <td>137.688131</td>\n",
       "      <td>0.772320</td>\n",
       "      <td>0.337084</td>\n",
       "      <td>0.192653</td>\n",
       "      <td>0.099673</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.930199</td>\n",
       "      <td>0.040993</td>\n",
       "      <td>0.168161</td>\n",
       "      <td>0.035077</td>\n",
       "      <td>0.122276</td>\n",
       "      <td>0.503005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.308957</td>\n",
       "      <td>0.347486</td>\n",
       "      <td>0.185695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.524649</td>\n",
       "      <td>0.361055</td>\n",
       "      <td>0.312566</td>\n",
       "      <td>0.197330</td>\n",
       "      <td>0.127739</td>\n",
       "      <td>0.212992</td>\n",
       "      <td>0.449021</td>\n",
       "      <td>0.547641</td>\n",
       "      <td>0.065436</td>\n",
       "      <td>0.285910</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.515635</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.154953</td>\n",
       "      <td>0.965613</td>\n",
       "      <td>0.576344</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.952424</td>\n",
       "      <td>414.485889</td>\n",
       "      <td>340.614529</td>\n",
       "      <td>1.993864</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>116.522378</td>\n",
       "      <td>763.729713</td>\n",
       "      <td>37.128672</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>71.489390</td>\n",
       "      <td>9.922170</td>\n",
       "      <td>4.952574</td>\n",
       "      <td>8.371917</td>\n",
       "      <td>2.487921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.785486</td>\n",
       "      <td>7.032972</td>\n",
       "      <td>2.942463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.913684</td>\n",
       "      <td>2.550249</td>\n",
       "      <td>366.619781</td>\n",
       "      <td>0.992109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-0.043627</td>\n",
       "      <td>0.978151</td>\n",
       "      <td>158.855559</td>\n",
       "      <td>0.930154</td>\n",
       "      <td>0.546528</td>\n",
       "      <td>0.469570</td>\n",
       "      <td>0.464810</td>\n",
       "      <td>0.267742</td>\n",
       "      <td>0.950335</td>\n",
       "      <td>0.376901</td>\n",
       "      <td>0.546344</td>\n",
       "      <td>0.025064</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.201476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125579</td>\n",
       "      <td>0.428246</td>\n",
       "      <td>0.319880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.561084</td>\n",
       "      <td>0.060553</td>\n",
       "      <td>0.112762</td>\n",
       "      <td>0.471676</td>\n",
       "      <td>0.475132</td>\n",
       "      <td>0.512560</td>\n",
       "      <td>0.532920</td>\n",
       "      <td>0.154246</td>\n",
       "      <td>0.273851</td>\n",
       "      <td>0.492606</td>\n",
       "      <td>0.218295</td>\n",
       "      <td>0.342852</td>\n",
       "      <td>0.494612</td>\n",
       "      <td>0.281833</td>\n",
       "      <td>0.580523</td>\n",
       "      <td>0.790126</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.633106</td>\n",
       "      <td>371.363028</td>\n",
       "      <td>229.262183</td>\n",
       "      <td>0.771784</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>21.271507</td>\n",
       "      <td>1157.447114</td>\n",
       "      <td>55.501718</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>107.356916</td>\n",
       "      <td>1.129854</td>\n",
       "      <td>8.871831</td>\n",
       "      <td>7.571994</td>\n",
       "      <td>6.925989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.550417</td>\n",
       "      <td>9.509783</td>\n",
       "      <td>7.250359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.602937</td>\n",
       "      <td>9.250231</td>\n",
       "      <td>262.569990</td>\n",
       "      <td>0.994904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-0.044698</td>\n",
       "      <td>0.978585</td>\n",
       "      <td>299.282373</td>\n",
       "      <td>0.701418</td>\n",
       "      <td>0.038689</td>\n",
       "      <td>0.282951</td>\n",
       "      <td>0.126934</td>\n",
       "      <td>0.527541</td>\n",
       "      <td>0.763787</td>\n",
       "      <td>0.188018</td>\n",
       "      <td>0.068014</td>\n",
       "      <td>0.273380</td>\n",
       "      <td>0.165951</td>\n",
       "      <td>0.454600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131990</td>\n",
       "      <td>0.496386</td>\n",
       "      <td>0.176807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774734</td>\n",
       "      <td>0.528437</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.163647</td>\n",
       "      <td>0.225498</td>\n",
       "      <td>0.154988</td>\n",
       "      <td>0.492707</td>\n",
       "      <td>0.065224</td>\n",
       "      <td>0.119895</td>\n",
       "      <td>0.205706</td>\n",
       "      <td>0.547200</td>\n",
       "      <td>0.164725</td>\n",
       "      <td>0.334800</td>\n",
       "      <td>0.123427</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>0.505798</td>\n",
       "      <td>0.179243</td>\n",
       "      <td>0.501126</td>\n",
       "      <td>267.818325</td>\n",
       "      <td>170.329946</td>\n",
       "      <td>0.946312</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>68.396149</td>\n",
       "      <td>48.983105</td>\n",
       "      <td>124.924729</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>178.469176</td>\n",
       "      <td>4.261537</td>\n",
       "      <td>2.147131</td>\n",
       "      <td>7.526172</td>\n",
       "      <td>2.228887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.943117</td>\n",
       "      <td>8.521101</td>\n",
       "      <td>6.209608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.439866</td>\n",
       "      <td>2.807386</td>\n",
       "      <td>476.883943</td>\n",
       "      <td>0.988569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-0.045396</td>\n",
       "      <td>0.772191</td>\n",
       "      <td>85.963134</td>\n",
       "      <td>0.444898</td>\n",
       "      <td>0.345937</td>\n",
       "      <td>0.175044</td>\n",
       "      <td>0.430154</td>\n",
       "      <td>0.506307</td>\n",
       "      <td>0.875685</td>\n",
       "      <td>0.330793</td>\n",
       "      <td>0.429203</td>\n",
       "      <td>0.029159</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.121311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101594</td>\n",
       "      <td>0.070952</td>\n",
       "      <td>0.385816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954209</td>\n",
       "      <td>0.226404</td>\n",
       "      <td>0.221103</td>\n",
       "      <td>0.399593</td>\n",
       "      <td>0.245040</td>\n",
       "      <td>0.238515</td>\n",
       "      <td>0.147885</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.335764</td>\n",
       "      <td>0.052465</td>\n",
       "      <td>0.434698</td>\n",
       "      <td>0.471271</td>\n",
       "      <td>0.118880</td>\n",
       "      <td>0.636275</td>\n",
       "      <td>0.692315</td>\n",
       "      <td>0.105696</td>\n",
       "      <td>0.582267</td>\n",
       "      <td>218.078654</td>\n",
       "      <td>164.000955</td>\n",
       "      <td>0.543287</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-2.258863</td>\n",
       "      <td>178.538561</td>\n",
       "      <td>314.563973</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>168.898764</td>\n",
       "      <td>10.065733</td>\n",
       "      <td>4.693921</td>\n",
       "      <td>5.357342</td>\n",
       "      <td>9.429564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.794863</td>\n",
       "      <td>9.344924</td>\n",
       "      <td>6.601624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.124765</td>\n",
       "      <td>3.309190</td>\n",
       "      <td>242.680177</td>\n",
       "      <td>0.987716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.045644</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>267.844668</td>\n",
       "      <td>0.415299</td>\n",
       "      <td>0.081668</td>\n",
       "      <td>0.075534</td>\n",
       "      <td>0.224381</td>\n",
       "      <td>0.531544</td>\n",
       "      <td>0.749173</td>\n",
       "      <td>0.069062</td>\n",
       "      <td>0.337452</td>\n",
       "      <td>0.271928</td>\n",
       "      <td>0.300285</td>\n",
       "      <td>0.291893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.135446</td>\n",
       "      <td>0.043467</td>\n",
       "      <td>0.393285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506265</td>\n",
       "      <td>0.450673</td>\n",
       "      <td>0.187620</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.229497</td>\n",
       "      <td>0.298957</td>\n",
       "      <td>0.444100</td>\n",
       "      <td>0.495667</td>\n",
       "      <td>0.075212</td>\n",
       "      <td>0.462680</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.399723</td>\n",
       "      <td>0.067774</td>\n",
       "      <td>0.457964</td>\n",
       "      <td>0.733895</td>\n",
       "      <td>0.580729</td>\n",
       "      <td>0.189355</td>\n",
       "      <td>0.982443</td>\n",
       "      <td>156.312253</td>\n",
       "      <td>36.705594</td>\n",
       "      <td>0.163379</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>16.126177</td>\n",
       "      <td>51.932267</td>\n",
       "      <td>441.174466</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>56.300532</td>\n",
       "      <td>1.890383</td>\n",
       "      <td>7.800821</td>\n",
       "      <td>11.710723</td>\n",
       "      <td>8.010602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.615649</td>\n",
       "      <td>4.514266</td>\n",
       "      <td>7.307728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.112233</td>\n",
       "      <td>8.835890</td>\n",
       "      <td>71.498466</td>\n",
       "      <td>0.990973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-0.045794</td>\n",
       "      <td>0.928950</td>\n",
       "      <td>456.460893</td>\n",
       "      <td>0.463258</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.279037</td>\n",
       "      <td>0.370191</td>\n",
       "      <td>0.367242</td>\n",
       "      <td>0.985039</td>\n",
       "      <td>0.087177</td>\n",
       "      <td>0.180161</td>\n",
       "      <td>0.219384</td>\n",
       "      <td>0.512832</td>\n",
       "      <td>0.383977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130849</td>\n",
       "      <td>0.281454</td>\n",
       "      <td>0.138519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.427285</td>\n",
       "      <td>0.394137</td>\n",
       "      <td>0.260713</td>\n",
       "      <td>0.121322</td>\n",
       "      <td>0.237264</td>\n",
       "      <td>0.496930</td>\n",
       "      <td>0.486624</td>\n",
       "      <td>0.445844</td>\n",
       "      <td>0.159906</td>\n",
       "      <td>0.512598</td>\n",
       "      <td>0.190642</td>\n",
       "      <td>0.432718</td>\n",
       "      <td>0.057594</td>\n",
       "      <td>0.360182</td>\n",
       "      <td>0.957271</td>\n",
       "      <td>0.972243</td>\n",
       "      <td>0.326094</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>47.170751</td>\n",
       "      <td>325.732336</td>\n",
       "      <td>0.469351</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>67.576119</td>\n",
       "      <td>620.228702</td>\n",
       "      <td>57.128993</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>143.211056</td>\n",
       "      <td>3.415403</td>\n",
       "      <td>1.743452</td>\n",
       "      <td>3.916662</td>\n",
       "      <td>8.831041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.059395</td>\n",
       "      <td>8.064110</td>\n",
       "      <td>6.643205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.422200</td>\n",
       "      <td>3.102789</td>\n",
       "      <td>78.732770</td>\n",
       "      <td>0.988243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.046405</td>\n",
       "      <td>0.848802</td>\n",
       "      <td>68.582147</td>\n",
       "      <td>0.993918</td>\n",
       "      <td>0.517803</td>\n",
       "      <td>0.190859</td>\n",
       "      <td>0.447192</td>\n",
       "      <td>0.151250</td>\n",
       "      <td>0.836694</td>\n",
       "      <td>0.321638</td>\n",
       "      <td>0.067272</td>\n",
       "      <td>0.224642</td>\n",
       "      <td>0.042406</td>\n",
       "      <td>0.267731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512489</td>\n",
       "      <td>0.085679</td>\n",
       "      <td>0.373776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595448</td>\n",
       "      <td>0.506160</td>\n",
       "      <td>0.228692</td>\n",
       "      <td>0.251901</td>\n",
       "      <td>0.320998</td>\n",
       "      <td>0.476065</td>\n",
       "      <td>0.410902</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>0.244290</td>\n",
       "      <td>0.522550</td>\n",
       "      <td>0.364258</td>\n",
       "      <td>0.312321</td>\n",
       "      <td>0.160552</td>\n",
       "      <td>0.258222</td>\n",
       "      <td>0.997456</td>\n",
       "      <td>0.498623</td>\n",
       "      <td>0.437421</td>\n",
       "      <td>0.945813</td>\n",
       "      <td>100.572120</td>\n",
       "      <td>88.717461</td>\n",
       "      <td>1.873116</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>66.220218</td>\n",
       "      <td>1264.235553</td>\n",
       "      <td>494.817500</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>113.614797</td>\n",
       "      <td>7.008619</td>\n",
       "      <td>3.968640</td>\n",
       "      <td>5.524310</td>\n",
       "      <td>3.002475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.579866</td>\n",
       "      <td>6.421961</td>\n",
       "      <td>6.847635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.228899</td>\n",
       "      <td>8.053394</td>\n",
       "      <td>459.631351</td>\n",
       "      <td>0.991430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>-0.046592</td>\n",
       "      <td>0.920875</td>\n",
       "      <td>331.240352</td>\n",
       "      <td>0.425510</td>\n",
       "      <td>0.359788</td>\n",
       "      <td>0.450275</td>\n",
       "      <td>0.507394</td>\n",
       "      <td>0.303479</td>\n",
       "      <td>0.674087</td>\n",
       "      <td>0.384421</td>\n",
       "      <td>0.298872</td>\n",
       "      <td>0.449515</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.523702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.371190</td>\n",
       "      <td>0.294713</td>\n",
       "      <td>0.377727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.901433</td>\n",
       "      <td>0.151616</td>\n",
       "      <td>0.404121</td>\n",
       "      <td>0.035313</td>\n",
       "      <td>0.449077</td>\n",
       "      <td>0.075916</td>\n",
       "      <td>0.399819</td>\n",
       "      <td>0.414313</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.097858</td>\n",
       "      <td>0.482732</td>\n",
       "      <td>0.305038</td>\n",
       "      <td>0.293564</td>\n",
       "      <td>0.292562</td>\n",
       "      <td>0.951759</td>\n",
       "      <td>0.479983</td>\n",
       "      <td>0.492187</td>\n",
       "      <td>0.073926</td>\n",
       "      <td>224.330663</td>\n",
       "      <td>105.282489</td>\n",
       "      <td>0.778729</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>114.169634</td>\n",
       "      <td>705.178639</td>\n",
       "      <td>491.810637</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>140.081682</td>\n",
       "      <td>6.760191</td>\n",
       "      <td>9.895542</td>\n",
       "      <td>1.967320</td>\n",
       "      <td>6.366098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.592732</td>\n",
       "      <td>2.454060</td>\n",
       "      <td>6.492008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.196508</td>\n",
       "      <td>5.145977</td>\n",
       "      <td>104.203144</td>\n",
       "      <td>0.994697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>-0.046594</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>247.523178</td>\n",
       "      <td>0.568976</td>\n",
       "      <td>0.280854</td>\n",
       "      <td>0.191817</td>\n",
       "      <td>0.524434</td>\n",
       "      <td>0.270936</td>\n",
       "      <td>0.718578</td>\n",
       "      <td>0.126917</td>\n",
       "      <td>0.205057</td>\n",
       "      <td>0.398031</td>\n",
       "      <td>0.194612</td>\n",
       "      <td>0.374216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.432810</td>\n",
       "      <td>0.204876</td>\n",
       "      <td>0.262176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.541275</td>\n",
       "      <td>0.463012</td>\n",
       "      <td>0.334214</td>\n",
       "      <td>0.314931</td>\n",
       "      <td>0.390598</td>\n",
       "      <td>0.093340</td>\n",
       "      <td>0.434621</td>\n",
       "      <td>0.309250</td>\n",
       "      <td>0.458009</td>\n",
       "      <td>0.115247</td>\n",
       "      <td>0.165891</td>\n",
       "      <td>0.399283</td>\n",
       "      <td>0.101980</td>\n",
       "      <td>0.200339</td>\n",
       "      <td>0.841751</td>\n",
       "      <td>0.764927</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>0.845458</td>\n",
       "      <td>233.165964</td>\n",
       "      <td>122.784035</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>124.398886</td>\n",
       "      <td>311.664199</td>\n",
       "      <td>105.534494</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>196.413851</td>\n",
       "      <td>2.703997</td>\n",
       "      <td>1.475677</td>\n",
       "      <td>4.586709</td>\n",
       "      <td>5.986706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.289569</td>\n",
       "      <td>7.913245</td>\n",
       "      <td>4.121886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.985537</td>\n",
       "      <td>7.688638</td>\n",
       "      <td>472.336103</td>\n",
       "      <td>0.992840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target  bagging_fraction  bagging_freq  enabled_cfips_  \\\n",
       "439  -0.036237          0.882815    450.198362        0.795720   \n",
       "64   -0.036940          0.834705    234.442983        0.442988   \n",
       "756  -0.039043          0.973046    213.081618        0.891956   \n",
       "1064 -0.039473          0.810348    378.957633        0.586587   \n",
       "363  -0.041960          0.980787    472.450989        0.450301   \n",
       "232  -0.041976          0.746352     51.491337        0.637995   \n",
       "729  -0.043604          0.582655    137.688131        0.772320   \n",
       "220  -0.043627          0.978151    158.855559        0.930154   \n",
       "324  -0.044698          0.978585    299.282373        0.701418   \n",
       "176  -0.045396          0.772191     85.963134        0.444898   \n",
       "345  -0.045644          0.650595    267.844668        0.415299   \n",
       "568  -0.045794          0.928950    456.460893        0.463258   \n",
       "89   -0.046405          0.848802     68.582147        0.993918   \n",
       "1152 -0.046592          0.920875    331.240352        0.425510   \n",
       "618  -0.046594          0.761079    247.523178        0.568976   \n",
       "\n",
       "      enabled_cfips_microbusiness_density_rolling_mean_0  \\\n",
       "439                                            0.529293    \n",
       "64                                             0.405021    \n",
       "756                                            0.546802    \n",
       "1064                                           0.148818    \n",
       "363                                            0.008000    \n",
       "232                                            0.327184    \n",
       "729                                            0.337084    \n",
       "220                                            0.546528    \n",
       "324                                            0.038689    \n",
       "176                                            0.345937    \n",
       "345                                            0.081668    \n",
       "568                                            0.003091    \n",
       "89                                             0.517803    \n",
       "1152                                           0.359788    \n",
       "618                                            0.280854    \n",
       "\n",
       "      enabled_cfips_microbusiness_density_rolling_mean_1  \\\n",
       "439                                            0.019884    \n",
       "64                                             0.358016    \n",
       "756                                            0.156231    \n",
       "1064                                           0.312188    \n",
       "363                                            0.271682    \n",
       "232                                            0.302564    \n",
       "729                                            0.192653    \n",
       "220                                            0.469570    \n",
       "324                                            0.282951    \n",
       "176                                            0.175044    \n",
       "345                                            0.075534    \n",
       "568                                            0.279037    \n",
       "89                                             0.190859    \n",
       "1152                                           0.450275    \n",
       "618                                            0.191817    \n",
       "\n",
       "      enabled_cfips_microbusiness_density_rolling_mean_2  \\\n",
       "439                                            0.145980    \n",
       "64                                             0.077524    \n",
       "756                                            0.547378    \n",
       "1064                                           0.497603    \n",
       "363                                            0.518999    \n",
       "232                                            0.531826    \n",
       "729                                            0.099673    \n",
       "220                                            0.464810    \n",
       "324                                            0.126934    \n",
       "176                                            0.430154    \n",
       "345                                            0.224381    \n",
       "568                                            0.370191    \n",
       "89                                             0.447192    \n",
       "1152                                           0.507394    \n",
       "618                                            0.524434    \n",
       "\n",
       "      enabled_cfips_microbusiness_density_rolling_mean_3  enabled_county_  \\\n",
       "439                                            0.206118          0.808912   \n",
       "64                                             0.410925          0.756191   \n",
       "756                                            0.059538          0.873181   \n",
       "1064                                           0.517811          0.705311   \n",
       "363                                            0.368802          0.408235   \n",
       "232                                            0.394414          0.647066   \n",
       "729                                            0.003279          0.930199   \n",
       "220                                            0.267742          0.950335   \n",
       "324                                            0.527541          0.763787   \n",
       "176                                            0.506307          0.875685   \n",
       "345                                            0.531544          0.749173   \n",
       "568                                            0.367242          0.985039   \n",
       "89                                             0.151250          0.836694   \n",
       "1152                                           0.303479          0.674087   \n",
       "618                                            0.270936          0.718578   \n",
       "\n",
       "      enabled_lat_  enabled_lng_  enabled_median_hh_inc_  \\\n",
       "439       0.291202      0.120747                0.328032   \n",
       "64        0.049557      0.511296                0.197433   \n",
       "756       0.152099      0.033508                0.208690   \n",
       "1064      0.343366      0.479607                0.055277   \n",
       "363       0.079007      0.215462                0.211603   \n",
       "232       0.293325      0.122960                0.328632   \n",
       "729       0.040993      0.168161                0.035077   \n",
       "220       0.376901      0.546344                0.025064   \n",
       "324       0.188018      0.068014                0.273380   \n",
       "176       0.330793      0.429203                0.029159   \n",
       "345       0.069062      0.337452                0.271928   \n",
       "568       0.087177      0.180161                0.219384   \n",
       "89        0.321638      0.067272                0.224642   \n",
       "1152      0.384421      0.298872                0.449515   \n",
       "618       0.126917      0.205057                0.398031   \n",
       "\n",
       "      enabled_microbusiness_density_diff_  \\\n",
       "439                              0.193926   \n",
       "64                               0.497688   \n",
       "756                              0.199923   \n",
       "1064                             0.500069   \n",
       "363                              0.273656   \n",
       "232                              0.261236   \n",
       "729                              0.122276   \n",
       "220                              0.006841   \n",
       "324                              0.165951   \n",
       "176                              0.032369   \n",
       "345                              0.300285   \n",
       "568                              0.512832   \n",
       "89                               0.042406   \n",
       "1152                             0.514300   \n",
       "618                              0.194612   \n",
       "\n",
       "      enabled_microbusiness_density_pct_change_  \\\n",
       "439                                    0.232675   \n",
       "64                                     0.506822   \n",
       "756                                    0.396123   \n",
       "1064                                   0.408370   \n",
       "363                                    0.384955   \n",
       "232                                    0.428946   \n",
       "729                                    0.503005   \n",
       "220                                    0.201476   \n",
       "324                                    0.454600   \n",
       "176                                    0.121311   \n",
       "345                                    0.291893   \n",
       "568                                    0.383977   \n",
       "89                                     0.267731   \n",
       "1152                                   0.523702   \n",
       "618                                    0.374216   \n",
       "\n",
       "      enabled_microbusiness_density_shift_0  \\\n",
       "439                                     1.0   \n",
       "64                                      1.0   \n",
       "756                                     1.0   \n",
       "1064                                    1.0   \n",
       "363                                     1.0   \n",
       "232                                     1.0   \n",
       "729                                     1.0   \n",
       "220                                     1.0   \n",
       "324                                     1.0   \n",
       "176                                     1.0   \n",
       "345                                     1.0   \n",
       "568                                     1.0   \n",
       "89                                      1.0   \n",
       "1152                                    1.0   \n",
       "618                                     1.0   \n",
       "\n",
       "      enabled_microbusiness_density_shift_1  \\\n",
       "439                                0.468819   \n",
       "64                                 0.320625   \n",
       "756                                0.076301   \n",
       "1064                               0.105192   \n",
       "363                                0.505330   \n",
       "232                                0.269857   \n",
       "729                                0.308957   \n",
       "220                                0.125579   \n",
       "324                                0.131990   \n",
       "176                                0.101594   \n",
       "345                                0.135446   \n",
       "568                                0.130849   \n",
       "89                                 0.512489   \n",
       "1152                               0.371190   \n",
       "618                                0.432810   \n",
       "\n",
       "      enabled_microbusiness_density_shift_2  \\\n",
       "439                                0.402029   \n",
       "64                                 0.343188   \n",
       "756                                0.028221   \n",
       "1064                               0.488155   \n",
       "363                                0.455839   \n",
       "232                                0.384704   \n",
       "729                                0.347486   \n",
       "220                                0.428246   \n",
       "324                                0.496386   \n",
       "176                                0.070952   \n",
       "345                                0.043467   \n",
       "568                                0.281454   \n",
       "89                                 0.085679   \n",
       "1152                               0.294713   \n",
       "618                                0.204876   \n",
       "\n",
       "      enabled_microbusiness_density_shift_3  \\\n",
       "439                                0.067431   \n",
       "64                                 0.262035   \n",
       "756                                0.441624   \n",
       "1064                               0.338509   \n",
       "363                                0.419501   \n",
       "232                                0.475832   \n",
       "729                                0.185695   \n",
       "220                                0.319880   \n",
       "324                                0.176807   \n",
       "176                                0.385816   \n",
       "345                                0.393285   \n",
       "568                                0.138519   \n",
       "89                                 0.373776   \n",
       "1152                               0.377727   \n",
       "618                                0.262176   \n",
       "\n",
       "      enabled_original_microbusiness_density_shift_0  \\\n",
       "439                                              1.0   \n",
       "64                                               1.0   \n",
       "756                                              1.0   \n",
       "1064                                             1.0   \n",
       "363                                              1.0   \n",
       "232                                              1.0   \n",
       "729                                              1.0   \n",
       "220                                              1.0   \n",
       "324                                              1.0   \n",
       "176                                              1.0   \n",
       "345                                              1.0   \n",
       "568                                              1.0   \n",
       "89                                               1.0   \n",
       "1152                                             1.0   \n",
       "618                                              1.0   \n",
       "\n",
       "      enabled_original_microbusiness_density_shift_1  \\\n",
       "439                                         0.746386   \n",
       "64                                          0.936076   \n",
       "756                                         0.607956   \n",
       "1064                                        0.923349   \n",
       "363                                         0.796426   \n",
       "232                                         0.428246   \n",
       "729                                         0.524649   \n",
       "220                                         0.561084   \n",
       "324                                         0.774734   \n",
       "176                                         0.954209   \n",
       "345                                         0.506265   \n",
       "568                                         0.427285   \n",
       "89                                          0.595448   \n",
       "1152                                        0.901433   \n",
       "618                                         0.541275   \n",
       "\n",
       "      enabled_original_microbusiness_density_shift_2  \\\n",
       "439                                         0.103699   \n",
       "64                                          0.176021   \n",
       "756                                         0.003731   \n",
       "1064                                        0.185202   \n",
       "363                                         0.186542   \n",
       "232                                         0.136043   \n",
       "729                                         0.361055   \n",
       "220                                         0.060553   \n",
       "324                                         0.528437   \n",
       "176                                         0.226404   \n",
       "345                                         0.450673   \n",
       "568                                         0.394137   \n",
       "89                                          0.506160   \n",
       "1152                                        0.151616   \n",
       "618                                         0.463012   \n",
       "\n",
       "      enabled_original_microbusiness_density_shift_3  enabled_pct_bb_  \\\n",
       "439                                         0.489015         0.417343   \n",
       "64                                          0.108296         0.499658   \n",
       "756                                         0.038816         0.243959   \n",
       "1064                                        0.100411         0.104880   \n",
       "363                                         0.261848         0.219883   \n",
       "232                                         0.421242         0.068464   \n",
       "729                                         0.312566         0.197330   \n",
       "220                                         0.112762         0.471676   \n",
       "324                                         0.048363         0.163647   \n",
       "176                                         0.221103         0.399593   \n",
       "345                                         0.187620         0.146667   \n",
       "568                                         0.260713         0.121322   \n",
       "89                                          0.228692         0.251901   \n",
       "1152                                        0.404121         0.035313   \n",
       "618                                         0.334214         0.314931   \n",
       "\n",
       "      enabled_pct_college_  enabled_pct_foreign_born_  \\\n",
       "439               0.291748                   0.127420   \n",
       "64                0.158100                   0.541858   \n",
       "756               0.284043                   0.038342   \n",
       "1064              0.482190                   0.261041   \n",
       "363               0.373122                   0.533641   \n",
       "232               0.253784                   0.212912   \n",
       "729               0.127739                   0.212992   \n",
       "220               0.475132                   0.512560   \n",
       "324               0.225498                   0.154988   \n",
       "176               0.245040                   0.238515   \n",
       "345               0.229497                   0.298957   \n",
       "568               0.237264                   0.496930   \n",
       "89                0.320998                   0.476065   \n",
       "1152              0.449077                   0.075916   \n",
       "618               0.390598                   0.093340   \n",
       "\n",
       "      enabled_pct_it_workers_  enabled_rot_15_x_  enabled_rot_15_y_  \\\n",
       "439                  0.309854           0.244378           0.163359   \n",
       "64                   0.058500           0.530516           0.023818   \n",
       "756                  0.505452           0.336760           0.031231   \n",
       "1064                 0.426480           0.407317           0.006420   \n",
       "363                  0.136647           0.167823           0.073945   \n",
       "232                  0.107234           0.464577           0.212352   \n",
       "729                  0.449021           0.547641           0.065436   \n",
       "220                  0.532920           0.154246           0.273851   \n",
       "324                  0.492707           0.065224           0.119895   \n",
       "176                  0.147885           0.018116           0.205556   \n",
       "345                  0.444100           0.495667           0.075212   \n",
       "568                  0.486624           0.445844           0.159906   \n",
       "89                   0.410902           0.273469           0.244290   \n",
       "1152                 0.399819           0.414313           0.003129   \n",
       "618                  0.434621           0.309250           0.458009   \n",
       "\n",
       "      enabled_rot_30_x_  enabled_rot_30_y_  enabled_rot_45_x_  \\\n",
       "439            0.004255           0.467289           0.133641   \n",
       "64             0.489869           0.314270           0.419319   \n",
       "756            0.076665           0.346940           0.378916   \n",
       "1064           0.092989           0.338476           0.539963   \n",
       "363            0.344412           0.424761           0.529831   \n",
       "232            0.423801           0.531821           0.055384   \n",
       "729            0.285910           0.029116           0.515635   \n",
       "220            0.492606           0.218295           0.342852   \n",
       "324            0.205706           0.547200           0.164725   \n",
       "176            0.335764           0.052465           0.434698   \n",
       "345            0.462680           0.015228           0.399723   \n",
       "568            0.512598           0.190642           0.432718   \n",
       "89             0.522550           0.364258           0.312321   \n",
       "1152           0.097858           0.482732           0.305038   \n",
       "618            0.115247           0.165891           0.399283   \n",
       "\n",
       "      enabled_rot_45_y_  enabled_state_  \\\n",
       "439            0.180508        0.023712   \n",
       "64             0.520253        0.256259   \n",
       "756            0.397857        0.386840   \n",
       "1064           0.264152        0.226271   \n",
       "363            0.431764        0.534444   \n",
       "232            0.160150        0.303631   \n",
       "729            0.311927        0.154953   \n",
       "220            0.494612        0.281833   \n",
       "324            0.334800        0.123427   \n",
       "176            0.471271        0.118880   \n",
       "345            0.067774        0.457964   \n",
       "568            0.057594        0.360182   \n",
       "89             0.160552        0.258222   \n",
       "1152           0.293564        0.292562   \n",
       "618            0.101980        0.200339   \n",
       "\n",
       "      enabled_target_census_over_18_population_x1000_  \\\n",
       "439                                          0.610632   \n",
       "64                                           0.667763   \n",
       "756                                          0.731973   \n",
       "1064                                         0.793390   \n",
       "363                                          0.864762   \n",
       "232                                          0.788177   \n",
       "729                                          0.965613   \n",
       "220                                          0.580523   \n",
       "324                                          0.949451   \n",
       "176                                          0.636275   \n",
       "345                                          0.733895   \n",
       "568                                          0.957271   \n",
       "89                                           0.997456   \n",
       "1152                                         0.951759   \n",
       "618                                          0.841751   \n",
       "\n",
       "      enabled_target_census_population_x1000_  enabled_time_arrow_  \\\n",
       "439                                  0.644818             0.031358   \n",
       "64                                   0.627799             0.513982   \n",
       "756                                  0.915329             0.020934   \n",
       "1064                                 0.575494             0.392459   \n",
       "363                                  0.978508             0.088180   \n",
       "232                                  0.675019             0.140314   \n",
       "729                                  0.576344             0.018178   \n",
       "220                                  0.790126             0.020406   \n",
       "324                                  0.505798             0.179243   \n",
       "176                                  0.692315             0.105696   \n",
       "345                                  0.580729             0.189355   \n",
       "568                                  0.972243             0.326094   \n",
       "89                                   0.498623             0.437421   \n",
       "1152                                 0.479983             0.492187   \n",
       "618                                  0.764927             0.013360   \n",
       "\n",
       "      feature_fraction   lambda_l1   lambda_l2  learning_rate  lower_quantile  \\\n",
       "439           0.969019  108.968303  134.832860       1.712576        0.009613   \n",
       "64            0.739087   97.647669  424.056930       0.556111        0.000453   \n",
       "756           0.621647   42.524265  277.590630       1.080909        0.001784   \n",
       "1064          0.476613  180.722545   49.421819       0.011903        0.002838   \n",
       "363           0.682004   17.075982  121.664540       1.170692        0.002763   \n",
       "232           0.999952  208.054024  347.772484       0.028705        0.007655   \n",
       "729           0.952424  414.485889  340.614529       1.993864        0.006055   \n",
       "220           0.633106  371.363028  229.262183       0.771784        0.002568   \n",
       "324           0.501126  267.818325  170.329946       0.946312        0.000867   \n",
       "176           0.582267  218.078654  164.000955       0.543287        0.000188   \n",
       "345           0.982443  156.312253   36.705594       0.163379        0.003402   \n",
       "568           0.039939   47.170751  325.732336       0.469351        0.005567   \n",
       "89            0.945813  100.572120   88.717461       1.873116        0.008569   \n",
       "1152          0.073926  224.330663  105.282489       0.778729        0.008299   \n",
       "618           0.845458  233.165964  122.784035       0.136842        0.009316   \n",
       "\n",
       "       max_depth  min_data_in_leaf  min_sum_hessian_in_leaf  num_iterations  \\\n",
       "439    76.585341       1326.325342               323.015460          2000.0   \n",
       "64     93.796948        654.563838               483.238515          2000.0   \n",
       "756    20.619595        879.004232               433.440648          2000.0   \n",
       "1064   13.965846       1056.379885               103.438206          2000.0   \n",
       "363    70.460739        429.543495               422.239797          2000.0   \n",
       "232     1.794119        231.782686                32.390526          2000.0   \n",
       "729   116.522378        763.729713                37.128672          2000.0   \n",
       "220    21.271507       1157.447114                55.501718          2000.0   \n",
       "324    68.396149         48.983105               124.924729          2000.0   \n",
       "176    -2.258863        178.538561               314.563973          2000.0   \n",
       "345    16.126177         51.932267               441.174466          2000.0   \n",
       "568    67.576119        620.228702                57.128993          2000.0   \n",
       "89     66.220218       1264.235553               494.817500          2000.0   \n",
       "1152  114.169634        705.178639               491.810637          2000.0   \n",
       "618   124.398886        311.664199               105.534494          2000.0   \n",
       "\n",
       "      num_leaves  params_cfips_microbusiness_density_rolling_mean_0  \\\n",
       "439    20.296026                                           1.620234   \n",
       "64     67.735334                                           1.600089   \n",
       "756   167.496949                                           9.400186   \n",
       "1064   88.806857                                           3.861155   \n",
       "363   166.773483                                           3.912122   \n",
       "232    78.231976                                           3.324344   \n",
       "729    71.489390                                           9.922170   \n",
       "220   107.356916                                           1.129854   \n",
       "324   178.469176                                           4.261537   \n",
       "176   168.898764                                          10.065733   \n",
       "345    56.300532                                           1.890383   \n",
       "568   143.211056                                           3.415403   \n",
       "89    113.614797                                           7.008619   \n",
       "1152  140.081682                                           6.760191   \n",
       "618   196.413851                                           2.703997   \n",
       "\n",
       "      params_cfips_microbusiness_density_rolling_mean_1  \\\n",
       "439                                            3.557352   \n",
       "64                                             8.387131   \n",
       "756                                            6.808991   \n",
       "1064                                           8.021494   \n",
       "363                                            5.511245   \n",
       "232                                            7.492266   \n",
       "729                                            4.952574   \n",
       "220                                            8.871831   \n",
       "324                                            2.147131   \n",
       "176                                            4.693921   \n",
       "345                                            7.800821   \n",
       "568                                            1.743452   \n",
       "89                                             3.968640   \n",
       "1152                                           9.895542   \n",
       "618                                            1.475677   \n",
       "\n",
       "      params_cfips_microbusiness_density_rolling_mean_2  \\\n",
       "439                                            1.704538   \n",
       "64                                             4.241464   \n",
       "756                                            1.295828   \n",
       "1064                                           1.047040   \n",
       "363                                            5.014849   \n",
       "232                                            3.127598   \n",
       "729                                            8.371917   \n",
       "220                                            7.571994   \n",
       "324                                            7.526172   \n",
       "176                                            5.357342   \n",
       "345                                           11.710723   \n",
       "568                                            3.916662   \n",
       "89                                             5.524310   \n",
       "1152                                           1.967320   \n",
       "618                                            4.586709   \n",
       "\n",
       "      params_cfips_microbusiness_density_rolling_mean_3  \\\n",
       "439                                            6.479380   \n",
       "64                                             3.162764   \n",
       "756                                            3.490004   \n",
       "1064                                           1.488755   \n",
       "363                                            6.866023   \n",
       "232                                            2.455173   \n",
       "729                                            2.487921   \n",
       "220                                            6.925989   \n",
       "324                                            2.228887   \n",
       "176                                            9.429564   \n",
       "345                                            8.010602   \n",
       "568                                            8.831041   \n",
       "89                                             3.002475   \n",
       "1152                                           6.366098   \n",
       "618                                            5.986706   \n",
       "\n",
       "      params_microbusiness_density_shift_0  \\\n",
       "439                                    1.0   \n",
       "64                                     1.0   \n",
       "756                                    1.0   \n",
       "1064                                   1.0   \n",
       "363                                    1.0   \n",
       "232                                    1.0   \n",
       "729                                    1.0   \n",
       "220                                    1.0   \n",
       "324                                    1.0   \n",
       "176                                    1.0   \n",
       "345                                    1.0   \n",
       "568                                    1.0   \n",
       "89                                     1.0   \n",
       "1152                                   1.0   \n",
       "618                                    1.0   \n",
       "\n",
       "      params_microbusiness_density_shift_1  \\\n",
       "439                               4.969252   \n",
       "64                                4.116762   \n",
       "756                               3.711313   \n",
       "1064                              5.624923   \n",
       "363                               5.931244   \n",
       "232                               6.065963   \n",
       "729                               7.785486   \n",
       "220                               3.550417   \n",
       "324                               4.943117   \n",
       "176                               8.794863   \n",
       "345                               2.615649   \n",
       "568                               6.059395   \n",
       "89                                6.579866   \n",
       "1152                              6.592732   \n",
       "618                               3.289569   \n",
       "\n",
       "      params_microbusiness_density_shift_2  \\\n",
       "439                               7.655470   \n",
       "64                                4.997322   \n",
       "756                               3.889233   \n",
       "1064                              4.171323   \n",
       "363                               7.822793   \n",
       "232                               9.709920   \n",
       "729                               7.032972   \n",
       "220                               9.509783   \n",
       "324                               8.521101   \n",
       "176                               9.344924   \n",
       "345                               4.514266   \n",
       "568                               8.064110   \n",
       "89                                6.421961   \n",
       "1152                              2.454060   \n",
       "618                               7.913245   \n",
       "\n",
       "      params_microbusiness_density_shift_3  \\\n",
       "439                               2.285911   \n",
       "64                                9.924016   \n",
       "756                               4.531573   \n",
       "1064                              4.835619   \n",
       "363                               2.597802   \n",
       "232                               9.101259   \n",
       "729                               2.942463   \n",
       "220                               7.250359   \n",
       "324                               6.209608   \n",
       "176                               6.601624   \n",
       "345                               7.307728   \n",
       "568                               6.643205   \n",
       "89                                6.847635   \n",
       "1152                              6.492008   \n",
       "618                               4.121886   \n",
       "\n",
       "      params_original_microbusiness_density_shift_0  \\\n",
       "439                                             1.0   \n",
       "64                                              1.0   \n",
       "756                                             1.0   \n",
       "1064                                            1.0   \n",
       "363                                             1.0   \n",
       "232                                             1.0   \n",
       "729                                             1.0   \n",
       "220                                             1.0   \n",
       "324                                             1.0   \n",
       "176                                             1.0   \n",
       "345                                             1.0   \n",
       "568                                             1.0   \n",
       "89                                              1.0   \n",
       "1152                                            1.0   \n",
       "618                                             1.0   \n",
       "\n",
       "      params_original_microbusiness_density_shift_1  \\\n",
       "439                                             2.0   \n",
       "64                                              2.0   \n",
       "756                                             2.0   \n",
       "1064                                            2.0   \n",
       "363                                             2.0   \n",
       "232                                             2.0   \n",
       "729                                             2.0   \n",
       "220                                             2.0   \n",
       "324                                             2.0   \n",
       "176                                             2.0   \n",
       "345                                             2.0   \n",
       "568                                             2.0   \n",
       "89                                              2.0   \n",
       "1152                                            2.0   \n",
       "618                                             2.0   \n",
       "\n",
       "      params_original_microbusiness_density_shift_2  \\\n",
       "439                                        3.232797   \n",
       "64                                         8.068960   \n",
       "756                                        7.962882   \n",
       "1064                                       2.907654   \n",
       "363                                        6.492968   \n",
       "232                                        7.322260   \n",
       "729                                        5.913684   \n",
       "220                                        6.602937   \n",
       "324                                        4.439866   \n",
       "176                                        3.124765   \n",
       "345                                        7.112233   \n",
       "568                                        3.422200   \n",
       "89                                         6.228899   \n",
       "1152                                       6.196508   \n",
       "618                                        7.985537   \n",
       "\n",
       "      params_original_microbusiness_density_shift_3  path_smooth  \\\n",
       "439                                        8.497110   452.198852   \n",
       "64                                         2.303557   295.688732   \n",
       "756                                        7.933050   391.411732   \n",
       "1064                                       8.132610   107.484023   \n",
       "363                                        8.278917   215.548618   \n",
       "232                                        4.491572   235.956967   \n",
       "729                                        2.550249   366.619781   \n",
       "220                                        9.250231   262.569990   \n",
       "324                                        2.807386   476.883943   \n",
       "176                                        3.309190   242.680177   \n",
       "345                                        8.835890    71.498466   \n",
       "568                                        3.102789    78.732770   \n",
       "89                                         8.053394   459.631351   \n",
       "1152                                       5.145977   104.203144   \n",
       "618                                        7.688638   472.336103   \n",
       "\n",
       "      upper_quantile  \n",
       "439         0.999302  \n",
       "64          0.996772  \n",
       "756         0.983178  \n",
       "1064        0.997523  \n",
       "363         0.983667  \n",
       "232         0.988124  \n",
       "729         0.992109  \n",
       "220         0.994904  \n",
       "324         0.988569  \n",
       "176         0.987716  \n",
       "345         0.990973  \n",
       "568         0.988243  \n",
       "89          0.991430  \n",
       "1152        0.994697  \n",
       "618         0.992840  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_optimizer.sort_values('target', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940f70f-64e3-471b-a89e-280c25547a51",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"../data/bayesian_optimizer/\"\n",
    "df_bay_logs = [\n",
    "    (x, os.path.getsize(os.path.join(path, x)))\n",
    "    for x in os.listdir(path)\n",
    "    if \"_logs.json\" in x\n",
    "]\n",
    "df_bay_logs = pd.DataFrame(df_bay_logs, columns=[\"filename\", \"size_mb\"])\n",
    "df_bay_logs[\"size_mb\"] = (df_bay_logs[\"size_mb\"] / 1024 / 1024).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb916f6a-814d-4226-b6eb-af774053f2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_bay_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2bd72-0c57-4746-ad1e-26e2e9768946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764c97b-4036-48da-a6dc-2f2615bdc576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = optimizer.max['params']\n",
    "\n",
    "# keys_enabled = [x for x in params.keys() if 'enabled_' in x]\n",
    "# for k in keys_enabled:\n",
    "#     params[k] = 0\n",
    "    \n",
    "# keys_params = [x for x in params.keys() if 'params_' in x]\n",
    "# for k in keys_params:\n",
    "#     params[k] = 0\n",
    "\n",
    "# params['enabled_microbusiness_density_shift_0'] = 1\n",
    "# params['params_microbusiness_density_shift_0'] = 1\n",
    "\n",
    "# t = lgb.LGBMRegressor()\n",
    "# t_params = t.get_params()\n",
    "# for k in t_params.keys():\n",
    "#     if k in params.keys():\n",
    "#         print(k)\n",
    "#         params[k] = t_params[k]\n",
    "# # params = {**params, **t.get_params()}\n",
    "# params['bagging_fraction'] = 1\n",
    "# params['bagging_freq'] = 0\n",
    "# params['lambda_l1'] = 0\n",
    "# params['feature_fraction'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017259e3-0bcc-4435-a302-7b503db9e0ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = optimizer.max['params']\n",
    "gbm, lgb_train, lgb_eval, lgb_test, model_params, callbacks, df_features, df_target = optimize_this_partial(\n",
    "    return_booster=True, **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b345e-9cd3-48e1-8cbe-c2613d88c06a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbm.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e84691-d8d6-44f6-b3cf-4f5c9eeec0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = lgb_test.data.copy()\n",
    "pred = gbm.predict(df_test)\n",
    "df_test['label'] = lgb_test.label\n",
    "df_test['pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a149830-e6e0-41c5-9a01-f3352f073221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t2 = pd.merge(\n",
    "    df_test[[\"label\", \"pred\"]],\n",
    "    df_train.set_index(\"row_id\")[\n",
    "        [\"target_census_over_18_population_x1000\", \"original_microbusiness_density\"]\n",
    "    ],\n",
    "    \"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "t2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d23e1-fef4-4de8-a947-7c3c0d51d808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t2['microbusiness_density_pred'] = (t2['pred'] / (t2['target_census_over_18_population_x1000'] * 1000)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed79c8-d663-4190-812e-8ff2a408f4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smape(t2['microbusiness_density_pred'], t2['original_microbusiness_density'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9323df4-836f-4a7e-ac5c-b61b88930c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(t2['label'] / (t2['target_census_population_x1000'] * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63e3f2-124e-4c6f-8678-93e150875692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104fde0-ad5a-41ed-b8ff-e824e7e2d6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2895f-76db-4381-9963-baa187222d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.set_index('row_id')['target_census_population_x1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625451b-295d-4a19-bf97-0ee7d7b42f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88140e3f-c329-43f2-b2fb-3fcce9255748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set(t.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4903597-7d34-44c4-9b52-b68b61a61aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbm.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8e2f2-1f17-4ca5-8c62-0568e297392e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = lgb_test\n",
    "pred = gbm.predict(dataset.data)\n",
    "smape(pred, dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7feb41-323c-431e-ab0f-66d37544b668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t4 = df_optimizer.sort_values('target', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4324a-dab2-4314-9520-bfa31c97e58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
